{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/stun/source/css/index.styl","path":"css/index.styl","modified":0,"renderable":1},{"_id":"themes/stun/source/images/algolia.svg","path":"images/algolia.svg","modified":0,"renderable":1},{"_id":"themes/stun/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/stun/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/stun/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/stun/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/stun/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/stun/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/stun/source/images/loading.svg","path":"images/loading.svg","modified":0,"renderable":1},{"_id":"themes/stun/source/js/header.js","path":"js/header.js","modified":0,"renderable":1},{"_id":"themes/stun/source/js/scroll.js","path":"js/scroll.js","modified":0,"renderable":1},{"_id":"themes/stun/source/js/sidebar.js","path":"js/sidebar.js","modified":0,"renderable":1},{"_id":"themes/stun/source/js/stun-boot.js","path":"js/stun-boot.js","modified":0,"renderable":1},{"_id":"themes/stun/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/stun/source/images/icons/favicon-32x32.png","path":"images/icons/favicon-32x32.png","modified":0,"renderable":1},{"_id":"themes/stun/source/images/icons/favicon-16x16.png","path":"images/icons/favicon-16x16.png","modified":0,"renderable":1},{"_id":"themes/stun/source/images/icons/stun-logo.svg","path":"images/icons/stun-logo.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/hello-world.md","hash":"7d98d6592de80fdcd2949bd7401cec12afd98cdf","modified":1619274910905},{"_id":"themes/stun/.commitlintrc.js","hash":"af8f006fbdfc6a1880605c7a35e63de300d6929b","modified":1619310756379},{"_id":"themes/stun/.cz-config.js","hash":"fbb89df58c60cf4f3827059d0574accc8407e1bb","modified":1619310756379},{"_id":"themes/stun/.editorconfig","hash":"1ca001b8a7ed235eb9f5c21360b3a11eedb84ae7","modified":1619310756379},{"_id":"themes/stun/.eslintrc","hash":"1ba4f0ddd4bef04884c7fda6ef04f9d9697a62b4","modified":1619310756379},{"_id":"themes/stun/.gitignore","hash":"7745f04d70b1ea58b02d68dde999708836343c7a","modified":1619310756381},{"_id":"themes/stun/.prettierrc","hash":"4b6589404c509f4538daf6f3b8b3ee2ec37d2f4c","modified":1619310756381},{"_id":"themes/stun/CHANGELOG.md","hash":"77eadd10fafb46e194cd1a0ea9a986270ba994c9","modified":1619310756381},{"_id":"themes/stun/.stylintrc","hash":"3305c42a95c986341d7c7dd03ed9f37a42da343c","modified":1619310756381},{"_id":"themes/stun/LICENSE","hash":"c79ab3fe0ee8f2388376574dfe704b3df0c70a69","modified":1619310756382},{"_id":"themes/stun/README.md","hash":"b77f5b18bfe474178fee322ff6065f960f33c96d","modified":1619310756382},{"_id":"themes/stun/package.json","hash":"020d40d2fc58d74bdb79d9e1036631679733d2aa","modified":1619310756396},{"_id":"themes/stun/FAQ.md","hash":"df56d44b1297fe507d8b4edefb303629f4b23c67","modified":1619310756382},{"_id":"themes/stun/README_en-US.md","hash":"5e7bff4bcd02badcd3207379d353c5d1ea403a4f","modified":1619310756382},{"_id":"themes/stun/_config.yml","hash":"01d7a55e9e98bdc0d6d6ae9731122d4963cf0225","modified":1619310756382},{"_id":"themes/stun/languages/zh-CN.yml","hash":"8535e2d34d24769067ba7bd3d9c0b94d1fd01cc7","modified":1619310756383},{"_id":"themes/stun/languages/en.yml","hash":"e1348852aa00d2d57f5215c83709f6428f8e8a71","modified":1619310756383},{"_id":"themes/stun/languages/es.yml","hash":"e150c8a1f56ae9ed065611951aa124fb548577fc","modified":1619310756383},{"_id":"themes/stun/languages/zh-HK.yml","hash":"aef25f329cc05dbe8e38753fccd98d63c9fcd174","modified":1619310756383},{"_id":"themes/stun/layout/_layout.pug","hash":"5052ee5040ae736d78ad208df7352be69b61b0d1","modified":1619310756383},{"_id":"themes/stun/layout/category.pug","hash":"24153408b2971542d177227f09e93da7754bf75e","modified":1619310756392},{"_id":"themes/stun/layout/archive.pug","hash":"d45d078ae4196add83e21fcaed3ef168b237af90","modified":1619310756392},{"_id":"themes/stun/layout/index.pug","hash":"df40cf1f051fd29f0f51ace74e9f7394f6ea2ab7","modified":1619310756392},{"_id":"themes/stun/layout/post.pug","hash":"a4d16dbb919df5d4ffdb5a1d0114a4e1c8c21197","modified":1619310756393},{"_id":"themes/stun/layout/page.pug","hash":"22ba5928bd9ae8c56b3242b7caa5fc3ec471b082","modified":1619310756392},{"_id":"themes/stun/layout/tag.pug","hash":"46f956ad7e2aed879999ddf5e768d80c4bbe5b5f","modified":1619310756393},{"_id":"themes/stun/.github/FUNDING.yml","hash":"963cf7fb304865af888ad4bbb87a0f5991f3790f","modified":1619310756380},{"_id":"themes/stun/scripts/engine.js","hash":"a63a57c9206a77a79f93dbd86e86204447d7d904","modified":1619310756397},{"_id":"themes/stun/scripts/merge-config.js","hash":"bb914100129c5ca2d1a9e087fffd7bedcb6ae6a6","modified":1619310756398},{"_id":"themes/stun/.github/ISSUE_TEMPLATE/bug-report_en.md","hash":"70022617d944b410a21c28d2abafcfe0b2928f01","modified":1619310756380},{"_id":"themes/stun/.github/ISSUE_TEMPLATE/bug-report_zh.md","hash":"0b42693e9577d3203473caa11ceaa9f64096a67c","modified":1619310756380},{"_id":"themes/stun/.github/ISSUE_TEMPLATE/feature-request_en.md","hash":"af7175a0d0f7edfbfbeef3eeb949e20d1e41bf38","modified":1619310756380},{"_id":"themes/stun/.github/ISSUE_TEMPLATE/other_en.md","hash":"6b6afbfc66ee51624f7eeaeb5a1fc959e290e06d","modified":1619310756381},{"_id":"themes/stun/.github/ISSUE_TEMPLATE/feature-request_zh.md","hash":"1ecd119a1f4c6fbe3886c885b7d13f1fcc048a5b","modified":1619310756380},{"_id":"themes/stun/.github/ISSUE_TEMPLATE/other_zh.md","hash":"a9f7abd311731c21082fa5e553251f4704e555c5","modified":1619310756381},{"_id":"themes/stun/layout/_mixins/gallery.pug","hash":"3054e2c09bc205173c517fb1c36321f7c4c0db63","modified":1619310756383},{"_id":"themes/stun/layout/_mixins/menu-item.pug","hash":"93c4454e48a6f1456c29aeb9d1332be186b49d4f","modified":1619310756384},{"_id":"themes/stun/layout/_mixins/meta-item.pug","hash":"3d74dc8ba8651efd4a605e56a21e314678d04057","modified":1619310756384},{"_id":"themes/stun/layout/_mixins/post-header.pug","hash":"9486d07e56acf7bcc5d691bef93c19e2e5c98022","modified":1619310756384},{"_id":"themes/stun/.github/workflows/files-shaking.yml","hash":"3593429efe2f5b196a44d185e810b226cef26714","modified":1619310756381},{"_id":"themes/stun/.github/workflows/codeql-analysis.yml","hash":"7a9d289addb10720f6b666157efe170d47774906","modified":1619310756381},{"_id":"themes/stun/layout/_mixins/timeline.pug","hash":"4e19a670f002d3c6bc740a2d6ef03964e6b59c09","modified":1619310756384},{"_id":"themes/stun/layout/_scripts/stun.pug","hash":"961554914427578b57ea3912d751d398f4eb381d","modified":1619310756388},{"_id":"themes/stun/layout/_scripts/vendors.pug","hash":"62a6831d3b1d90d6c8335ce3402efc50e141eafb","modified":1619310756388},{"_id":"themes/stun/layout/_third-party/pjax.pug","hash":"4a786459a8e6a4f378a9d834502f8b11aa66f185","modified":1619310756391},{"_id":"themes/stun/layout/_partials/config.pug","hash":"4fb832652485161148ea957067c06d50ed11578b","modified":1619310756384},{"_id":"themes/stun/layout/_third-party/quicklink.pug","hash":"2bed65ed4d314dc587e2359e20ae099b46181ed5","modified":1619310756391},{"_id":"themes/stun/scripts/filters/image-setting.js","hash":"412318b6d189d5355dbcc52c9762072f7ecdaad4","modified":1619310756397},{"_id":"themes/stun/scripts/filters/post-heading.js","hash":"b504aa047e3f080fc3f95f3e96fad88bbbce20cb","modified":1619310756398},{"_id":"themes/stun/scripts/filters/lazyload.js","hash":"d5baf39faeff5368182be1f59fb598d023985cde","modified":1619310756397},{"_id":"themes/stun/scripts/filters/external-link.js","hash":"f5369becfd8cc6e43d6dc3595b1edbe014d9aa7c","modified":1619310756397},{"_id":"themes/stun/scripts/filters/shake-file.js","hash":"159dff6e4f7020545c9b151108398cd383d613e2","modified":1619310756398},{"_id":"themes/stun/scripts/filters/wrap-table.js","hash":"888c9eaaddcdb9b88d07837a9091aa39ed3fe677","modified":1619310756398},{"_id":"themes/stun/scripts/tags/friends.js","hash":"c2fe1e8e128f464d772bcb7534efef54ad224310","modified":1619310756399},{"_id":"themes/stun/scripts/tags/note.js","hash":"b436593a56e3bab8dd59c71e73ac9efbc8fa29d4","modified":1619310756399},{"_id":"themes/stun/scripts/tags/table.js","hash":"177061e1bfb296981a101643f51a27ccc1469307","modified":1619310756399},{"_id":"themes/stun/source/css/index.styl","hash":"8a75ec81fb064b0da2f978a064cc5bec2395f27d","modified":1619310756412},{"_id":"themes/stun/source/images/algolia.svg","hash":"90322f80db6ad0daf26ea3ec71dea6f691a8b2f1","modified":1619310756413},{"_id":"themes/stun/source/images/cc-by-nc-nd.svg","hash":"017ad912874686a982ebceae359299b8f2a492e2","modified":1619310756413},{"_id":"themes/stun/source/images/cc-by-nc-sa.svg","hash":"71d035c34219f924dbf1bf852166ee8fb58d2f24","modified":1619310756413},{"_id":"themes/stun/source/images/cc-by-nc.svg","hash":"4608189edbe7636dd651df65473298a3c5afb20d","modified":1619310756413},{"_id":"themes/stun/source/images/cc-by-nd.svg","hash":"20c66ae3c393903e6eab3bc8cf7c3be6d753f9f8","modified":1619310756413},{"_id":"themes/stun/source/images/cc-by-sa.svg","hash":"0455a8857ba096925d4145a56e8d10537fccb378","modified":1619310756414},{"_id":"themes/stun/source/images/cc-by.svg","hash":"77f74c241902447424207869c74cb9d9264bdced","modified":1619310756414},{"_id":"themes/stun/source/images/loading.svg","hash":"32a6e770d217ae6c0cf0f6beef3172f1b5b9a0a2","modified":1619310756415},{"_id":"themes/stun/source/js/scroll.js","hash":"8926ab87181a49c730ce5132518b608c54b8cdb1","modified":1619310756415},{"_id":"themes/stun/source/js/header.js","hash":"63d407ee6f80114e220171ba829b79b28d420fe0","modified":1619310756415},{"_id":"themes/stun/source/js/sidebar.js","hash":"20adff7f54bcd8299d32690d41ebc7a4eb7a8728","modified":1619310756415},{"_id":"themes/stun/source/js/stun-boot.js","hash":"8358ac0d879c0ca340c52e4de606523c2a91e156","modified":1619310756416},{"_id":"themes/stun/source/js/utils.js","hash":"b570eafe77e47d7701348f172a4dbaaba6fa8123","modified":1619310756416},{"_id":"themes/stun/layout/_partials/analytics/busuanzi.pug","hash":"80d2f4f8706a96b367ac1e89f5b56ada4684d571","modified":1619310756384},{"_id":"themes/stun/layout/_partials/footer/footer.pug","hash":"9a8e56bcc504f251c13ee3d0d18a08142fb7ee43","modified":1619310756384},{"_id":"themes/stun/layout/_partials/head/head.pug","hash":"c7909a6a50c7a76a6c1810b700a5d72bcb1e20c9","modified":1619310756385},{"_id":"themes/stun/layout/_partials/head/kill-old-ie.pug","hash":"427a95d02844f29e63c5e9f014ede3609aec1a5b","modified":1619310756385},{"_id":"themes/stun/layout/_partials/header/header.pug","hash":"7ecbe18da15d3a52c56f69c542540291b6178763","modified":1619310756385},{"_id":"themes/stun/layout/_partials/post/post-list.pug","hash":"c049078009aa251fc76cd948837c7a5efdd39cb2","modified":1619310756385},{"_id":"themes/stun/layout/_partials/search/algolia.pug","hash":"61181bece0e27929fe00df5204fefd8dee31a354","modified":1619310756385},{"_id":"themes/stun/layout/_partials/search/index.pug","hash":"0f84aa013a96e7eb3bb25b87f20bab9b7ac55538","modified":1619310756386},{"_id":"themes/stun/layout/_partials/search/assist-btns.pug","hash":"7e6dc0d975ccbe291116487b15277d27a391fb9a","modified":1619310756386},{"_id":"themes/stun/layout/_partials/search/localsearch.pug","hash":"4d8e0bc33f92a603e0b2a5f4296af6bcc7cc31b8","modified":1619310756386},{"_id":"themes/stun/layout/_partials/sidebar/sidebar.pug","hash":"18173a2acf99db39748c392f2e669acd805b4090","modified":1619310756386},{"_id":"themes/stun/layout/_partials/widgets/back2top.pug","hash":"48b7fedeb472bd01fd1f3317359a10e83ca919e1","modified":1619310756386},{"_id":"themes/stun/layout/_partials/widgets/comments.pug","hash":"af1b16be74c7e1242e0f57986672dc73e93546e2","modified":1619310756387},{"_id":"themes/stun/layout/_partials/widgets/copyright.pug","hash":"0938c885697f6eb388b28ddbf88f5631d024fe73","modified":1619310756387},{"_id":"themes/stun/layout/_partials/widgets/loading-bar.pug","hash":"6cda7866f9589c9ffc05ce4a3d7c33b706e70324","modified":1619310756387},{"_id":"themes/stun/layout/_partials/widgets/night-mode.pug","hash":"c7f9bd67cd231b9bd40a84123644e009ac8d8ef3","modified":1619310756387},{"_id":"themes/stun/layout/_partials/widgets/paginator.pug","hash":"b0045dcb9b151ee31f1db5b7d741f10ef3b74be0","modified":1619310756387},{"_id":"themes/stun/layout/_partials/widgets/share.pug","hash":"1bb3d25298b7ee6a28150aa286ed6b0ae42ead4f","modified":1619310756387},{"_id":"themes/stun/layout/_partials/widgets/reward.pug","hash":"c9081c1dcf0ca18df06d23638654d8f43b28d55c","modified":1619310756387},{"_id":"themes/stun/layout/_partials/widgets/sticky-top.pug","hash":"bf86b2f9f4b1471afb8b31965d3230f6088682ae","modified":1619310756388},{"_id":"themes/stun/layout/_third-party/advertising/google-adsense.pug","hash":"e489020f1130976d3ec2245915ede6319d89b89c","modified":1619310756388},{"_id":"themes/stun/layout/_third-party/advertising/index.pug","hash":"1285cd65a873f688ae3c51846c1284447f502adc","modified":1619310756388},{"_id":"themes/stun/layout/_third-party/analytics/baidu-analytics.pug","hash":"f7300991a29dbe2e8091a588dfa8c65c3dee6302","modified":1619310756389},{"_id":"themes/stun/layout/_third-party/analytics/busuanzi.pug","hash":"78a4fc9c9380e31536f5b500638f2d005accd361","modified":1619310756389},{"_id":"themes/stun/layout/_third-party/analytics/google-analytics.pug","hash":"4eef66fbb8a8ad55e0868cf4b77a6b7bca0e7f35","modified":1619310756389},{"_id":"themes/stun/layout/_third-party/analytics/index.pug","hash":"0d72f844bf9532b3be644c27b0af7cb4331fc46c","modified":1619310756389},{"_id":"themes/stun/layout/_third-party/analytics/tencent-analytics.pug","hash":"f88fb0f085812db6023c30308ba3458da7742993","modified":1619310756389},{"_id":"themes/stun/layout/_third-party/comments/disqus.pug","hash":"57bcbaac3d237d9168dd8f4b682f34351f11d250","modified":1619310756389},{"_id":"themes/stun/layout/_third-party/comments/fbcomments.pug","hash":"fb651812c87dc5e2134d7fb7d8f98d4d4227f1f6","modified":1619310756390},{"_id":"themes/stun/layout/_third-party/comments/gitalk.pug","hash":"c2a90e80c51b5b99e6804dbed5457a071b980bbd","modified":1619310756390},{"_id":"themes/stun/layout/_third-party/comments/index.pug","hash":"bec4d9c8ea360637e7da3314fa987e33facd8071","modified":1619310756390},{"_id":"themes/stun/layout/_third-party/comments/livere.pug","hash":"687f74a998519608944b40a41f3a98ccf4535139","modified":1619310756390},{"_id":"themes/stun/layout/_third-party/comments/minivaline.pug","hash":"5584ade7dd19deca418373115bde9d563d37d826","modified":1619310756390},{"_id":"themes/stun/layout/_third-party/comments/utterances.pug","hash":"6418baeb3aedcddb02a64bd89b26ac12e18551c8","modified":1619310756390},{"_id":"themes/stun/layout/_third-party/comments/valine.pug","hash":"b519a6948d6ef37c037385e3e3f9590c17f7ad62","modified":1619310756390},{"_id":"themes/stun/layout/_third-party/comments/waline.pug","hash":"fd4c958b13777752f176556c7b109b7dede7cc68","modified":1619310756390},{"_id":"themes/stun/layout/_third-party/math/index.pug","hash":"e952be6c736545e73c0e02f833f87a4f8c5a2582","modified":1619310756391},{"_id":"themes/stun/layout/_third-party/math/katex.pug","hash":"345c59fe76a7c83b529328e5144d1036cb14f533","modified":1619310756391},{"_id":"themes/stun/layout/_third-party/math/mathjax.pug","hash":"72d51538cc85f01c8c64db74b9219ccaf334c9e9","modified":1619310756391},{"_id":"themes/stun/layout/_third-party/search/index.pug","hash":"0f84aa013a96e7eb3bb25b87f20bab9b7ac55538","modified":1619310756392},{"_id":"themes/stun/layout/_third-party/search/algolia.pug","hash":"54233748e22ceae063f70ee49b44c4bd0a78f391","modified":1619310756391},{"_id":"themes/stun/layout/_third-party/search/localsearch.pug","hash":"d98db7ed7e3e4c574212fa9d75adba681f3d0687","modified":1619310756392},{"_id":"themes/stun/source/css/_common/index.styl","hash":"86057db6cb18263866d62a6669feee8752882398","modified":1619310756409},{"_id":"themes/stun/source/css/_common/responsive.styl","hash":"618c6005f1bc7c482fa37ae3ce15729a64044d9d","modified":1619310756410},{"_id":"themes/stun/source/css/_custom/index.styl","hash":"0d1adc70250941074c742f94f7801b3b43a7f1db","modified":1619310756411},{"_id":"themes/stun/source/css/_mixins/index.styl","hash":"f3060519f3acd05cb4b26bb5f6a5c6b857cb0d68","modified":1619310756411},{"_id":"themes/stun/source/css/_variables/index.styl","hash":"c81aac4285eb058026b255e31282d35f55a820ab","modified":1619310756412},{"_id":"themes/stun/source/images/icons/favicon-32x32.png","hash":"02fead07726920400ede57ddfdbf071dd7203fd5","modified":1619310756414},{"_id":"themes/stun/source/images/icons/favicon-16x16.png","hash":"7bfd64eac26e17ea162f0c399a4a40164c26b412","modified":1619310756414},{"_id":"themes/stun/source/images/icons/stun-logo.svg","hash":"069dc7590ad152373f1c346d892e32faa2bbdd87","modified":1619310756414},{"_id":"themes/stun/source/css/_common/components/index.styl","hash":"a54720db94121efd1a34ac88d344197c8206837e","modified":1619310756402},{"_id":"themes/stun/source/css/_common/outline/index.styl","hash":"467d4171c0690a95d40fbecea02e6b212b7c74f1","modified":1619310756409},{"_id":"themes/stun/source/css/_common/scaffolding/base.styl","hash":"4064a7e2c3f71d2ed72a47edd60e9be01af6c354","modified":1619310756410},{"_id":"themes/stun/source/css/_common/outline/macro.styl","hash":"13b96f239de15e1cfdc14d9c80e6959506556dd2","modified":1619310756410},{"_id":"themes/stun/source/css/_common/scaffolding/index.styl","hash":"e750f2dae9eb3385039ee018ff8001b0e6ec3b64","modified":1619310756410},{"_id":"themes/stun/source/css/_common/scaffolding/normalize.styl","hash":"c15a9616fddb267431416304d709185aeb3d45f5","modified":1619310756411},{"_id":"themes/stun/source/css/_common/scaffolding/utils.styl","hash":"7e62f34521ea539a25a101f25e1684e3a3ac4be8","modified":1619310756411},{"_id":"themes/stun/source/css/_common/components/analytics/index.styl","hash":"339a43fd5ee97a77775b723118f6ab1af754fed4","modified":1619310756400},{"_id":"themes/stun/source/css/_common/components/header/index.styl","hash":"904af0e73cdf0767ec781271856d7b5b63e043ef","modified":1619310756401},{"_id":"themes/stun/source/css/_common/components/footer/index.styl","hash":"14464841145cf3ecab66f1094653daa033c261eb","modified":1619310756401},{"_id":"themes/stun/source/css/_common/components/highlight/diff.styl","hash":"056e70f6dfe45ec50427d7ab293d33361c9b956f","modified":1619310756401},{"_id":"themes/stun/source/css/_common/components/highlight/highlight.styl","hash":"bc0b01021a0d19b2c98f0c5c9fa1af96d67c1099","modified":1619310756402},{"_id":"themes/stun/source/css/_common/components/highlight/index.styl","hash":"85848179cbc78152d2521b601ac9f888dea4e255","modified":1619310756402},{"_id":"themes/stun/source/css/_common/components/highlight/theme.styl","hash":"dfc99b05302f8203040431e563c9f63d63da46de","modified":1619310756402},{"_id":"themes/stun/source/css/_common/components/pages/index.styl","hash":"463a4e6a92ec5f757e167fbeb171e4e92e83a822","modified":1619310756403},{"_id":"themes/stun/source/css/_common/components/pages/page.styl","hash":"df732e267dfd9f1bda6a8cf1ede3198a205925f9","modified":1619310756403},{"_id":"themes/stun/source/css/_common/components/pages/timeline.styl","hash":"21e9c8def1613030f0927e2ce80f4ecc721f078e","modified":1619310756403},{"_id":"themes/stun/source/css/_common/components/plugins/friends.styl","hash":"bdb015173f8e5fa391fc4fb2b2a8d42787022c4b","modified":1619310756403},{"_id":"themes/stun/source/css/_common/components/plugins/note.styl","hash":"ae0ad9b44a87839d220792336478a9ae6db11c47","modified":1619310756404},{"_id":"themes/stun/source/css/_common/components/plugins/index.styl","hash":"c35d0cf421c6669ee0458c2f0264dca05769c01d","modified":1619310756404},{"_id":"themes/stun/source/css/_common/components/analytics/busuanzi.styl","hash":"d196c88ea2e9b851e8d8f9c5a315dfc2929eb897","modified":1619310756400},{"_id":"themes/stun/source/css/_common/components/plugins/table.styl","hash":"98cacc91e42f5e45279e2174a90ab26171085e2f","modified":1619310756404},{"_id":"themes/stun/source/css/_common/components/post/index.styl","hash":"08aad11e329cda0550efef226e0c4d0bb4540454","modified":1619310756404},{"_id":"themes/stun/source/css/_common/components/post/post-list.styl","hash":"d0ed844e28533f832cbd9b3f09203d16936628f7","modified":1619310756404},{"_id":"themes/stun/source/css/_common/components/post/post.styl","hash":"8b7b22225b40d028efee689d3700a9796291cb8d","modified":1619310756405},{"_id":"themes/stun/source/css/_common/components/search/index.styl","hash":"1990d2c2a9bfe8e09d656f0c2ae6cf0c9f7f5542","modified":1619310756405},{"_id":"themes/stun/source/css/_common/components/sidebar/index.styl","hash":"02138647437f7e8ee8927cae225d41072d936bdc","modified":1619310756406},{"_id":"themes/stun/source/css/_common/components/widgets/back2top.styl","hash":"b3da5ea71a9947e781056d1bd7d42e4045fa2aca","modified":1619310756406},{"_id":"themes/stun/source/css/_common/components/widgets/comments.styl","hash":"41d229ac4fa02a3a8b46687ccbafa7a608008e2f","modified":1619310756406},{"_id":"themes/stun/source/css/_common/components/widgets/copy-button.styl","hash":"378961fa7c986e3313053814806902bf76204a93","modified":1619310756406},{"_id":"themes/stun/source/css/_common/components/widgets/copyright.styl","hash":"1d28fc8f76f7164a306ed81a9ede21c0a2b0f7cd","modified":1619310756407},{"_id":"themes/stun/source/css/_common/components/widgets/ending.styl","hash":"63985ca9a3f6c481cc60207966fa1267de14d945","modified":1619310756407},{"_id":"themes/stun/source/css/_common/components/search/algolia.styl","hash":"fb62e4baf25a66e46c27783be5d79353ec394b44","modified":1619310756405},{"_id":"themes/stun/source/css/_common/components/search/common.styl","hash":"1939b7dfbcf557794a188fbf8fec4ef2b5afa437","modified":1619310756405},{"_id":"themes/stun/source/css/_common/components/widgets/font-icon.styl","hash":"bdda0953611378e93a8d6387cbdc93e1de4f7f0a","modified":1619310756407},{"_id":"themes/stun/source/css/_common/components/widgets/gallery-image.styl","hash":"99b1cc42f38816083f93233778b299422b6d8f32","modified":1619310756407},{"_id":"themes/stun/source/css/_common/components/widgets/index.styl","hash":"03ffdc55fd5fb64c3158bc222d0e8e9d7844686b","modified":1619310756407},{"_id":"themes/stun/source/css/_common/components/search/localsearch.styl","hash":"bf1ac1b8ee8c4daaa7e6b47eec097a176624e6d0","modified":1619310756405},{"_id":"themes/stun/source/css/_common/components/widgets/night-mode.styl","hash":"9caeef13a913aba38976f082e1f0ca191bffc64e","modified":1619310756408},{"_id":"themes/stun/source/css/_common/components/widgets/fancybox.styl","hash":"3d677c0323d77199bb9fbfefd65e97d8b882d7b3","modified":1619310756407},{"_id":"themes/stun/source/css/_common/components/widgets/paginator.styl","hash":"71ddb6a1e9664a4fde04a0ce143b8786ba6e0089","modified":1619310756408},{"_id":"themes/stun/source/css/_common/components/widgets/lazyload.styl","hash":"eced96235f0ff5dc6a8fd068d4ed05934a29b430","modified":1619310756408},{"_id":"themes/stun/source/css/_common/components/widgets/loading-bar.styl","hash":"9f23e8762d01fb4a3cbf5e786fdead2926849e8a","modified":1619310756408},{"_id":"themes/stun/source/css/_common/components/widgets/reward.styl","hash":"de1130ec3765879884cbdc77a15b458da6e37bcc","modified":1619310756408},{"_id":"themes/stun/source/css/_common/components/widgets/sticky-top.styl","hash":"f0e37944168a74a64b18dc54c6fde2308e4bf023","modified":1619310756409},{"_id":"themes/stun/source/css/_common/components/widgets/zoom-image.styl","hash":"40f832a199320642debabe32910c1168e3c6e40c","modified":1619310756409},{"_id":"themes/stun/source/css/_common/components/widgets/share.styl","hash":"fe32e3434107d92cefd7aacfdcef526a93c4b865","modified":1619310756409},{"_id":"themes/stun/package-lock.json","hash":"623a3d645e58db11a77bf118b8cbee96c8a527df","modified":1619310756396},{"_id":"public/2021/04/24/hello-world/index.html","hash":"a7ffbd053de12662eaa447f379863cbbfbec5acb","modified":1622723067863},{"_id":"public/archives/index.html","hash":"d744561c81443beb3344a66560d64a5da35c6476","modified":1622723067863},{"_id":"public/archives/2021/index.html","hash":"60d8841271b638598827877bf595ba0d33568325","modified":1622723067863},{"_id":"public/archives/2021/04/index.html","hash":"e0acd2f34a1abf728781db674db4a7c4cf406154","modified":1622723067863},{"_id":"public/index.html","hash":"e133b0f76ef289c3ee7fa0347d44826ba2e79104","modified":1622723144666},{"_id":"public/images/algolia.svg","hash":"90322f80db6ad0daf26ea3ec71dea6f691a8b2f1","modified":1619311546536},{"_id":"public/images/cc-by-nc-nd.svg","hash":"017ad912874686a982ebceae359299b8f2a492e2","modified":1619311546536},{"_id":"public/images/cc-by-nc-sa.svg","hash":"71d035c34219f924dbf1bf852166ee8fb58d2f24","modified":1619311546536},{"_id":"public/images/cc-by-nc.svg","hash":"4608189edbe7636dd651df65473298a3c5afb20d","modified":1619311546536},{"_id":"public/images/cc-by-nd.svg","hash":"20c66ae3c393903e6eab3bc8cf7c3be6d753f9f8","modified":1619311546536},{"_id":"public/images/cc-by-sa.svg","hash":"0455a8857ba096925d4145a56e8d10537fccb378","modified":1619311546536},{"_id":"public/images/cc-by.svg","hash":"77f74c241902447424207869c74cb9d9264bdced","modified":1619311546536},{"_id":"public/images/loading.svg","hash":"32a6e770d217ae6c0cf0f6beef3172f1b5b9a0a2","modified":1619311546536},{"_id":"public/images/icons/favicon-32x32.png","hash":"02fead07726920400ede57ddfdbf071dd7203fd5","modified":1619311546536},{"_id":"public/images/icons/favicon-16x16.png","hash":"7bfd64eac26e17ea162f0c399a4a40164c26b412","modified":1619311546536},{"_id":"public/images/icons/stun-logo.svg","hash":"069dc7590ad152373f1c346d892e32faa2bbdd87","modified":1619311546536},{"_id":"public/js/header.js","hash":"63d407ee6f80114e220171ba829b79b28d420fe0","modified":1619311546536},{"_id":"public/js/sidebar.js","hash":"20adff7f54bcd8299d32690d41ebc7a4eb7a8728","modified":1619311546536},{"_id":"public/js/stun-boot.js","hash":"8358ac0d879c0ca340c52e4de606523c2a91e156","modified":1619311546536},{"_id":"public/js/scroll.js","hash":"8926ab87181a49c730ce5132518b608c54b8cdb1","modified":1619311546536},{"_id":"public/css/index.css","hash":"59bc1caffdd54f68af88765f582caad107426a76","modified":1619311546536},{"_id":"public/js/utils.js","hash":"b570eafe77e47d7701348f172a4dbaaba6fa8123","modified":1619311546536},{"_id":"source/_posts/Linux系统安装配置初探.md","hash":"139ad4b275f8b507ce219019c7758cda95564cf7","modified":1622130535739},{"_id":"public/2021/05/27/Linux系统安装配置初探/index.html","hash":"118b446588cd136aa94289a1f33afc643e38559d","modified":1622723067863},{"_id":"public/archives/2021/05/index.html","hash":"c86746ec5a834125dd3b42ff4b7432f827d5c83d","modified":1622723067863},{"_id":"source/_posts/.DS_Store","hash":"39ddbbd84c09776839ebd70fb0a2761f55a2cbd7","modified":1622283914010},{"_id":"source/.DS_Store","hash":"58d64177b41308355e578c659fa4aefc295a4b66","modified":1622284916151},{"_id":"source/_posts/MapReduce论文及MIT相关实验总结.md","hash":"65cd43d4ab0857838526c0ef2679f5a242bf558f","modified":1622285581889},{"_id":"source/_posts/MapReduce论文及MIT相关实验总结/exec_overview.png","hash":"32b8aa4a964c19125f623426a7672fb96d5c92a9","modified":1622190516314},{"_id":"source/_posts/MapReduce论文及MIT相关实验总结/fault_tolerate.jpeg","hash":"9e3c94780821eca04ee81ea05f4ea4a31bfcb4ae","modified":1622262167000},{"_id":"source/_posts/MapReduce论文及MIT相关实验总结/invert_index.jpeg","hash":"88165c7dda3e5ba633b906ddcbdb22cc482e7249","modified":1622259213000},{"_id":"public/2021/05/29/MapReduce论文及MIT相关实验总结/index.html","hash":"b3a2d3584df501297b3ba5b00f4f03cdf277e8f2","modified":1622723067863},{"_id":"public/2021/05/29/MapReduce论文及MIT相关实验总结/exec_overview.png","hash":"32b8aa4a964c19125f623426a7672fb96d5c92a9","modified":1622284000417},{"_id":"public/2021/05/29/MapReduce论文及MIT相关实验总结/fault_tolerate.jpeg","hash":"9e3c94780821eca04ee81ea05f4ea4a31bfcb4ae","modified":1622284000417},{"_id":"public/2021/05/29/MapReduce论文及MIT相关实验总结/invert_index.jpeg","hash":"88165c7dda3e5ba633b906ddcbdb22cc482e7249","modified":1622284000417},{"_id":"source/_posts/Manjaro安装配置踩坑.md","hash":"e3c27adc035e357270bbee32a55b55fbdba3bceb","modified":1622723122712},{"_id":"public/2021/06/02/Manjaro安装配置踩坑/index.html","hash":"b3f1f273db489a5c4e81a0e47a253d837e394804","modified":1622723144666},{"_id":"public/archives/2021/06/index.html","hash":"9d0eb94a99099301da29291c8eaf526f20137fdb","modified":1622723067863},{"_id":"source/about/me.md","hash":"b5e9649f19932c716529c0bba9debd82e59d5363","modified":1716372882836}],"Category":[],"Data":[],"Page":[{"title":"About me","date":"2024-05-22T10:14:42.000Z","_content":"","source":"about/me.md","raw":"---\ntitle: About me\ndate: 2024-05-22 18:14:42\n---\n","updated":"2024-05-22T10:14:42.836Z","path":"about/me.html","_id":"clwho3kbx0000jjpd7t51g7j9","comments":1,"layout":"page","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2021-04-24T14:35:10.905Z","updated":"2021-04-24T14:35:10.905Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cknwg9oij00002kfe3m3r7a13","content":"<p>Welcome to <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/\" >Hexo</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>! This is your very first post. Check <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/\" >documentation</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span> for more info. If you get any problems when using Hexo, you can find the answer in <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/troubleshooting.html\" >troubleshooting</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span> or you can ask me on <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://github.com/hexojs/hexo/issues\" >GitHub</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>.</p>\n\n        <h2 id=\"Quick-Start\"   >\n          <a href=\"#Quick-Start\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2>\n      \n        <h3 id=\"Create-a-new-post\"   >\n          <a href=\"#Create-a-new-post\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3>\n      <figure class=\"highlight bash\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></div></figure>\n\n<p>More info: <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/writing.html\" >Writing</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h3 id=\"Run-server\"   >\n          <a href=\"#Run-server\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3>\n      <figure class=\"highlight bash\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></div></figure>\n\n<p>More info: <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/server.html\" >Server</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h3 id=\"Generate-static-files\"   >\n          <a href=\"#Generate-static-files\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3>\n      <figure class=\"highlight bash\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></div></figure>\n\n<p>More info: <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/generating.html\" >Generating</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h3 id=\"Deploy-to-remote-sites\"   >\n          <a href=\"#Deploy-to-remote-sites\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3>\n      <figure class=\"highlight bash\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></div></figure>\n\n<p>More info: <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/one-command-deployment.html\" >Deployment</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/\" >Hexo</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>! This is your very first post. Check <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/\" >documentation</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span> for more info. If you get any problems when using Hexo, you can find the answer in <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/troubleshooting.html\" >troubleshooting</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span> or you can ask me on <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://github.com/hexojs/hexo/issues\" >GitHub</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>.</p>\n\n        <h2 id=\"Quick-Start\"   >\n          <a href=\"#Quick-Start\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2>\n      \n        <h3 id=\"Create-a-new-post\"   >\n          <a href=\"#Create-a-new-post\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3>\n      <figure class=\"highlight bash\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></div></figure>\n\n<p>More info: <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/writing.html\" >Writing</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h3 id=\"Run-server\"   >\n          <a href=\"#Run-server\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3>\n      <figure class=\"highlight bash\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></div></figure>\n\n<p>More info: <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/server.html\" >Server</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h3 id=\"Generate-static-files\"   >\n          <a href=\"#Generate-static-files\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3>\n      <figure class=\"highlight bash\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></div></figure>\n\n<p>More info: <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/generating.html\" >Generating</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h3 id=\"Deploy-to-remote-sites\"   >\n          <a href=\"#Deploy-to-remote-sites\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3>\n      <figure class=\"highlight bash\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></div></figure>\n\n<p>More info: <span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://hexo.io/docs/one-command-deployment.html\" >Deployment</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n"},{"title":"Linux系统安装配置初探","date":"2021-05-27T15:47:26.000Z","_content":"\n## 一、网卡驱动问题\n\n新拿到一台微星的十代主机，是实验室学长留下的，但这台主机的遗留问题是无法上网。\n\n学长研究后定位问题应该是网卡驱动与网卡不匹配造成的（在stack overflow上发现使用相同网卡会出现类似问题）。\n\n关键问题在于：刚装的Linux系统除了网卡和驱动外，不包含gcc、make等编译套件，这就形成了环形依赖——\n\n- 从网上下载的驱动源码因为没有make不能安装\n- gcc等工具的常见安装方法 ```apt get``` 需要联网才能使用\n\n#### 尝试过程：\n\n- 尝试使用ubuntu启动盘中自带的gcc等组件作为 ```apt get``` 的源，而不是通过网络下载。[具体参考](\"https://blog.csdn.net/weixin_36452379/article/details/116906829\")。但尝试后无法成功，怀疑原因可能是ubuntu桌面版不包含gcc等组件，而博客中的解决的是ubuntu server版的问题。由于重新下载server版，制作启动盘等过程较慢，也没有自己的U盘，因此没有继续尝试重装server版。\n- 尝试离线安装gcc。没有gcc是无法离线安装网卡驱动的根源，但gcc的离线安装非常困难，需要预装大量依赖，而每个依赖的安装又可能需要其他很多依赖，可能会遇到循环依赖的问题。[具体参考](\"https://blog.csdn.net/weixin_42432439/article/details/108777302?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-8&spm=1001.2101.3001.4242\")。由于过程繁复，成功率低，没有尝试。\n\n#### 最终解决：\n\n最终经同学介绍我发现，电脑可以通过USB数据线连接手机，使用手机的共享网络。[具体参考](\"https://jingyan.baidu.com/article/5552ef47a4a14c518ffbc99b.html\")。连接成功后ubuntu右上角出现网络连接的图标，可在命令行中查看网络设备。\n\n于是，安装了基本的开发工具后，又顺利的安装了网卡对应的驱动（安装驱动[具体参考](\"https://blog.csdn.net/hellohake/article/details/109908363\")），通过```ifconfig``` 查看网络连接状态，可发现以太网连接成功，至此，无法上网的问题全部解决。\n\n#### 知识总结：\n\n- 面对网络故障且缺少其他资源时，应首先尝试其他联网方法，包括wifi网卡，usb共享网络的方法等。\n- 在linux kernel中会自带网卡驱动模块，包含了常用网卡的驱动源码，最近的内核版本中都包含了r8169模块，ubuntu20.04的kernel版本为5.8.0，可通过```uname```命令查看。\n- 设备管理的命令包括：```lspci -vv```   ```lsmod```  等，驱动相关命令有 ```insmod```。\n\n\n\n## 二、重装系统过程\n\n使用 ```dd``` 命令制作Linux系统启动盘。[具体参考](\"https://www.dreamoftime0.com/2018/09/25/linux下使用dd命令制作启动盘/\")。\n\n","source":"_posts/Linux系统安装配置初探.md","raw":"---\ntitle: Linux系统安装配置初探\ndate: 2021-05-27 23:47:26\ntags:\n---\n\n## 一、网卡驱动问题\n\n新拿到一台微星的十代主机，是实验室学长留下的，但这台主机的遗留问题是无法上网。\n\n学长研究后定位问题应该是网卡驱动与网卡不匹配造成的（在stack overflow上发现使用相同网卡会出现类似问题）。\n\n关键问题在于：刚装的Linux系统除了网卡和驱动外，不包含gcc、make等编译套件，这就形成了环形依赖——\n\n- 从网上下载的驱动源码因为没有make不能安装\n- gcc等工具的常见安装方法 ```apt get``` 需要联网才能使用\n\n#### 尝试过程：\n\n- 尝试使用ubuntu启动盘中自带的gcc等组件作为 ```apt get``` 的源，而不是通过网络下载。[具体参考](\"https://blog.csdn.net/weixin_36452379/article/details/116906829\")。但尝试后无法成功，怀疑原因可能是ubuntu桌面版不包含gcc等组件，而博客中的解决的是ubuntu server版的问题。由于重新下载server版，制作启动盘等过程较慢，也没有自己的U盘，因此没有继续尝试重装server版。\n- 尝试离线安装gcc。没有gcc是无法离线安装网卡驱动的根源，但gcc的离线安装非常困难，需要预装大量依赖，而每个依赖的安装又可能需要其他很多依赖，可能会遇到循环依赖的问题。[具体参考](\"https://blog.csdn.net/weixin_42432439/article/details/108777302?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-8&spm=1001.2101.3001.4242\")。由于过程繁复，成功率低，没有尝试。\n\n#### 最终解决：\n\n最终经同学介绍我发现，电脑可以通过USB数据线连接手机，使用手机的共享网络。[具体参考](\"https://jingyan.baidu.com/article/5552ef47a4a14c518ffbc99b.html\")。连接成功后ubuntu右上角出现网络连接的图标，可在命令行中查看网络设备。\n\n于是，安装了基本的开发工具后，又顺利的安装了网卡对应的驱动（安装驱动[具体参考](\"https://blog.csdn.net/hellohake/article/details/109908363\")），通过```ifconfig``` 查看网络连接状态，可发现以太网连接成功，至此，无法上网的问题全部解决。\n\n#### 知识总结：\n\n- 面对网络故障且缺少其他资源时，应首先尝试其他联网方法，包括wifi网卡，usb共享网络的方法等。\n- 在linux kernel中会自带网卡驱动模块，包含了常用网卡的驱动源码，最近的内核版本中都包含了r8169模块，ubuntu20.04的kernel版本为5.8.0，可通过```uname```命令查看。\n- 设备管理的命令包括：```lspci -vv```   ```lsmod```  等，驱动相关命令有 ```insmod```。\n\n\n\n## 二、重装系统过程\n\n使用 ```dd``` 命令制作Linux系统启动盘。[具体参考](\"https://www.dreamoftime0.com/2018/09/25/linux下使用dd命令制作启动盘/\")。\n\n","slug":"Linux系统安装配置初探","published":1,"updated":"2021-05-27T15:48:55.739Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckp72ntmx000028wuci4ig3z4","content":"\n        <h2 id=\"一、网卡驱动问题\"   >\n          <a href=\"#一、网卡驱动问题\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#一、网卡驱动问题\" class=\"headerlink\" title=\"一、网卡驱动问题\"></a>一、网卡驱动问题</h2>\n      <p>新拿到一台微星的十代主机，是实验室学长留下的，但这台主机的遗留问题是无法上网。</p>\n<p>学长研究后定位问题应该是网卡驱动与网卡不匹配造成的（在stack overflow上发现使用相同网卡会出现类似问题）。</p>\n<p>关键问题在于：刚装的Linux系统除了网卡和驱动外，不包含gcc、make等编译套件，这就形成了环形依赖——</p>\n<ul>\n<li>从网上下载的驱动源码因为没有make不能安装</li>\n<li>gcc等工具的常见安装方法 <code>apt get</code> 需要联网才能使用</li>\n</ul>\n\n        <h4 id=\"尝试过程：\"   >\n          <a href=\"#尝试过程：\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#尝试过程：\" class=\"headerlink\" title=\"尝试过程：\"></a>尝试过程：</h4>\n      <ul>\n<li>尝试使用ubuntu启动盘中自带的gcc等组件作为 <code>apt get</code> 的源，而不是通过网络下载。<a href=\"%22https://blog.csdn.net/weixin_36452379/article/details/116906829%22\">具体参考</a>。但尝试后无法成功，怀疑原因可能是ubuntu桌面版不包含gcc等组件，而博客中的解决的是ubuntu server版的问题。由于重新下载server版，制作启动盘等过程较慢，也没有自己的U盘，因此没有继续尝试重装server版。</li>\n<li>尝试离线安装gcc。没有gcc是无法离线安装网卡驱动的根源，但gcc的离线安装非常困难，需要预装大量依赖，而每个依赖的安装又可能需要其他很多依赖，可能会遇到循环依赖的问题。<a href=\"%22https://blog.csdn.net/weixin_42432439/article/details/108777302?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-8&spm=1001.2101.3001.4242%22\">具体参考</a>。由于过程繁复，成功率低，没有尝试。</li>\n</ul>\n\n        <h4 id=\"最终解决：\"   >\n          <a href=\"#最终解决：\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#最终解决：\" class=\"headerlink\" title=\"最终解决：\"></a>最终解决：</h4>\n      <p>最终经同学介绍我发现，电脑可以通过USB数据线连接手机，使用手机的共享网络。<a href=\"%22https://jingyan.baidu.com/article/5552ef47a4a14c518ffbc99b.html%22\">具体参考</a>。连接成功后ubuntu右上角出现网络连接的图标，可在命令行中查看网络设备。</p>\n<p>于是，安装了基本的开发工具后，又顺利的安装了网卡对应的驱动（安装驱动<a href=\"%22https://blog.csdn.net/hellohake/article/details/109908363%22\">具体参考</a>），通过<code>ifconfig</code> 查看网络连接状态，可发现以太网连接成功，至此，无法上网的问题全部解决。</p>\n\n        <h4 id=\"知识总结：\"   >\n          <a href=\"#知识总结：\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#知识总结：\" class=\"headerlink\" title=\"知识总结：\"></a>知识总结：</h4>\n      <ul>\n<li>面对网络故障且缺少其他资源时，应首先尝试其他联网方法，包括wifi网卡，usb共享网络的方法等。</li>\n<li>在linux kernel中会自带网卡驱动模块，包含了常用网卡的驱动源码，最近的内核版本中都包含了r8169模块，ubuntu20.04的kernel版本为5.8.0，可通过<code>uname</code>命令查看。</li>\n<li>设备管理的命令包括：<code>lspci -vv</code>   <code>lsmod</code>  等，驱动相关命令有 <code>insmod</code>。</li>\n</ul>\n\n        <h2 id=\"二、重装系统过程\"   >\n          <a href=\"#二、重装系统过程\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#二、重装系统过程\" class=\"headerlink\" title=\"二、重装系统过程\"></a>二、重装系统过程</h2>\n      <p>使用 <code>dd</code> 命令制作Linux系统启动盘。<a href=\"%22https://www.dreamoftime0.com/2018/09/25/linux%E4%B8%8B%E4%BD%BF%E7%94%A8dd%E5%91%BD%E4%BB%A4%E5%88%B6%E4%BD%9C%E5%90%AF%E5%8A%A8%E7%9B%98/%22\">具体参考</a>。</p>\n","site":{"data":{}},"excerpt":"","more":"\n        <h2 id=\"一、网卡驱动问题\"   >\n          <a href=\"#一、网卡驱动问题\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#一、网卡驱动问题\" class=\"headerlink\" title=\"一、网卡驱动问题\"></a>一、网卡驱动问题</h2>\n      <p>新拿到一台微星的十代主机，是实验室学长留下的，但这台主机的遗留问题是无法上网。</p>\n<p>学长研究后定位问题应该是网卡驱动与网卡不匹配造成的（在stack overflow上发现使用相同网卡会出现类似问题）。</p>\n<p>关键问题在于：刚装的Linux系统除了网卡和驱动外，不包含gcc、make等编译套件，这就形成了环形依赖——</p>\n<ul>\n<li>从网上下载的驱动源码因为没有make不能安装</li>\n<li>gcc等工具的常见安装方法 <code>apt get</code> 需要联网才能使用</li>\n</ul>\n\n        <h4 id=\"尝试过程：\"   >\n          <a href=\"#尝试过程：\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#尝试过程：\" class=\"headerlink\" title=\"尝试过程：\"></a>尝试过程：</h4>\n      <ul>\n<li>尝试使用ubuntu启动盘中自带的gcc等组件作为 <code>apt get</code> 的源，而不是通过网络下载。<a href=\"%22https://blog.csdn.net/weixin_36452379/article/details/116906829%22\">具体参考</a>。但尝试后无法成功，怀疑原因可能是ubuntu桌面版不包含gcc等组件，而博客中的解决的是ubuntu server版的问题。由于重新下载server版，制作启动盘等过程较慢，也没有自己的U盘，因此没有继续尝试重装server版。</li>\n<li>尝试离线安装gcc。没有gcc是无法离线安装网卡驱动的根源，但gcc的离线安装非常困难，需要预装大量依赖，而每个依赖的安装又可能需要其他很多依赖，可能会遇到循环依赖的问题。<a href=\"%22https://blog.csdn.net/weixin_42432439/article/details/108777302?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-8&spm=1001.2101.3001.4242%22\">具体参考</a>。由于过程繁复，成功率低，没有尝试。</li>\n</ul>\n\n        <h4 id=\"最终解决：\"   >\n          <a href=\"#最终解决：\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#最终解决：\" class=\"headerlink\" title=\"最终解决：\"></a>最终解决：</h4>\n      <p>最终经同学介绍我发现，电脑可以通过USB数据线连接手机，使用手机的共享网络。<a href=\"%22https://jingyan.baidu.com/article/5552ef47a4a14c518ffbc99b.html%22\">具体参考</a>。连接成功后ubuntu右上角出现网络连接的图标，可在命令行中查看网络设备。</p>\n<p>于是，安装了基本的开发工具后，又顺利的安装了网卡对应的驱动（安装驱动<a href=\"%22https://blog.csdn.net/hellohake/article/details/109908363%22\">具体参考</a>），通过<code>ifconfig</code> 查看网络连接状态，可发现以太网连接成功，至此，无法上网的问题全部解决。</p>\n\n        <h4 id=\"知识总结：\"   >\n          <a href=\"#知识总结：\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#知识总结：\" class=\"headerlink\" title=\"知识总结：\"></a>知识总结：</h4>\n      <ul>\n<li>面对网络故障且缺少其他资源时，应首先尝试其他联网方法，包括wifi网卡，usb共享网络的方法等。</li>\n<li>在linux kernel中会自带网卡驱动模块，包含了常用网卡的驱动源码，最近的内核版本中都包含了r8169模块，ubuntu20.04的kernel版本为5.8.0，可通过<code>uname</code>命令查看。</li>\n<li>设备管理的命令包括：<code>lspci -vv</code>   <code>lsmod</code>  等，驱动相关命令有 <code>insmod</code>。</li>\n</ul>\n\n        <h2 id=\"二、重装系统过程\"   >\n          <a href=\"#二、重装系统过程\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#二、重装系统过程\" class=\"headerlink\" title=\"二、重装系统过程\"></a>二、重装系统过程</h2>\n      <p>使用 <code>dd</code> 命令制作Linux系统启动盘。<a href=\"%22https://www.dreamoftime0.com/2018/09/25/linux%E4%B8%8B%E4%BD%BF%E7%94%A8dd%E5%91%BD%E4%BB%A4%E5%88%B6%E4%BD%9C%E5%90%AF%E5%8A%A8%E7%9B%98/%22\">具体参考</a>。</p>\n"},{"title":"MapReduce论文及MIT相关实验总结","date":"2021-05-29T10:47:26.000Z","_content":"\n\n本文分四个部分，将从MapReduce论文讲起，分析项目代码是如何实现简化版的MapReduce框架，最后讲述实验内容的完成过程和总结反思。\n\n\n## 一、MapReduce论文理解与回顾\n\nMapReduce是一个用于处理大规模数据的分布式计算框架。分布式计算框架往往看重灵活易使用的前端，和高性能可拓展的后端，这在图计算和深度学习领域也是如此。而对MapReduce这个处理大规模同质数据的框架来说，应该从两方面来理解：一是它为程序员提供了什么样的抽象，给上层编程人员提供了什么样的编程模型，即编程时对此系统功能和性质的认识；二是它内部是如何实现，从而为上层提供多种支持和保证。\n\n### Section 2: Programming Model\n\n编程模型是这篇工作最突出的贡献，它所解决的“重要的问题”在于给各种大规模计算在分布式编程时提供了便利。\n\n> Users specify a *map* function that processes a key/value pair to generate a set of intermediate key/value pairs, and a *reduce* function that merges all intermediate values associated with the same intermediate key.\n>\n> ```\n> map    (k1,v1)        → list(k2,v2)\n> reduce (k2,list(v2))  → list(v2)\n> ```\n>\n> the input keys and values are drawn from a different domain than the output keys and values. Furthermore, the intermediate keys and values are from the same do- main as the output keys and values.\n>\n> Our C++ implementation passes strings to and from the user-defined functions and leaves it to the user code to convert between strings and appropriate types.\n\n上面选取的是论文中Section 2的内容，主要明确用户定义的Map和Reduce函数的外在表现和要求（如键值对的域）。而要真正应用MapReduce框架，还需要对MapReduce的语义有更直观的理解，可参考论文Section 2.3部分。简单来说，一个任务是否适合使用MapReduce模型来解决，需要看是否满足以下两点要求：\n\n- 计算的数据规模大，需要利用并行与分布式计算来加速\n- 计算任务之间没有依赖，没有先后顺序关系，任务完成的先后顺序对结果没有影响（操作元满足交换律）\n\n当然，在云计算繁荣发展的今天，关于MapReduce模型的优化在学术界备受关注，最近的一篇工作提出用符号执行的方法破除顺序依赖，使MapReduce框架也能加速存在计算先后顺序的计算过程。\n\n### Section 3: Implementation\n\n框架实现是这篇工作的实际困难与巧妙解法，系统软件要做的就是将简单留给用户，复杂性留给自己。\n\n> As a reaction to this complexity, we designed a new abstraction that allows us to express the simple computa- tions we were trying to perform but hides the messy de- tails of parallelization, fault-tolerance, data distribution and load balancing in a library.\n>\n> The run-time system takes care of the details of partitioning the input data, scheduling the program’s execution across a set of machines, handling ma- chine failures, and managing the required inter-machine communication.\n\n#### 3.1 **Execution Overview**\n\n分布式计算任务的完成是一个框架首先考虑的事，理解执行过程才能理解分布式编程的一般思路（对实验的完成也很有帮助），其次才是容错、性能等方面，因此这里将引用论文中关于执行过程的全部说明。执行过程如下图所示：\n\n{% asset_img exec_overview.png %}\n\n> 1. The MapReduce library in the user program first splits the input files into M pieces of typically 16 megabytes to 64 megabytes (MB) per piece (con- trollable by the user via an optional parameter). It then starts up many copies of the program on a clus- ter of machines.\n> 2. One of the copies of the program is special – the master. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.\n> 3. A worker who is assigned a map task reads the contents of the corresponding input split. It parses key/value pairs out of the input data and passes each pair to the user-defined *Map* function. The interme- diate key/value pairs produced by the *Map* function are buffered in memory.\n> 4. Periodically, **the buffered pairs are written to local disk, partitioned into R regions by the partitioning function.** The locations of these buffered pairs on the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers.\n> 5. When a reduce worker is notified by the master about these locations, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all in- termediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. **If the amount of intermediate data is too large to fit in memory, an external sort is used.**\n> 6. The reduce worker iterates over the sorted interme- diate data and for each unique intermediate key en- countered, **it passes the key and the corresponding set of intermediate values to the user’s *Reduce* func- tion.** The output of the *Reduce* function is appended to a final output file for this reduce partition.\n> 7. When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user pro- gram returns back to the user code.\n\n以上过程标号与图中标号对应，文字加粗部分是个人认为需要着重记忆的或“smart”的实现。\n\n#### 3.x Other Problem in Distributed Systems\n\nSection 3的其他内容将在以下做简要概括：\n\n- **Master Data Structures：**Master是整个MapReduce过程的管理者，是Worker间通讯的线人，它将保存任务的状态，以及文件内容在文件系统中的位置等。\n- **Fault Tolerance：**\n  - Worker是无状态的，任意宕机的Worker上完成的任务可被其他Worker重做。\n  - Master只有一个，宕机的可能性很小，因此若Master宕机则MapReduce任务失败，交给应用来处理。\n  - 并行与分布式计算的正确性需要通过和可能的顺序执行结果进行比较来衡量。本来每个Worker操作的数据对象是不重叠的，因此不会有并发错误，但Worker宕机导致的任务重做可能会使系统各部分看到的状态不同，这时 ```We rely on atomic commits of map and reduce task outputs to achieve this property.``` 包括两点：1. Map任务的完成由唯一的Master来仲裁；2. 底层的分布式文件系统提供rename的原子性来保证reduce输出唯一。\n- **Locality：**任务调度要考虑局部性，避免数据的网络传输。实际上这点在大型分布式系统中非常重要！\n- **Task Granularity**：理论上任务粒度越细越好， ```Having each worker perform many different tasks improves dynamic load balancing, and also speeds up recovery when a worker fails: the many map tasks it has completed can be spread out across all the other worker machines.``` 但现实能够支持的调度数量是有限的，请记住以下数字：```We often per- form MapReduce computations with M = 200, 000 and R = 5, 000, using 2,000 worker machines.```\n- **Backup Tasks：**木桶效应，分布式问题就像是管理问题，是调度问题。不同的机器能力不同，快的得等慢的，当然管机器比管人要容易的多。这里举李沐（交大学长，亚马逊CTO，分布式深度学习框架）的[五年工作感悟](https://zhuanlan.zhihu.com/p/374777591?utm_source=qq&utm_medium=social&utm_oi=989596755247349760)。 ```When a MapReduce operation is close to completion, the master schedules backup executions of the remaining *in-progress* tasks.```\n\n以上就是MapReduce论文1到3节的全部内容理解，对于今后把握项目整体思想、分析分布式编程主要问题都有所帮助。\n\n\n\n## 二、MapReduce代码框架分析\n\n实验代码MapReduce是由MIT设计实现的用于教学的简化版本，通过此版本可以更好的理解上述编程模型和底层执行过程。我们的关注点在于`wc.go`中的由我们定义的map和reduce函数，以及`mapreduce`包中的所有内容。\n\n```go\nfunc main() {\n\tif len(os.Args) < 4 {\n\t\tfmt.Printf(\"%s: see usage comments in file\\n\", os.Args[0])\n\t} else if os.Args[1] == \"master\" {\n\t\tvar mr *mapreduce.Master\n\t\tif os.Args[2] == \"sequential\" {\n\t\t\tmr = mapreduce.Sequential(\"wcseq\", os.Args[3:], 3, mapF, reduceF)\n\t\t} else {\n\t\t\tmr = mapreduce.Distributed(\"wcseq\", os.Args[3:], 3, os.Args[2])\n\t\t}\n\t\tmr.Wait()\n\t} else {\n\t\tmapreduce.RunWorker(os.Args[2], os.Args[3], mapF, reduceF, 100, nil)\n\t}\n}\n```\n\n上面展示了`wc.go`中的`main`函数的内容。与论文附录中展示的代码类似，用户通过指定自定义的map和reduce函数，构造特殊的数据结构（实验中是传多个参数）作为`MapReduce`函数的调用参数来开始一项MapReduce任务。在实验代码实现的MapReduce框架中，`mapreduce.Sequential` 和 `mapreduce.Distributed` 是 *MapReduce* 对外提供的两个接口。由于正确实现的MapReduce框架可以与顺序执行产生同样的结果，实验代码设计了顺序执行的`mapreduce.Sequential`来方便我们调试，以及在编写用户map和reduce函数时加深对程序行为的认识。\n\n### 1. 首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\n\n由于真实的分布式计算框架只需提供 `mapreduce.Distributed` 即可，我们首先分析用户主函数通过 `mapreduce.Distributed` 的调用能否完成分布式计算任务。\n\n `mapreduce.Distributed` 调用层次图如下：`run`中的`schedule`是由`distribute`传入的。\n\n```\nmain\n｜—— Distributed\n    ｜—— newMaster\n    ｜—— mr.startRPCServer\n    ｜—— go mr.run\n        ｜—— schedule(mapPhase)\n            ｜—— go mr.forwardRegistrations(ch)\n            ｜—— schedule(mr.jobName, mr.files, mr.nReduce, mapPhase, ch)\n        \t｜—— go call(reg, \"Worker.DoTask\", ...)\n        ｜—— schedule(reducePhase)\n            ｜—— go mr.forwardRegistrations(ch)\n            ｜—— schedule(mr.jobName, mr.files, mr.nReduce, reducePhase, ch)\n        \t｜—— go call(reg, \"Worker.DoTask\", ...)\n        ｜—— mr.merge()\n        ｜—— mr.doneChannel <- true\n        ｜—— mr.killWorkers\n        ｜—— mr.stopRPCServer\n｜—— mr.Wait()\n```\n\n分析调用路径后，奇怪的是，整个调用过程没有Worker的参与，即使Master声明了RPC，也没有Worker注册。**也就是说，用户不能仅通过 `mapreduce.Distributed` 的调用完成分布式并行计算任务，而需要`mapreduce.RunWorker`的配合，这与论文附录中的接口区别较大**。\n\n那我们自定义的map和reduce函数在测试时并没有并行计算吗？是的。\n\n\n```shell\n#!/bin/bash\ngo run wc.go master sequential pg-*.txt\nsort -n -k2 mrtmp.wcseq | tail -10 | diff - mr-testout.txt > diff.out\nif [ -s diff.out ]\nthen\necho \"Failed test. Output should be as in mr-testout.txt. Your output differs as follows (from diff.out):\" > /dev/stderr\n  cat diff.out\nelse\n  echo \"Passed test\" > /dev/stderr\nfi\n```\n\n上面展示了`test_wc.sh`中的内容，另外查看` test_ii.sh`以及`test_mr.sh`两个测试文件后，可以看出我们自己编写的两套map和reduce函数只运行在`sequential`模式下，这是很令人失望的。考察`RunWorker`函数的被调用情况，只有`test_test.go`中调用过，当然了，测试的执行和main的执行也没有本质的区别啦。。\n\n### 2. 更重要的，从面向对象的角度分析如何从零构建MapReduce框架\n\n思考论文中Section 3的执行过程概述以及Master数据结构部分，我们要怎样在单机多核上实现并行计算呢？那我们可以用多线程模拟Master和Worker。\n\n- Master管理MapReduce任务，记录整个任务的元数据（任务名、Map个数、Reduce个数等），实现数据集划分和任务调度的策略，负责与Worker通信进行任务分发（需要Master和Worker间制定协议），对Reduce的结果进行合并。\n\n- Worker负责map和reduce的执行，将用户定义的map和reduce函数应用在数据集上得到结果（结果在文件系统上共享需要协议）。\n\n上面是论文中的要求，作为简化，实验代码中Master并未实现数据集的划分，而是需要用户划分后通过文件指定Map的数量（其实在论文附录的代码中也是这样做的）。\n\n用go语言实现是相对简单的，任务分发用RPC库，状态监视用goroutine加通道、信号量。mapreduce包中的每个文件都分工明确，整体上实验代码非常清晰、整洁。\n\n\n\n\n## 三、实验问题的解决思路和代码实现\n\n#### 实验整体解决思路\n\n实验问题整体上并不复杂，解决思路实际上只要阅读代码，找到该函数被调用的语境，结合论文和实验文档理解函数需要完成的任务，对整个包内容即自己可以使用的现有资源有充分的认识，以及阅读注释和文档掌握编程细节和go语言库函数即可。不同部分的具体要求不同，思考的领域维度也不相同，但只要根据实验步骤，循序渐进，就会发现实验就像一个个puzzle一样，以阅读、理解、填空为主，既不会让人灰心丧气，还享受到克服困难、学习新语言的成就感。\n\n实现过程中，我并没有碰到太多Bug，让人印象深刻的是Part I的 `doReduce` 函数，以及Part III的 `schedule` 函数的Bug。\n\n### Part I: Map/Reduce input and output\n\n这一部分要求实现的是 `commen_map.go` 中的 `doMap` 函数和`commen_reduce.go` 中的 `doReduce` 函数。\n\n`doMap` 函数：该函数的功能是完成单个给定的mapTask。其主要执行过程如下：\n\n- 创建中间键值文件，创建相应的`json.Encoder`\n- 读入map任务的输入文件内容，用`ioutil.ReadFile()`，然后调用map函数得到中间键值对\n- 对键算哈希，确定键值对要写入的文件，然后以json格式写入\n\n```go\nfunc doMap(\n   jobName string, // the name of the MapReduce job\n   mapTask int, // which map task this is\n   inFile string,\n   nReduce int, // the number of reduce task that will be run (\"R\" in the paper)\n   mapF func(filename string, contents string) []KeyValue,\n) {\n   \n   interFiles := make([]*os.File, nReduce)\n   encoders := make([]*json.Encoder, nReduce)\n   for i := 0; i < nReduce; i++ {\n      interFile, err := os.Create(reduceName(jobName, mapTask, i))\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n      interFiles[i] = interFile\n      encoders[i] = json.NewEncoder(interFile)\n   }\n\n   inputFile, err := ioutil.ReadFile(inFile)\n   if err != nil {\n      log.Fatal(\"check: \", err)\n   }\n   inputKeyValue := mapF(inFile, string(inputFile[:]))\n\n   for _, _KeyValue := range inputKeyValue {\n      index := ihash(_KeyValue.Key) % nReduce\n      err = encoders[index].Encode(&_KeyValue)\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n   }\n\n   for i := 0; i < nReduce; i++ {\n      err = interFiles[i].Close()\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n   }\n}\n```\n\n`doReduce` 函数：该函数用来完成单个给定的reduceTask。其执行过程如下：\n\n- 收集由它负责的键值对，读出文件中用json编码的键值对：如注释中所述对一个文件不断decode直到报错为止\n- 按键排序，即把相同键的键值对聚集到一起\n- 创建输出文件，创建对应的`json.Encoder`\n- 通过键的变化把相同键的所有值形成字符串数组，调用reduce函数得到结果，写入文件中\n\n```go\nfunc doReduce(\n   jobName string, // the name of the whole MapReduce job\n   reduceTask int, // which reduce task this is\n   outFile string, // write the output here\n   nMap int, // the number of map tasks that were run (\"M\" in the paper)\n   reduceF func(key string, values []string) string,\n) {\n\n   var KeyValues []KeyValue\n   for i := 0; i < nMap; i++ {\n      interFile, err := os.Open(reduceName(jobName, i, reduceTask))\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n      decoder := json.NewDecoder(interFile)\n      for {\n         var kv KeyValue\n         err = decoder.Decode(&kv)\n         if err != nil {\n            break\n         }\n         KeyValues = append(KeyValues, kv)\n      }\n      err = interFile.Close()\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n   }\n\n   sort.Slice(KeyValues, func(i, j int) bool {return KeyValues[i].Key < KeyValues[j].Key})\n\n   outputFile, err := os.Create(outFile)\n   if err != nil {\n      log.Fatal(\"check: \", err)\n   }\n   encoder := json.NewEncoder(outputFile)\n\n   var values []string\n   var key string\n   if len(KeyValues) > 0 {\n      key = KeyValues[0].Key\n      for _, kv := range KeyValues {\n         if kv.Key == key {\n            values = append(values, kv.Value)\n         } else {\n            err = encoder.Encode(KeyValue{key, reduceF(key, values)})\n            if err != nil {\n               log.Fatal(\"check: \", err)\n            }\n            values = make([]string, 0)\n            values = append(values, kv.Value)\n            key = kv.Key\n         }\n      }\n\n      err = encoder.Encode(KeyValue{key, reduceF(key, values)})\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n   }\n\n   err = outputFile.Close()\n   if err != nil {\n      log.Fatal(\"check: \", err)\n   }\n}\n```\n\n\n\n\n### Part II: Single-worker word count\n\n这部分要仿照论文中示例给出自定义函数，也就是map处理输入的字符串对其中的每个单词输出中间键值对，因为中间键值对的值都是1所以reduce直接算中间值数组长度即可。\n\n本以为字符串处理和判断单词是个难事，点开文档链接一看就会了，甚至字符串转换都贴心的写好了参考。\n\n```go\nfunc mapF(filename string, contents string) []mapreduce.KeyValue {\n   // Your code here (Part II).\n   f := func(c rune) bool {\n      return !unicode.IsLetter(c)\n   }\n\n   words := strings.FieldsFunc(contents, f)\n   var KeyValues []mapreduce.KeyValue\n   for _, word := range words {\n      KeyValues = append(KeyValues, mapreduce.KeyValue{word, \"1\"})\n   }\n   return KeyValues\n}\n\nfunc reduceF(key string, values []string) string {\n   // Your code here (Part II).\n   return strconv.Itoa(len(values))\n}\n```\n\n\n\n### Part III: Distributing MapReduce tasks\n\n这部分是要上手并行计算了。也是实验中最有趣的部分，涉及go语言通道和信号量的使用。\n\n- 已知我们就是要调RPC，RPC不能阻塞因此要用go routine开协程来监视调用情况。\n- RPC中参数构建较简单，弄清楚通道里的Worker address是怎么来的就会用了。已知Worker `DoTask` 结束后不会再次注册，因此RPC返回后要将该Worker重新放入通道。\n- 使用`sync.WaitGroup` 来同步所有RPC的结束。\n\n这里遇到了一个很关键的bug: `wg.done()` 和 `registerChan <- worker` 这两句写反了。这就出现了输出中显示map task都做完了但就是无法输出`Schedule: mapPhase done` 这句话。说明主线程被阻塞住了，为什么呢？因为这个`registerChan` 通道是没有缓冲区的，也就是通道中最多只有一个值，再往进放就会阻塞住。于是产生了如下循环依赖：\n\n- 主线程在等所有协程`wg.done()` \n- 完成任务的协程在等主线程开新的协程消费通道中的内容，才好把信号放进通道中\n\n***我个人认为在创建通道时给通道声明task数量的缓冲区会更好，因为这样协程才会顺利退出，否则飘着的协程虽不影响主线程接下来的执行，但浪费内存空间，而且调度时会浪费CPU时间。***\n\n修改顺序后，打破循环依赖，就顺利通过测试了～\n\n```go\nfunc schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, registerChan chan string) {\n   var ntasks int\n   var n_other int // number of inputs (for reduce) or outputs (for map)\n   switch phase {\n   case mapPhase:\n      ntasks = len(mapFiles)\n      n_other = nReduce\n   case reducePhase:\n      ntasks = nReduce\n      n_other = len(mapFiles)\n   }\n\n   fmt.Printf(\"Schedule: %v %v tasks (%d I/Os)\\n\", ntasks, phase, n_other)\n\n   // All ntasks tasks have to be scheduled on workers. Once all tasks\n   // have completed successfully, schedule() should return.\n   //\n   // Your code here (Part III, Part IV).\n   //\n   var wg sync.WaitGroup\n   wg.Add(ntasks)\n   for i := 0; i < ntasks; i++ {\n      taskNumber := i\n      go func() {\n         var worker string\n         for {\n            reg := <-registerChan\n            result := call(reg, \"Worker.DoTask\", DoTaskArgs{\n               JobName:       jobName,\n               File:          mapFiles[taskNumber],\n               Phase:         phase,\n               TaskNumber:    taskNumber,\n               NumOtherPhase: n_other,\n            }, nil)\n            if result == true {\n               worker = reg\n               break\n            }\n         }\n         wg.Done()\n         registerChan <- worker\n      }()\n   }\n   wg.Wait()\n   fmt.Printf(\"Schedule: %v done\\n\", phase)\n}\n```\n\n\n\n### Part IV: Handling worker failures\n\n此部分只需在上一部分的基础上加上循环，即在RPC失败时选取下一空闲的Worker重做任务，在RPC返回成功时退出即可。\n\n{% asset_img fault_tolerate.jpeg %}\n\n没想到只加了几行就通过测试了，但它确实是这样。\n\n\n\n### Part V: Inverted index generation (OPTIONAL)\n\n这部分要完成倒排索引的建立，其实就是加深对map和reduce函数语义的认识，用它们做更多有意义的事。\n\n{% asset_img invert_index.jpeg %}\n\n如上图所示，黑色是词数统计的过程，蓝色是倒排索引的区别。将生成倒排索引的任务与此前的词数统计做对比，很容易知道该如何改进。\n\n这里关键问题是去除重复，这里选择在reduce阶段做，这样编程更简洁明了，同时很容易证明是正确的。去除重复采用和Part I `doReduce` 中类似的方法，将所有中间value排序，然后统计不同的内容。\n\n```go\nfunc mapF(document string, value string) (res []mapreduce.KeyValue) {\n   // Your code here (Part V).\n   f := func(c rune) bool {\n      return !unicode.IsLetter(c)\n   }\n\n   words := strings.FieldsFunc(value, f)\n   var KeyValues []mapreduce.KeyValue\n   for _, word := range words {\n      KeyValues = append(KeyValues, mapreduce.KeyValue{word, document})\n   }\n   return KeyValues\n}\n\nfunc reduceF(key string, values []string) string {\n   // Your code here (Part V).\n   var reduceValue []string\n   var lastValue string\n   sort.Slice(values, func(i, j int) bool {return values[i] < values[j]})\n   if len(values) > 0 {\n      reduceValue = append(reduceValue, values[0])\n      lastValue = values[0]\n      for _, value := range values {\n         if value != lastValue {\n            reduceValue = append(reduceValue, value)\n            lastValue = value\n         }\n      }\n   }\n   return strconv.Itoa(len(reduceValue)) + \" \" + strings.Join(reduceValue, \",\")\n}\n```\n\n\n\n## 四、实验过程总结与反思\n\n从科研项目的角度看，我越来越理解高校搞科研面对的问题：资源的限制。\n\n- 由MIT设计的这个实验，是运行在单机上的简化版本，作为我们这次云计算课程实验，它与我曾做过的其他众多实验体量类似，也没有实际应用的能力，如果不是作为名校开源的教材，可能没几个人会注意到这份框架实现。\n\n- 这篇分布式场景下的经典工作，出自谷歌。假设MIT先想到搞这样的研究，不与企业合作的话，倒也可以写一个版本，但evaluation没法在真实场景下测只能模拟、调研工作也会比企业的人付出更多更多，最后发论文后也很难有实际项目落地。相比之下，企业做这样的研究就容易很多：Google发论文无数、微软研究院与英特尔是好兄弟，动不动就改硬件发论文、阿里达摩院宣讲时论文的产出等等。\n- 所以，**要与企业良性合作，互利互惠**，做适应工业界当下需求的科研，积极与工业界交流。\n\n\n\n从课程实验的角度看，该实验如果在以下方面作出改进会更好：\n\n1. 简化注释，可将注释内容转移到文档中，以不经意的形式。这次实验注释过于详尽，使同学对很多数据结构的设计都缺乏思考。\n2. 增加问题练习，在文档中增加需要在实验报告中回答的问题，加深同学对重点的理解。不仅能看懂，而且会表达。\n3. 补充测试，这次实验测试过于简单，显然遗漏了某些边界情况，而且Part V自定义函数运行在Sequential模式下（过度简化）。随随便便就过了测试不能让同学们养成编程时缜密的思考方式。\n4. 论文中有`If the amount of intermediate data is too large to fit in memory, an external sort is used.` 这样的描述，迭代器在数据量大时很常用，但如何构造和实现迭代器依然很陌生，如果简化框架能加入迭代器的实现就更好了。\n","source":"_posts/MapReduce论文及MIT相关实验总结.md","raw":"---\ntitle: MapReduce论文及MIT相关实验总结\ndate: 2021-05-29 18:47:26\ntags:\n---\n\n\n本文分四个部分，将从MapReduce论文讲起，分析项目代码是如何实现简化版的MapReduce框架，最后讲述实验内容的完成过程和总结反思。\n\n\n## 一、MapReduce论文理解与回顾\n\nMapReduce是一个用于处理大规模数据的分布式计算框架。分布式计算框架往往看重灵活易使用的前端，和高性能可拓展的后端，这在图计算和深度学习领域也是如此。而对MapReduce这个处理大规模同质数据的框架来说，应该从两方面来理解：一是它为程序员提供了什么样的抽象，给上层编程人员提供了什么样的编程模型，即编程时对此系统功能和性质的认识；二是它内部是如何实现，从而为上层提供多种支持和保证。\n\n### Section 2: Programming Model\n\n编程模型是这篇工作最突出的贡献，它所解决的“重要的问题”在于给各种大规模计算在分布式编程时提供了便利。\n\n> Users specify a *map* function that processes a key/value pair to generate a set of intermediate key/value pairs, and a *reduce* function that merges all intermediate values associated with the same intermediate key.\n>\n> ```\n> map    (k1,v1)        → list(k2,v2)\n> reduce (k2,list(v2))  → list(v2)\n> ```\n>\n> the input keys and values are drawn from a different domain than the output keys and values. Furthermore, the intermediate keys and values are from the same do- main as the output keys and values.\n>\n> Our C++ implementation passes strings to and from the user-defined functions and leaves it to the user code to convert between strings and appropriate types.\n\n上面选取的是论文中Section 2的内容，主要明确用户定义的Map和Reduce函数的外在表现和要求（如键值对的域）。而要真正应用MapReduce框架，还需要对MapReduce的语义有更直观的理解，可参考论文Section 2.3部分。简单来说，一个任务是否适合使用MapReduce模型来解决，需要看是否满足以下两点要求：\n\n- 计算的数据规模大，需要利用并行与分布式计算来加速\n- 计算任务之间没有依赖，没有先后顺序关系，任务完成的先后顺序对结果没有影响（操作元满足交换律）\n\n当然，在云计算繁荣发展的今天，关于MapReduce模型的优化在学术界备受关注，最近的一篇工作提出用符号执行的方法破除顺序依赖，使MapReduce框架也能加速存在计算先后顺序的计算过程。\n\n### Section 3: Implementation\n\n框架实现是这篇工作的实际困难与巧妙解法，系统软件要做的就是将简单留给用户，复杂性留给自己。\n\n> As a reaction to this complexity, we designed a new abstraction that allows us to express the simple computa- tions we were trying to perform but hides the messy de- tails of parallelization, fault-tolerance, data distribution and load balancing in a library.\n>\n> The run-time system takes care of the details of partitioning the input data, scheduling the program’s execution across a set of machines, handling ma- chine failures, and managing the required inter-machine communication.\n\n#### 3.1 **Execution Overview**\n\n分布式计算任务的完成是一个框架首先考虑的事，理解执行过程才能理解分布式编程的一般思路（对实验的完成也很有帮助），其次才是容错、性能等方面，因此这里将引用论文中关于执行过程的全部说明。执行过程如下图所示：\n\n{% asset_img exec_overview.png %}\n\n> 1. The MapReduce library in the user program first splits the input files into M pieces of typically 16 megabytes to 64 megabytes (MB) per piece (con- trollable by the user via an optional parameter). It then starts up many copies of the program on a clus- ter of machines.\n> 2. One of the copies of the program is special – the master. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.\n> 3. A worker who is assigned a map task reads the contents of the corresponding input split. It parses key/value pairs out of the input data and passes each pair to the user-defined *Map* function. The interme- diate key/value pairs produced by the *Map* function are buffered in memory.\n> 4. Periodically, **the buffered pairs are written to local disk, partitioned into R regions by the partitioning function.** The locations of these buffered pairs on the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers.\n> 5. When a reduce worker is notified by the master about these locations, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all in- termediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. **If the amount of intermediate data is too large to fit in memory, an external sort is used.**\n> 6. The reduce worker iterates over the sorted interme- diate data and for each unique intermediate key en- countered, **it passes the key and the corresponding set of intermediate values to the user’s *Reduce* func- tion.** The output of the *Reduce* function is appended to a final output file for this reduce partition.\n> 7. When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user pro- gram returns back to the user code.\n\n以上过程标号与图中标号对应，文字加粗部分是个人认为需要着重记忆的或“smart”的实现。\n\n#### 3.x Other Problem in Distributed Systems\n\nSection 3的其他内容将在以下做简要概括：\n\n- **Master Data Structures：**Master是整个MapReduce过程的管理者，是Worker间通讯的线人，它将保存任务的状态，以及文件内容在文件系统中的位置等。\n- **Fault Tolerance：**\n  - Worker是无状态的，任意宕机的Worker上完成的任务可被其他Worker重做。\n  - Master只有一个，宕机的可能性很小，因此若Master宕机则MapReduce任务失败，交给应用来处理。\n  - 并行与分布式计算的正确性需要通过和可能的顺序执行结果进行比较来衡量。本来每个Worker操作的数据对象是不重叠的，因此不会有并发错误，但Worker宕机导致的任务重做可能会使系统各部分看到的状态不同，这时 ```We rely on atomic commits of map and reduce task outputs to achieve this property.``` 包括两点：1. Map任务的完成由唯一的Master来仲裁；2. 底层的分布式文件系统提供rename的原子性来保证reduce输出唯一。\n- **Locality：**任务调度要考虑局部性，避免数据的网络传输。实际上这点在大型分布式系统中非常重要！\n- **Task Granularity**：理论上任务粒度越细越好， ```Having each worker perform many different tasks improves dynamic load balancing, and also speeds up recovery when a worker fails: the many map tasks it has completed can be spread out across all the other worker machines.``` 但现实能够支持的调度数量是有限的，请记住以下数字：```We often per- form MapReduce computations with M = 200, 000 and R = 5, 000, using 2,000 worker machines.```\n- **Backup Tasks：**木桶效应，分布式问题就像是管理问题，是调度问题。不同的机器能力不同，快的得等慢的，当然管机器比管人要容易的多。这里举李沐（交大学长，亚马逊CTO，分布式深度学习框架）的[五年工作感悟](https://zhuanlan.zhihu.com/p/374777591?utm_source=qq&utm_medium=social&utm_oi=989596755247349760)。 ```When a MapReduce operation is close to completion, the master schedules backup executions of the remaining *in-progress* tasks.```\n\n以上就是MapReduce论文1到3节的全部内容理解，对于今后把握项目整体思想、分析分布式编程主要问题都有所帮助。\n\n\n\n## 二、MapReduce代码框架分析\n\n实验代码MapReduce是由MIT设计实现的用于教学的简化版本，通过此版本可以更好的理解上述编程模型和底层执行过程。我们的关注点在于`wc.go`中的由我们定义的map和reduce函数，以及`mapreduce`包中的所有内容。\n\n```go\nfunc main() {\n\tif len(os.Args) < 4 {\n\t\tfmt.Printf(\"%s: see usage comments in file\\n\", os.Args[0])\n\t} else if os.Args[1] == \"master\" {\n\t\tvar mr *mapreduce.Master\n\t\tif os.Args[2] == \"sequential\" {\n\t\t\tmr = mapreduce.Sequential(\"wcseq\", os.Args[3:], 3, mapF, reduceF)\n\t\t} else {\n\t\t\tmr = mapreduce.Distributed(\"wcseq\", os.Args[3:], 3, os.Args[2])\n\t\t}\n\t\tmr.Wait()\n\t} else {\n\t\tmapreduce.RunWorker(os.Args[2], os.Args[3], mapF, reduceF, 100, nil)\n\t}\n}\n```\n\n上面展示了`wc.go`中的`main`函数的内容。与论文附录中展示的代码类似，用户通过指定自定义的map和reduce函数，构造特殊的数据结构（实验中是传多个参数）作为`MapReduce`函数的调用参数来开始一项MapReduce任务。在实验代码实现的MapReduce框架中，`mapreduce.Sequential` 和 `mapreduce.Distributed` 是 *MapReduce* 对外提供的两个接口。由于正确实现的MapReduce框架可以与顺序执行产生同样的结果，实验代码设计了顺序执行的`mapreduce.Sequential`来方便我们调试，以及在编写用户map和reduce函数时加深对程序行为的认识。\n\n### 1. 首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\n\n由于真实的分布式计算框架只需提供 `mapreduce.Distributed` 即可，我们首先分析用户主函数通过 `mapreduce.Distributed` 的调用能否完成分布式计算任务。\n\n `mapreduce.Distributed` 调用层次图如下：`run`中的`schedule`是由`distribute`传入的。\n\n```\nmain\n｜—— Distributed\n    ｜—— newMaster\n    ｜—— mr.startRPCServer\n    ｜—— go mr.run\n        ｜—— schedule(mapPhase)\n            ｜—— go mr.forwardRegistrations(ch)\n            ｜—— schedule(mr.jobName, mr.files, mr.nReduce, mapPhase, ch)\n        \t｜—— go call(reg, \"Worker.DoTask\", ...)\n        ｜—— schedule(reducePhase)\n            ｜—— go mr.forwardRegistrations(ch)\n            ｜—— schedule(mr.jobName, mr.files, mr.nReduce, reducePhase, ch)\n        \t｜—— go call(reg, \"Worker.DoTask\", ...)\n        ｜—— mr.merge()\n        ｜—— mr.doneChannel <- true\n        ｜—— mr.killWorkers\n        ｜—— mr.stopRPCServer\n｜—— mr.Wait()\n```\n\n分析调用路径后，奇怪的是，整个调用过程没有Worker的参与，即使Master声明了RPC，也没有Worker注册。**也就是说，用户不能仅通过 `mapreduce.Distributed` 的调用完成分布式并行计算任务，而需要`mapreduce.RunWorker`的配合，这与论文附录中的接口区别较大**。\n\n那我们自定义的map和reduce函数在测试时并没有并行计算吗？是的。\n\n\n```shell\n#!/bin/bash\ngo run wc.go master sequential pg-*.txt\nsort -n -k2 mrtmp.wcseq | tail -10 | diff - mr-testout.txt > diff.out\nif [ -s diff.out ]\nthen\necho \"Failed test. Output should be as in mr-testout.txt. Your output differs as follows (from diff.out):\" > /dev/stderr\n  cat diff.out\nelse\n  echo \"Passed test\" > /dev/stderr\nfi\n```\n\n上面展示了`test_wc.sh`中的内容，另外查看` test_ii.sh`以及`test_mr.sh`两个测试文件后，可以看出我们自己编写的两套map和reduce函数只运行在`sequential`模式下，这是很令人失望的。考察`RunWorker`函数的被调用情况，只有`test_test.go`中调用过，当然了，测试的执行和main的执行也没有本质的区别啦。。\n\n### 2. 更重要的，从面向对象的角度分析如何从零构建MapReduce框架\n\n思考论文中Section 3的执行过程概述以及Master数据结构部分，我们要怎样在单机多核上实现并行计算呢？那我们可以用多线程模拟Master和Worker。\n\n- Master管理MapReduce任务，记录整个任务的元数据（任务名、Map个数、Reduce个数等），实现数据集划分和任务调度的策略，负责与Worker通信进行任务分发（需要Master和Worker间制定协议），对Reduce的结果进行合并。\n\n- Worker负责map和reduce的执行，将用户定义的map和reduce函数应用在数据集上得到结果（结果在文件系统上共享需要协议）。\n\n上面是论文中的要求，作为简化，实验代码中Master并未实现数据集的划分，而是需要用户划分后通过文件指定Map的数量（其实在论文附录的代码中也是这样做的）。\n\n用go语言实现是相对简单的，任务分发用RPC库，状态监视用goroutine加通道、信号量。mapreduce包中的每个文件都分工明确，整体上实验代码非常清晰、整洁。\n\n\n\n\n## 三、实验问题的解决思路和代码实现\n\n#### 实验整体解决思路\n\n实验问题整体上并不复杂，解决思路实际上只要阅读代码，找到该函数被调用的语境，结合论文和实验文档理解函数需要完成的任务，对整个包内容即自己可以使用的现有资源有充分的认识，以及阅读注释和文档掌握编程细节和go语言库函数即可。不同部分的具体要求不同，思考的领域维度也不相同，但只要根据实验步骤，循序渐进，就会发现实验就像一个个puzzle一样，以阅读、理解、填空为主，既不会让人灰心丧气，还享受到克服困难、学习新语言的成就感。\n\n实现过程中，我并没有碰到太多Bug，让人印象深刻的是Part I的 `doReduce` 函数，以及Part III的 `schedule` 函数的Bug。\n\n### Part I: Map/Reduce input and output\n\n这一部分要求实现的是 `commen_map.go` 中的 `doMap` 函数和`commen_reduce.go` 中的 `doReduce` 函数。\n\n`doMap` 函数：该函数的功能是完成单个给定的mapTask。其主要执行过程如下：\n\n- 创建中间键值文件，创建相应的`json.Encoder`\n- 读入map任务的输入文件内容，用`ioutil.ReadFile()`，然后调用map函数得到中间键值对\n- 对键算哈希，确定键值对要写入的文件，然后以json格式写入\n\n```go\nfunc doMap(\n   jobName string, // the name of the MapReduce job\n   mapTask int, // which map task this is\n   inFile string,\n   nReduce int, // the number of reduce task that will be run (\"R\" in the paper)\n   mapF func(filename string, contents string) []KeyValue,\n) {\n   \n   interFiles := make([]*os.File, nReduce)\n   encoders := make([]*json.Encoder, nReduce)\n   for i := 0; i < nReduce; i++ {\n      interFile, err := os.Create(reduceName(jobName, mapTask, i))\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n      interFiles[i] = interFile\n      encoders[i] = json.NewEncoder(interFile)\n   }\n\n   inputFile, err := ioutil.ReadFile(inFile)\n   if err != nil {\n      log.Fatal(\"check: \", err)\n   }\n   inputKeyValue := mapF(inFile, string(inputFile[:]))\n\n   for _, _KeyValue := range inputKeyValue {\n      index := ihash(_KeyValue.Key) % nReduce\n      err = encoders[index].Encode(&_KeyValue)\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n   }\n\n   for i := 0; i < nReduce; i++ {\n      err = interFiles[i].Close()\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n   }\n}\n```\n\n`doReduce` 函数：该函数用来完成单个给定的reduceTask。其执行过程如下：\n\n- 收集由它负责的键值对，读出文件中用json编码的键值对：如注释中所述对一个文件不断decode直到报错为止\n- 按键排序，即把相同键的键值对聚集到一起\n- 创建输出文件，创建对应的`json.Encoder`\n- 通过键的变化把相同键的所有值形成字符串数组，调用reduce函数得到结果，写入文件中\n\n```go\nfunc doReduce(\n   jobName string, // the name of the whole MapReduce job\n   reduceTask int, // which reduce task this is\n   outFile string, // write the output here\n   nMap int, // the number of map tasks that were run (\"M\" in the paper)\n   reduceF func(key string, values []string) string,\n) {\n\n   var KeyValues []KeyValue\n   for i := 0; i < nMap; i++ {\n      interFile, err := os.Open(reduceName(jobName, i, reduceTask))\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n      decoder := json.NewDecoder(interFile)\n      for {\n         var kv KeyValue\n         err = decoder.Decode(&kv)\n         if err != nil {\n            break\n         }\n         KeyValues = append(KeyValues, kv)\n      }\n      err = interFile.Close()\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n   }\n\n   sort.Slice(KeyValues, func(i, j int) bool {return KeyValues[i].Key < KeyValues[j].Key})\n\n   outputFile, err := os.Create(outFile)\n   if err != nil {\n      log.Fatal(\"check: \", err)\n   }\n   encoder := json.NewEncoder(outputFile)\n\n   var values []string\n   var key string\n   if len(KeyValues) > 0 {\n      key = KeyValues[0].Key\n      for _, kv := range KeyValues {\n         if kv.Key == key {\n            values = append(values, kv.Value)\n         } else {\n            err = encoder.Encode(KeyValue{key, reduceF(key, values)})\n            if err != nil {\n               log.Fatal(\"check: \", err)\n            }\n            values = make([]string, 0)\n            values = append(values, kv.Value)\n            key = kv.Key\n         }\n      }\n\n      err = encoder.Encode(KeyValue{key, reduceF(key, values)})\n      if err != nil {\n         log.Fatal(\"check: \", err)\n      }\n   }\n\n   err = outputFile.Close()\n   if err != nil {\n      log.Fatal(\"check: \", err)\n   }\n}\n```\n\n\n\n\n### Part II: Single-worker word count\n\n这部分要仿照论文中示例给出自定义函数，也就是map处理输入的字符串对其中的每个单词输出中间键值对，因为中间键值对的值都是1所以reduce直接算中间值数组长度即可。\n\n本以为字符串处理和判断单词是个难事，点开文档链接一看就会了，甚至字符串转换都贴心的写好了参考。\n\n```go\nfunc mapF(filename string, contents string) []mapreduce.KeyValue {\n   // Your code here (Part II).\n   f := func(c rune) bool {\n      return !unicode.IsLetter(c)\n   }\n\n   words := strings.FieldsFunc(contents, f)\n   var KeyValues []mapreduce.KeyValue\n   for _, word := range words {\n      KeyValues = append(KeyValues, mapreduce.KeyValue{word, \"1\"})\n   }\n   return KeyValues\n}\n\nfunc reduceF(key string, values []string) string {\n   // Your code here (Part II).\n   return strconv.Itoa(len(values))\n}\n```\n\n\n\n### Part III: Distributing MapReduce tasks\n\n这部分是要上手并行计算了。也是实验中最有趣的部分，涉及go语言通道和信号量的使用。\n\n- 已知我们就是要调RPC，RPC不能阻塞因此要用go routine开协程来监视调用情况。\n- RPC中参数构建较简单，弄清楚通道里的Worker address是怎么来的就会用了。已知Worker `DoTask` 结束后不会再次注册，因此RPC返回后要将该Worker重新放入通道。\n- 使用`sync.WaitGroup` 来同步所有RPC的结束。\n\n这里遇到了一个很关键的bug: `wg.done()` 和 `registerChan <- worker` 这两句写反了。这就出现了输出中显示map task都做完了但就是无法输出`Schedule: mapPhase done` 这句话。说明主线程被阻塞住了，为什么呢？因为这个`registerChan` 通道是没有缓冲区的，也就是通道中最多只有一个值，再往进放就会阻塞住。于是产生了如下循环依赖：\n\n- 主线程在等所有协程`wg.done()` \n- 完成任务的协程在等主线程开新的协程消费通道中的内容，才好把信号放进通道中\n\n***我个人认为在创建通道时给通道声明task数量的缓冲区会更好，因为这样协程才会顺利退出，否则飘着的协程虽不影响主线程接下来的执行，但浪费内存空间，而且调度时会浪费CPU时间。***\n\n修改顺序后，打破循环依赖，就顺利通过测试了～\n\n```go\nfunc schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, registerChan chan string) {\n   var ntasks int\n   var n_other int // number of inputs (for reduce) or outputs (for map)\n   switch phase {\n   case mapPhase:\n      ntasks = len(mapFiles)\n      n_other = nReduce\n   case reducePhase:\n      ntasks = nReduce\n      n_other = len(mapFiles)\n   }\n\n   fmt.Printf(\"Schedule: %v %v tasks (%d I/Os)\\n\", ntasks, phase, n_other)\n\n   // All ntasks tasks have to be scheduled on workers. Once all tasks\n   // have completed successfully, schedule() should return.\n   //\n   // Your code here (Part III, Part IV).\n   //\n   var wg sync.WaitGroup\n   wg.Add(ntasks)\n   for i := 0; i < ntasks; i++ {\n      taskNumber := i\n      go func() {\n         var worker string\n         for {\n            reg := <-registerChan\n            result := call(reg, \"Worker.DoTask\", DoTaskArgs{\n               JobName:       jobName,\n               File:          mapFiles[taskNumber],\n               Phase:         phase,\n               TaskNumber:    taskNumber,\n               NumOtherPhase: n_other,\n            }, nil)\n            if result == true {\n               worker = reg\n               break\n            }\n         }\n         wg.Done()\n         registerChan <- worker\n      }()\n   }\n   wg.Wait()\n   fmt.Printf(\"Schedule: %v done\\n\", phase)\n}\n```\n\n\n\n### Part IV: Handling worker failures\n\n此部分只需在上一部分的基础上加上循环，即在RPC失败时选取下一空闲的Worker重做任务，在RPC返回成功时退出即可。\n\n{% asset_img fault_tolerate.jpeg %}\n\n没想到只加了几行就通过测试了，但它确实是这样。\n\n\n\n### Part V: Inverted index generation (OPTIONAL)\n\n这部分要完成倒排索引的建立，其实就是加深对map和reduce函数语义的认识，用它们做更多有意义的事。\n\n{% asset_img invert_index.jpeg %}\n\n如上图所示，黑色是词数统计的过程，蓝色是倒排索引的区别。将生成倒排索引的任务与此前的词数统计做对比，很容易知道该如何改进。\n\n这里关键问题是去除重复，这里选择在reduce阶段做，这样编程更简洁明了，同时很容易证明是正确的。去除重复采用和Part I `doReduce` 中类似的方法，将所有中间value排序，然后统计不同的内容。\n\n```go\nfunc mapF(document string, value string) (res []mapreduce.KeyValue) {\n   // Your code here (Part V).\n   f := func(c rune) bool {\n      return !unicode.IsLetter(c)\n   }\n\n   words := strings.FieldsFunc(value, f)\n   var KeyValues []mapreduce.KeyValue\n   for _, word := range words {\n      KeyValues = append(KeyValues, mapreduce.KeyValue{word, document})\n   }\n   return KeyValues\n}\n\nfunc reduceF(key string, values []string) string {\n   // Your code here (Part V).\n   var reduceValue []string\n   var lastValue string\n   sort.Slice(values, func(i, j int) bool {return values[i] < values[j]})\n   if len(values) > 0 {\n      reduceValue = append(reduceValue, values[0])\n      lastValue = values[0]\n      for _, value := range values {\n         if value != lastValue {\n            reduceValue = append(reduceValue, value)\n            lastValue = value\n         }\n      }\n   }\n   return strconv.Itoa(len(reduceValue)) + \" \" + strings.Join(reduceValue, \",\")\n}\n```\n\n\n\n## 四、实验过程总结与反思\n\n从科研项目的角度看，我越来越理解高校搞科研面对的问题：资源的限制。\n\n- 由MIT设计的这个实验，是运行在单机上的简化版本，作为我们这次云计算课程实验，它与我曾做过的其他众多实验体量类似，也没有实际应用的能力，如果不是作为名校开源的教材，可能没几个人会注意到这份框架实现。\n\n- 这篇分布式场景下的经典工作，出自谷歌。假设MIT先想到搞这样的研究，不与企业合作的话，倒也可以写一个版本，但evaluation没法在真实场景下测只能模拟、调研工作也会比企业的人付出更多更多，最后发论文后也很难有实际项目落地。相比之下，企业做这样的研究就容易很多：Google发论文无数、微软研究院与英特尔是好兄弟，动不动就改硬件发论文、阿里达摩院宣讲时论文的产出等等。\n- 所以，**要与企业良性合作，互利互惠**，做适应工业界当下需求的科研，积极与工业界交流。\n\n\n\n从课程实验的角度看，该实验如果在以下方面作出改进会更好：\n\n1. 简化注释，可将注释内容转移到文档中，以不经意的形式。这次实验注释过于详尽，使同学对很多数据结构的设计都缺乏思考。\n2. 增加问题练习，在文档中增加需要在实验报告中回答的问题，加深同学对重点的理解。不仅能看懂，而且会表达。\n3. 补充测试，这次实验测试过于简单，显然遗漏了某些边界情况，而且Part V自定义函数运行在Sequential模式下（过度简化）。随随便便就过了测试不能让同学们养成编程时缜密的思考方式。\n4. 论文中有`If the amount of intermediate data is too large to fit in memory, an external sort is used.` 这样的描述，迭代器在数据量大时很常用，但如何构造和实现迭代器依然很陌生，如果简化框架能加入迭代器的实现就更好了。\n","slug":"MapReduce论文及MIT相关实验总结","published":1,"updated":"2021-05-29T10:53:01.889Z","_id":"ckp9m0c200000vowu1i8r4wkr","comments":1,"layout":"post","photos":[],"link":"","content":"<p>本文分四个部分，将从MapReduce论文讲起，分析项目代码是如何实现简化版的MapReduce框架，最后讲述实验内容的完成过程和总结反思。</p>\n\n        <h2 id=\"一、MapReduce论文理解与回顾\"   >\n          <a href=\"#一、MapReduce论文理解与回顾\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#一、MapReduce论文理解与回顾\" class=\"headerlink\" title=\"一、MapReduce论文理解与回顾\"></a>一、MapReduce论文理解与回顾</h2>\n      <p>MapReduce是一个用于处理大规模数据的分布式计算框架。分布式计算框架往往看重灵活易使用的前端，和高性能可拓展的后端，这在图计算和深度学习领域也是如此。而对MapReduce这个处理大规模同质数据的框架来说，应该从两方面来理解：一是它为程序员提供了什么样的抽象，给上层编程人员提供了什么样的编程模型，即编程时对此系统功能和性质的认识；二是它内部是如何实现，从而为上层提供多种支持和保证。</p>\n\n        <h3 id=\"Section-2-Programming-Model\"   >\n          <a href=\"#Section-2-Programming-Model\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Section-2-Programming-Model\" class=\"headerlink\" title=\"Section 2: Programming Model\"></a>Section 2: Programming Model</h3>\n      <p>编程模型是这篇工作最突出的贡献，它所解决的“重要的问题”在于给各种大规模计算在分布式编程时提供了便利。</p>\n<blockquote>\n<p>Users specify a <em>map</em> function that processes a key/value pair to generate a set of intermediate key/value pairs, and a <em>reduce</em> function that merges all intermediate values associated with the same intermediate key.</p>\n<figure class=\"highlight plain\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map    (k1,v1)        → list(k2,v2)</span><br><span class=\"line\">reduce (k2,list(v2))  → list(v2)</span><br></pre></td></tr></table></div></figure>\n\n<p>the input keys and values are drawn from a different domain than the output keys and values. Furthermore, the intermediate keys and values are from the same do- main as the output keys and values.</p>\n<p>Our C++ implementation passes strings to and from the user-defined functions and leaves it to the user code to convert between strings and appropriate types.</p>\n</blockquote>\n<p>上面选取的是论文中Section 2的内容，主要明确用户定义的Map和Reduce函数的外在表现和要求（如键值对的域）。而要真正应用MapReduce框架，还需要对MapReduce的语义有更直观的理解，可参考论文Section 2.3部分。简单来说，一个任务是否适合使用MapReduce模型来解决，需要看是否满足以下两点要求：</p>\n<ul>\n<li>计算的数据规模大，需要利用并行与分布式计算来加速</li>\n<li>计算任务之间没有依赖，没有先后顺序关系，任务完成的先后顺序对结果没有影响（操作元满足交换律）</li>\n</ul>\n<p>当然，在云计算繁荣发展的今天，关于MapReduce模型的优化在学术界备受关注，最近的一篇工作提出用符号执行的方法破除顺序依赖，使MapReduce框架也能加速存在计算先后顺序的计算过程。</p>\n\n        <h3 id=\"Section-3-Implementation\"   >\n          <a href=\"#Section-3-Implementation\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Section-3-Implementation\" class=\"headerlink\" title=\"Section 3: Implementation\"></a>Section 3: Implementation</h3>\n      <p>框架实现是这篇工作的实际困难与巧妙解法，系统软件要做的就是将简单留给用户，复杂性留给自己。</p>\n<blockquote>\n<p>As a reaction to this complexity, we designed a new abstraction that allows us to express the simple computa- tions we were trying to perform but hides the messy de- tails of parallelization, fault-tolerance, data distribution and load balancing in a library.</p>\n<p>The run-time system takes care of the details of partitioning the input data, scheduling the program’s execution across a set of machines, handling ma- chine failures, and managing the required inter-machine communication.</p>\n</blockquote>\n\n        <h4 id=\"3-1-Execution-Overview\"   >\n          <a href=\"#3-1-Execution-Overview\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#3-1-Execution-Overview\" class=\"headerlink\" title=\"3.1 Execution Overview\"></a>3.1 <strong>Execution Overview</strong></h4>\n      <p>分布式计算任务的完成是一个框架首先考虑的事，理解执行过程才能理解分布式编程的一般思路（对实验的完成也很有帮助），其次才是容错、性能等方面，因此这里将引用论文中关于执行过程的全部说明。执行过程如下图所示：</p>\n<img src=\"/2021/05/29/MapReduce%E8%AE%BA%E6%96%87%E5%8F%8AMIT%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/exec_overview.png\" class=\"\">\n\n<blockquote>\n<ol>\n<li>The MapReduce library in the user program first splits the input files into M pieces of typically 16 megabytes to 64 megabytes (MB) per piece (con- trollable by the user via an optional parameter). It then starts up many copies of the program on a clus- ter of machines.</li>\n<li>One of the copies of the program is special – the master. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.</li>\n<li>A worker who is assigned a map task reads the contents of the corresponding input split. It parses key/value pairs out of the input data and passes each pair to the user-defined <em>Map</em> function. The interme- diate key/value pairs produced by the <em>Map</em> function are buffered in memory.</li>\n<li>Periodically, <strong>the buffered pairs are written to local disk, partitioned into R regions by the partitioning function.</strong> The locations of these buffered pairs on the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers.</li>\n<li>When a reduce worker is notified by the master about these locations, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all in- termediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. <strong>If the amount of intermediate data is too large to fit in memory, an external sort is used.</strong></li>\n<li>The reduce worker iterates over the sorted interme- diate data and for each unique intermediate key en- countered, <strong>it passes the key and the corresponding set of intermediate values to the user’s <em>Reduce</em> func- tion.</strong> The output of the <em>Reduce</em> function is appended to a final output file for this reduce partition.</li>\n<li>When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user pro- gram returns back to the user code.</li>\n</ol>\n</blockquote>\n<p>以上过程标号与图中标号对应，文字加粗部分是个人认为需要着重记忆的或“smart”的实现。</p>\n\n        <h4 id=\"3-x-Other-Problem-in-Distributed-Systems\"   >\n          <a href=\"#3-x-Other-Problem-in-Distributed-Systems\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#3-x-Other-Problem-in-Distributed-Systems\" class=\"headerlink\" title=\"3.x Other Problem in Distributed Systems\"></a>3.x Other Problem in Distributed Systems</h4>\n      <p>Section 3的其他内容将在以下做简要概括：</p>\n<ul>\n<li><strong>Master Data Structures：</strong>Master是整个MapReduce过程的管理者，是Worker间通讯的线人，它将保存任务的状态，以及文件内容在文件系统中的位置等。</li>\n<li><strong>Fault Tolerance：</strong><ul>\n<li>Worker是无状态的，任意宕机的Worker上完成的任务可被其他Worker重做。</li>\n<li>Master只有一个，宕机的可能性很小，因此若Master宕机则MapReduce任务失败，交给应用来处理。</li>\n<li>并行与分布式计算的正确性需要通过和可能的顺序执行结果进行比较来衡量。本来每个Worker操作的数据对象是不重叠的，因此不会有并发错误，但Worker宕机导致的任务重做可能会使系统各部分看到的状态不同，这时 <code>We rely on atomic commits of map and reduce task outputs to achieve this property.</code> 包括两点：1. Map任务的完成由唯一的Master来仲裁；2. 底层的分布式文件系统提供rename的原子性来保证reduce输出唯一。</li>\n</ul>\n</li>\n<li><strong>Locality：</strong>任务调度要考虑局部性，避免数据的网络传输。实际上这点在大型分布式系统中非常重要！</li>\n<li><strong>Task Granularity</strong>：理论上任务粒度越细越好， <code>Having each worker perform many different tasks improves dynamic load balancing, and also speeds up recovery when a worker fails: the many map tasks it has completed can be spread out across all the other worker machines.</code> 但现实能够支持的调度数量是有限的，请记住以下数字：<code>We often per- form MapReduce computations with M = 200, 000 and R = 5, 000, using 2,000 worker machines.</code></li>\n<li><strong>Backup Tasks：</strong>木桶效应，分布式问题就像是管理问题，是调度问题。不同的机器能力不同，快的得等慢的，当然管机器比管人要容易的多。这里举李沐（交大学长，亚马逊CTO，分布式深度学习框架）的<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://zhuanlan.zhihu.com/p/374777591?utm_source=qq&utm_medium=social&utm_oi=989596755247349760\" >五年工作感悟</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>。 <code>When a MapReduce operation is close to completion, the master schedules backup executions of the remaining *in-progress* tasks.</code></li>\n</ul>\n<p>以上就是MapReduce论文1到3节的全部内容理解，对于今后把握项目整体思想、分析分布式编程主要问题都有所帮助。</p>\n\n        <h2 id=\"二、MapReduce代码框架分析\"   >\n          <a href=\"#二、MapReduce代码框架分析\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#二、MapReduce代码框架分析\" class=\"headerlink\" title=\"二、MapReduce代码框架分析\"></a>二、MapReduce代码框架分析</h2>\n      <p>实验代码MapReduce是由MIT设计实现的用于教学的简化版本，通过此版本可以更好的理解上述编程模型和底层执行过程。我们的关注点在于<code>wc.go</code>中的由我们定义的map和reduce函数，以及<code>mapreduce</code>包中的所有内容。</p>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(os.Args) &lt; <span class=\"number\">4</span> &#123;</span><br><span class=\"line\">\t\tfmt.Printf(<span class=\"string\">&quot;%s: see usage comments in file\\n&quot;</span>, os.Args[<span class=\"number\">0</span>])</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> os.Args[<span class=\"number\">1</span>] == <span class=\"string\">&quot;master&quot;</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">var</span> mr *mapreduce.Master</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> os.Args[<span class=\"number\">2</span>] == <span class=\"string\">&quot;sequential&quot;</span> &#123;</span><br><span class=\"line\">\t\t\tmr = mapreduce.Sequential(<span class=\"string\">&quot;wcseq&quot;</span>, os.Args[<span class=\"number\">3</span>:], <span class=\"number\">3</span>, mapF, reduceF)</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\tmr = mapreduce.Distributed(<span class=\"string\">&quot;wcseq&quot;</span>, os.Args[<span class=\"number\">3</span>:], <span class=\"number\">3</span>, os.Args[<span class=\"number\">2</span>])</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tmr.Wait()</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tmapreduce.RunWorker(os.Args[<span class=\"number\">2</span>], os.Args[<span class=\"number\">3</span>], mapF, reduceF, <span class=\"number\">100</span>, <span class=\"literal\">nil</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<p>上面展示了<code>wc.go</code>中的<code>main</code>函数的内容。与论文附录中展示的代码类似，用户通过指定自定义的map和reduce函数，构造特殊的数据结构（实验中是传多个参数）作为<code>MapReduce</code>函数的调用参数来开始一项MapReduce任务。在实验代码实现的MapReduce框架中，<code>mapreduce.Sequential</code> 和 <code>mapreduce.Distributed</code> 是 <em>MapReduce</em> 对外提供的两个接口。由于正确实现的MapReduce框架可以与顺序执行产生同样的结果，实验代码设计了顺序执行的<code>mapreduce.Sequential</code>来方便我们调试，以及在编写用户map和reduce函数时加深对程序行为的认识。</p>\n\n        <h3 id=\"1-首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\"   >\n          <a href=\"#1-首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#1-首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\" class=\"headerlink\" title=\"1. 首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\"></a>1. 首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：</h3>\n      <p>由于真实的分布式计算框架只需提供 <code>mapreduce.Distributed</code> 即可，我们首先分析用户主函数通过 <code>mapreduce.Distributed</code> 的调用能否完成分布式计算任务。</p>\n<p> <code>mapreduce.Distributed</code> 调用层次图如下：<code>run</code>中的<code>schedule</code>是由<code>distribute</code>传入的。</p>\n<figure class=\"highlight plain\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main</span><br><span class=\"line\">｜—— Distributed</span><br><span class=\"line\">    ｜—— newMaster</span><br><span class=\"line\">    ｜—— mr.startRPCServer</span><br><span class=\"line\">    ｜—— go mr.run</span><br><span class=\"line\">        ｜—— schedule(mapPhase)</span><br><span class=\"line\">            ｜—— go mr.forwardRegistrations(ch)</span><br><span class=\"line\">            ｜—— schedule(mr.jobName, mr.files, mr.nReduce, mapPhase, ch)</span><br><span class=\"line\">        \t｜—— go call(reg, &quot;Worker.DoTask&quot;, ...)</span><br><span class=\"line\">        ｜—— schedule(reducePhase)</span><br><span class=\"line\">            ｜—— go mr.forwardRegistrations(ch)</span><br><span class=\"line\">            ｜—— schedule(mr.jobName, mr.files, mr.nReduce, reducePhase, ch)</span><br><span class=\"line\">        \t｜—— go call(reg, &quot;Worker.DoTask&quot;, ...)</span><br><span class=\"line\">        ｜—— mr.merge()</span><br><span class=\"line\">        ｜—— mr.doneChannel &lt;- true</span><br><span class=\"line\">        ｜—— mr.killWorkers</span><br><span class=\"line\">        ｜—— mr.stopRPCServer</span><br><span class=\"line\">｜—— mr.Wait()</span><br></pre></td></tr></table></div></figure>\n\n<p>分析调用路径后，奇怪的是，整个调用过程没有Worker的参与，即使Master声明了RPC，也没有Worker注册。<strong>也就是说，用户不能仅通过 <code>mapreduce.Distributed</code> 的调用完成分布式并行计算任务，而需要<code>mapreduce.RunWorker</code>的配合，这与论文附录中的接口区别较大</strong>。</p>\n<p>那我们自定义的map和reduce函数在测试时并没有并行计算吗？是的。</p>\n<figure class=\"highlight shell\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">!/bin/bash</span></span><br><span class=\"line\">go run wc.go master sequential pg-*.txt</span><br><span class=\"line\">sort -n -k2 mrtmp.wcseq | tail -10 | diff - mr-testout.txt &gt; diff.out</span><br><span class=\"line\">if [ -s diff.out ]</span><br><span class=\"line\">then</span><br><span class=\"line\">echo &quot;Failed test. Output should be as in mr-testout.txt. Your output differs as follows (from diff.out):&quot; &gt; /dev/stderr</span><br><span class=\"line\">  cat diff.out</span><br><span class=\"line\">else</span><br><span class=\"line\">  echo &quot;Passed test&quot; &gt; /dev/stderr</span><br><span class=\"line\">fi</span><br></pre></td></tr></table></div></figure>\n\n<p>上面展示了<code>test_wc.sh</code>中的内容，另外查看<code> test_ii.sh</code>以及<code>test_mr.sh</code>两个测试文件后，可以看出我们自己编写的两套map和reduce函数只运行在<code>sequential</code>模式下，这是很令人失望的。考察<code>RunWorker</code>函数的被调用情况，只有<code>test_test.go</code>中调用过，当然了，测试的执行和main的执行也没有本质的区别啦。。</p>\n\n        <h3 id=\"2-更重要的，从面向对象的角度分析如何从零构建MapReduce框架\"   >\n          <a href=\"#2-更重要的，从面向对象的角度分析如何从零构建MapReduce框架\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#2-更重要的，从面向对象的角度分析如何从零构建MapReduce框架\" class=\"headerlink\" title=\"2. 更重要的，从面向对象的角度分析如何从零构建MapReduce框架\"></a>2. 更重要的，从面向对象的角度分析如何从零构建MapReduce框架</h3>\n      <p>思考论文中Section 3的执行过程概述以及Master数据结构部分，我们要怎样在单机多核上实现并行计算呢？那我们可以用多线程模拟Master和Worker。</p>\n<ul>\n<li><p>Master管理MapReduce任务，记录整个任务的元数据（任务名、Map个数、Reduce个数等），实现数据集划分和任务调度的策略，负责与Worker通信进行任务分发（需要Master和Worker间制定协议），对Reduce的结果进行合并。</p>\n</li>\n<li><p>Worker负责map和reduce的执行，将用户定义的map和reduce函数应用在数据集上得到结果（结果在文件系统上共享需要协议）。</p>\n</li>\n</ul>\n<p>上面是论文中的要求，作为简化，实验代码中Master并未实现数据集的划分，而是需要用户划分后通过文件指定Map的数量（其实在论文附录的代码中也是这样做的）。</p>\n<p>用go语言实现是相对简单的，任务分发用RPC库，状态监视用goroutine加通道、信号量。mapreduce包中的每个文件都分工明确，整体上实验代码非常清晰、整洁。</p>\n\n        <h2 id=\"三、实验问题的解决思路和代码实现\"   >\n          <a href=\"#三、实验问题的解决思路和代码实现\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#三、实验问题的解决思路和代码实现\" class=\"headerlink\" title=\"三、实验问题的解决思路和代码实现\"></a>三、实验问题的解决思路和代码实现</h2>\n      \n        <h4 id=\"实验整体解决思路\"   >\n          <a href=\"#实验整体解决思路\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#实验整体解决思路\" class=\"headerlink\" title=\"实验整体解决思路\"></a>实验整体解决思路</h4>\n      <p>实验问题整体上并不复杂，解决思路实际上只要阅读代码，找到该函数被调用的语境，结合论文和实验文档理解函数需要完成的任务，对整个包内容即自己可以使用的现有资源有充分的认识，以及阅读注释和文档掌握编程细节和go语言库函数即可。不同部分的具体要求不同，思考的领域维度也不相同，但只要根据实验步骤，循序渐进，就会发现实验就像一个个puzzle一样，以阅读、理解、填空为主，既不会让人灰心丧气，还享受到克服困难、学习新语言的成就感。</p>\n<p>实现过程中，我并没有碰到太多Bug，让人印象深刻的是Part I的 <code>doReduce</code> 函数，以及Part III的 <code>schedule</code> 函数的Bug。</p>\n\n        <h3 id=\"Part-I-Map-Reduce-input-and-output\"   >\n          <a href=\"#Part-I-Map-Reduce-input-and-output\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-I-Map-Reduce-input-and-output\" class=\"headerlink\" title=\"Part I: Map/Reduce input and output\"></a>Part I: Map/Reduce input and output</h3>\n      <p>这一部分要求实现的是 <code>commen_map.go</code> 中的 <code>doMap</code> 函数和<code>commen_reduce.go</code> 中的 <code>doReduce</code> 函数。</p>\n<p><code>doMap</code> 函数：该函数的功能是完成单个给定的mapTask。其主要执行过程如下：</p>\n<ul>\n<li>创建中间键值文件，创建相应的<code>json.Encoder</code></li>\n<li>读入map任务的输入文件内容，用<code>ioutil.ReadFile()</code>，然后调用map函数得到中间键值对</li>\n<li>对键算哈希，确定键值对要写入的文件，然后以json格式写入</li>\n</ul>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">doMap</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   jobName <span class=\"keyword\">string</span>, // the name of the MapReduce job</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   mapTask <span class=\"keyword\">int</span>, // which <span class=\"keyword\">map</span> task this is</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   inFile <span class=\"keyword\">string</span>,</span></span></span><br><span class=\"line\">   nReduce int, // the number of reduce task that will be run (&quot;R&quot; in the paper)</span><br><span class=\"line\">   mapF <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(filename <span class=\"keyword\">string</span>, contents <span class=\"keyword\">string</span>)</span> []<span class=\"title\">KeyValue</span>,</span></span><br><span class=\"line\">) &#123;</span><br><span class=\"line\">   </span><br><span class=\"line\">   interFiles := <span class=\"built_in\">make</span>([]*os.File, nReduce)</span><br><span class=\"line\">   encoders := <span class=\"built_in\">make</span>([]*json.Encoder, nReduce)</span><br><span class=\"line\">   <span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; nReduce; i++ &#123;</span><br><span class=\"line\">      interFile, err := os.Create(reduceName(jobName, mapTask, i))</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      interFiles[i] = interFile</span><br><span class=\"line\">      encoders[i] = json.NewEncoder(interFile)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   inputFile, err := ioutil.ReadFile(inFile)</span><br><span class=\"line\">   <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">      log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   inputKeyValue := mapF(inFile, <span class=\"keyword\">string</span>(inputFile[:]))</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">for</span> _, _KeyValue := <span class=\"keyword\">range</span> inputKeyValue &#123;</span><br><span class=\"line\">      index := ihash(_KeyValue.Key) % nReduce</span><br><span class=\"line\">      err = encoders[index].Encode(&amp;_KeyValue)</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; nReduce; i++ &#123;</span><br><span class=\"line\">      err = interFiles[i].Close()</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<p><code>doReduce</code> 函数：该函数用来完成单个给定的reduceTask。其执行过程如下：</p>\n<ul>\n<li>收集由它负责的键值对，读出文件中用json编码的键值对：如注释中所述对一个文件不断decode直到报错为止</li>\n<li>按键排序，即把相同键的键值对聚集到一起</li>\n<li>创建输出文件，创建对应的<code>json.Encoder</code></li>\n<li>通过键的变化把相同键的所有值形成字符串数组，调用reduce函数得到结果，写入文件中</li>\n</ul>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">doReduce</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   jobName <span class=\"keyword\">string</span>, // the name of the whole MapReduce job</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   reduceTask <span class=\"keyword\">int</span>, // which reduce task this is</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   outFile <span class=\"keyword\">string</span>, // write the output here</span></span></span><br><span class=\"line\">   nMap int, // the number of map tasks that were run (&quot;M&quot; in the paper)</span><br><span class=\"line\">   reduceF <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(key <span class=\"keyword\">string</span>, values []<span class=\"keyword\">string</span>)</span> <span class=\"title\">string</span>,</span></span><br><span class=\"line\">) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">var</span> KeyValues []KeyValue</span><br><span class=\"line\">   <span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; nMap; i++ &#123;</span><br><span class=\"line\">      interFile, err := os.Open(reduceName(jobName, i, reduceTask))</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      decoder := json.NewDecoder(interFile)</span><br><span class=\"line\">      <span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">var</span> kv KeyValue</span><br><span class=\"line\">         err = decoder.Decode(&amp;kv)</span><br><span class=\"line\">         <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">         KeyValues = <span class=\"built_in\">append</span>(KeyValues, kv)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      err = interFile.Close()</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   sort.Slice(KeyValues, <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(i, j <span class=\"keyword\">int</span>)</span> <span class=\"title\">bool</span></span> &#123;<span class=\"keyword\">return</span> KeyValues[i].Key &lt; KeyValues[j].Key&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">   outputFile, err := os.Create(outFile)</span><br><span class=\"line\">   <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">      log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   encoder := json.NewEncoder(outputFile)</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">var</span> values []<span class=\"keyword\">string</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> key <span class=\"keyword\">string</span></span><br><span class=\"line\">   <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(KeyValues) &gt; <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">      key = KeyValues[<span class=\"number\">0</span>].Key</span><br><span class=\"line\">      <span class=\"keyword\">for</span> _, kv := <span class=\"keyword\">range</span> KeyValues &#123;</span><br><span class=\"line\">         <span class=\"keyword\">if</span> kv.Key == key &#123;</span><br><span class=\"line\">            values = <span class=\"built_in\">append</span>(values, kv.Value)</span><br><span class=\"line\">         &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            err = encoder.Encode(KeyValue&#123;key, reduceF(key, values)&#125;)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">               log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            values = <span class=\"built_in\">make</span>([]<span class=\"keyword\">string</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">            values = <span class=\"built_in\">append</span>(values, kv.Value)</span><br><span class=\"line\">            key = kv.Key</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      err = encoder.Encode(KeyValue&#123;key, reduceF(key, values)&#125;)</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   err = outputFile.Close()</span><br><span class=\"line\">   <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">      log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n\n\n\n\n        <h3 id=\"Part-II-Single-worker-word-count\"   >\n          <a href=\"#Part-II-Single-worker-word-count\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-II-Single-worker-word-count\" class=\"headerlink\" title=\"Part II: Single-worker word count\"></a>Part II: Single-worker word count</h3>\n      <p>这部分要仿照论文中示例给出自定义函数，也就是map处理输入的字符串对其中的每个单词输出中间键值对，因为中间键值对的值都是1所以reduce直接算中间值数组长度即可。</p>\n<p>本以为字符串处理和判断单词是个难事，点开文档链接一看就会了，甚至字符串转换都贴心的写好了参考。</p>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">mapF</span><span class=\"params\">(filename <span class=\"keyword\">string</span>, contents <span class=\"keyword\">string</span>)</span> []<span class=\"title\">mapreduce</span>.<span class=\"title\">KeyValue</span></span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part II).</span></span><br><span class=\"line\">   f := <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(c <span class=\"keyword\">rune</span>)</span> <span class=\"title\">bool</span></span> &#123;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> !unicode.IsLetter(c)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   words := strings.FieldsFunc(contents, f)</span><br><span class=\"line\">   <span class=\"keyword\">var</span> KeyValues []mapreduce.KeyValue</span><br><span class=\"line\">   <span class=\"keyword\">for</span> _, word := <span class=\"keyword\">range</span> words &#123;</span><br><span class=\"line\">      KeyValues = <span class=\"built_in\">append</span>(KeyValues, mapreduce.KeyValue&#123;word, <span class=\"string\">&quot;1&quot;</span>&#125;)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   <span class=\"keyword\">return</span> KeyValues</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">reduceF</span><span class=\"params\">(key <span class=\"keyword\">string</span>, values []<span class=\"keyword\">string</span>)</span> <span class=\"title\">string</span></span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part II).</span></span><br><span class=\"line\">   <span class=\"keyword\">return</span> strconv.Itoa(<span class=\"built_in\">len</span>(values))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n\n\n\n        <h3 id=\"Part-III-Distributing-MapReduce-tasks\"   >\n          <a href=\"#Part-III-Distributing-MapReduce-tasks\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-III-Distributing-MapReduce-tasks\" class=\"headerlink\" title=\"Part III: Distributing MapReduce tasks\"></a>Part III: Distributing MapReduce tasks</h3>\n      <p>这部分是要上手并行计算了。也是实验中最有趣的部分，涉及go语言通道和信号量的使用。</p>\n<ul>\n<li>已知我们就是要调RPC，RPC不能阻塞因此要用go routine开协程来监视调用情况。</li>\n<li>RPC中参数构建较简单，弄清楚通道里的Worker address是怎么来的就会用了。已知Worker <code>DoTask</code> 结束后不会再次注册，因此RPC返回后要将该Worker重新放入通道。</li>\n<li>使用<code>sync.WaitGroup</code> 来同步所有RPC的结束。</li>\n</ul>\n<p>这里遇到了一个很关键的bug: <code>wg.done()</code> 和 <code>registerChan &lt;- worker</code> 这两句写反了。这就出现了输出中显示map task都做完了但就是无法输出<code>Schedule: mapPhase done</code> 这句话。说明主线程被阻塞住了，为什么呢？因为这个<code>registerChan</code> 通道是没有缓冲区的，也就是通道中最多只有一个值，再往进放就会阻塞住。于是产生了如下循环依赖：</p>\n<ul>\n<li>主线程在等所有协程<code>wg.done()</code> </li>\n<li>完成任务的协程在等主线程开新的协程消费通道中的内容，才好把信号放进通道中</li>\n</ul>\n<p><em><strong>我个人认为在创建通道时给通道声明task数量的缓冲区会更好，因为这样协程才会顺利退出，否则飘着的协程虽不影响主线程接下来的执行，但浪费内存空间，而且调度时会浪费CPU时间。</strong></em></p>\n<p>修改顺序后，打破循环依赖，就顺利通过测试了～</p>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">schedule</span><span class=\"params\">(jobName <span class=\"keyword\">string</span>, mapFiles []<span class=\"keyword\">string</span>, nReduce <span class=\"keyword\">int</span>, phase jobPhase, registerChan <span class=\"keyword\">chan</span> <span class=\"keyword\">string</span>)</span></span> &#123;</span><br><span class=\"line\">   <span class=\"keyword\">var</span> ntasks <span class=\"keyword\">int</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> n_other <span class=\"keyword\">int</span> <span class=\"comment\">// number of inputs (for reduce) or outputs (for map)</span></span><br><span class=\"line\">   <span class=\"keyword\">switch</span> phase &#123;</span><br><span class=\"line\">   <span class=\"keyword\">case</span> mapPhase:</span><br><span class=\"line\">      ntasks = <span class=\"built_in\">len</span>(mapFiles)</span><br><span class=\"line\">      n_other = nReduce</span><br><span class=\"line\">   <span class=\"keyword\">case</span> reducePhase:</span><br><span class=\"line\">      ntasks = nReduce</span><br><span class=\"line\">      n_other = <span class=\"built_in\">len</span>(mapFiles)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   fmt.Printf(<span class=\"string\">&quot;Schedule: %v %v tasks (%d I/Os)\\n&quot;</span>, ntasks, phase, n_other)</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"comment\">// All ntasks tasks have to be scheduled on workers. Once all tasks</span></span><br><span class=\"line\">   <span class=\"comment\">// have completed successfully, schedule() should return.</span></span><br><span class=\"line\">   <span class=\"comment\">//</span></span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part III, Part IV).</span></span><br><span class=\"line\">   <span class=\"comment\">//</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">   wg.Add(ntasks)</span><br><span class=\"line\">   <span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; ntasks; i++ &#123;</span><br><span class=\"line\">      taskNumber := i</span><br><span class=\"line\">      <span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">var</span> worker <span class=\"keyword\">string</span></span><br><span class=\"line\">         <span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">            reg := &lt;-registerChan</span><br><span class=\"line\">            result := call(reg, <span class=\"string\">&quot;Worker.DoTask&quot;</span>, DoTaskArgs&#123;</span><br><span class=\"line\">               JobName:       jobName,</span><br><span class=\"line\">               File:          mapFiles[taskNumber],</span><br><span class=\"line\">               Phase:         phase,</span><br><span class=\"line\">               TaskNumber:    taskNumber,</span><br><span class=\"line\">               NumOtherPhase: n_other,</span><br><span class=\"line\">            &#125;, <span class=\"literal\">nil</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> result == <span class=\"literal\">true</span> &#123;</span><br><span class=\"line\">               worker = reg</span><br><span class=\"line\">               <span class=\"keyword\">break</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">         wg.Done()</span><br><span class=\"line\">         registerChan &lt;- worker</span><br><span class=\"line\">      &#125;()</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   wg.Wait()</span><br><span class=\"line\">   fmt.Printf(<span class=\"string\">&quot;Schedule: %v done\\n&quot;</span>, phase)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n\n\n\n        <h3 id=\"Part-IV-Handling-worker-failures\"   >\n          <a href=\"#Part-IV-Handling-worker-failures\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-IV-Handling-worker-failures\" class=\"headerlink\" title=\"Part IV: Handling worker failures\"></a>Part IV: Handling worker failures</h3>\n      <p>此部分只需在上一部分的基础上加上循环，即在RPC失败时选取下一空闲的Worker重做任务，在RPC返回成功时退出即可。</p>\n<img src=\"/2021/05/29/MapReduce%E8%AE%BA%E6%96%87%E5%8F%8AMIT%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/fault_tolerate.jpeg\" class=\"\">\n\n<p>没想到只加了几行就通过测试了，但它确实是这样。</p>\n\n        <h3 id=\"Part-V-Inverted-index-generation-OPTIONAL\"   >\n          <a href=\"#Part-V-Inverted-index-generation-OPTIONAL\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-V-Inverted-index-generation-OPTIONAL\" class=\"headerlink\" title=\"Part V: Inverted index generation (OPTIONAL)\"></a>Part V: Inverted index generation (OPTIONAL)</h3>\n      <p>这部分要完成倒排索引的建立，其实就是加深对map和reduce函数语义的认识，用它们做更多有意义的事。</p>\n<img src=\"/2021/05/29/MapReduce%E8%AE%BA%E6%96%87%E5%8F%8AMIT%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/invert_index.jpeg\" class=\"\">\n\n<p>如上图所示，黑色是词数统计的过程，蓝色是倒排索引的区别。将生成倒排索引的任务与此前的词数统计做对比，很容易知道该如何改进。</p>\n<p>这里关键问题是去除重复，这里选择在reduce阶段做，这样编程更简洁明了，同时很容易证明是正确的。去除重复采用和Part I <code>doReduce</code> 中类似的方法，将所有中间value排序，然后统计不同的内容。</p>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">mapF</span><span class=\"params\">(document <span class=\"keyword\">string</span>, value <span class=\"keyword\">string</span>)</span> <span class=\"params\">(res []mapreduce.KeyValue)</span></span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part V).</span></span><br><span class=\"line\">   f := <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(c <span class=\"keyword\">rune</span>)</span> <span class=\"title\">bool</span></span> &#123;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> !unicode.IsLetter(c)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   words := strings.FieldsFunc(value, f)</span><br><span class=\"line\">   <span class=\"keyword\">var</span> KeyValues []mapreduce.KeyValue</span><br><span class=\"line\">   <span class=\"keyword\">for</span> _, word := <span class=\"keyword\">range</span> words &#123;</span><br><span class=\"line\">      KeyValues = <span class=\"built_in\">append</span>(KeyValues, mapreduce.KeyValue&#123;word, document&#125;)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   <span class=\"keyword\">return</span> KeyValues</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">reduceF</span><span class=\"params\">(key <span class=\"keyword\">string</span>, values []<span class=\"keyword\">string</span>)</span> <span class=\"title\">string</span></span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part V).</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> reduceValue []<span class=\"keyword\">string</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> lastValue <span class=\"keyword\">string</span></span><br><span class=\"line\">   sort.Slice(values, <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(i, j <span class=\"keyword\">int</span>)</span> <span class=\"title\">bool</span></span> &#123;<span class=\"keyword\">return</span> values[i] &lt; values[j]&#125;)</span><br><span class=\"line\">   <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(values) &gt; <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">      reduceValue = <span class=\"built_in\">append</span>(reduceValue, values[<span class=\"number\">0</span>])</span><br><span class=\"line\">      lastValue = values[<span class=\"number\">0</span>]</span><br><span class=\"line\">      <span class=\"keyword\">for</span> _, value := <span class=\"keyword\">range</span> values &#123;</span><br><span class=\"line\">         <span class=\"keyword\">if</span> value != lastValue &#123;</span><br><span class=\"line\">            reduceValue = <span class=\"built_in\">append</span>(reduceValue, value)</span><br><span class=\"line\">            lastValue = value</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   <span class=\"keyword\">return</span> strconv.Itoa(<span class=\"built_in\">len</span>(reduceValue)) + <span class=\"string\">&quot; &quot;</span> + strings.Join(reduceValue, <span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n\n\n\n        <h2 id=\"四、实验过程总结与反思\"   >\n          <a href=\"#四、实验过程总结与反思\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#四、实验过程总结与反思\" class=\"headerlink\" title=\"四、实验过程总结与反思\"></a>四、实验过程总结与反思</h2>\n      <p>从科研项目的角度看，我越来越理解高校搞科研面对的问题：资源的限制。</p>\n<ul>\n<li><p>由MIT设计的这个实验，是运行在单机上的简化版本，作为我们这次云计算课程实验，它与我曾做过的其他众多实验体量类似，也没有实际应用的能力，如果不是作为名校开源的教材，可能没几个人会注意到这份框架实现。</p>\n</li>\n<li><p>这篇分布式场景下的经典工作，出自谷歌。假设MIT先想到搞这样的研究，不与企业合作的话，倒也可以写一个版本，但evaluation没法在真实场景下测只能模拟、调研工作也会比企业的人付出更多更多，最后发论文后也很难有实际项目落地。相比之下，企业做这样的研究就容易很多：Google发论文无数、微软研究院与英特尔是好兄弟，动不动就改硬件发论文、阿里达摩院宣讲时论文的产出等等。</p>\n</li>\n<li><p>所以，<strong>要与企业良性合作，互利互惠</strong>，做适应工业界当下需求的科研，积极与工业界交流。</p>\n</li>\n</ul>\n<p>从课程实验的角度看，该实验如果在以下方面作出改进会更好：</p>\n<ol>\n<li>简化注释，可将注释内容转移到文档中，以不经意的形式。这次实验注释过于详尽，使同学对很多数据结构的设计都缺乏思考。</li>\n<li>增加问题练习，在文档中增加需要在实验报告中回答的问题，加深同学对重点的理解。不仅能看懂，而且会表达。</li>\n<li>补充测试，这次实验测试过于简单，显然遗漏了某些边界情况，而且Part V自定义函数运行在Sequential模式下（过度简化）。随随便便就过了测试不能让同学们养成编程时缜密的思考方式。</li>\n<li>论文中有<code>If the amount of intermediate data is too large to fit in memory, an external sort is used.</code> 这样的描述，迭代器在数据量大时很常用，但如何构造和实现迭代器依然很陌生，如果简化框架能加入迭代器的实现就更好了。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<p>本文分四个部分，将从MapReduce论文讲起，分析项目代码是如何实现简化版的MapReduce框架，最后讲述实验内容的完成过程和总结反思。</p>\n\n        <h2 id=\"一、MapReduce论文理解与回顾\"   >\n          <a href=\"#一、MapReduce论文理解与回顾\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#一、MapReduce论文理解与回顾\" class=\"headerlink\" title=\"一、MapReduce论文理解与回顾\"></a>一、MapReduce论文理解与回顾</h2>\n      <p>MapReduce是一个用于处理大规模数据的分布式计算框架。分布式计算框架往往看重灵活易使用的前端，和高性能可拓展的后端，这在图计算和深度学习领域也是如此。而对MapReduce这个处理大规模同质数据的框架来说，应该从两方面来理解：一是它为程序员提供了什么样的抽象，给上层编程人员提供了什么样的编程模型，即编程时对此系统功能和性质的认识；二是它内部是如何实现，从而为上层提供多种支持和保证。</p>\n\n        <h3 id=\"Section-2-Programming-Model\"   >\n          <a href=\"#Section-2-Programming-Model\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Section-2-Programming-Model\" class=\"headerlink\" title=\"Section 2: Programming Model\"></a>Section 2: Programming Model</h3>\n      <p>编程模型是这篇工作最突出的贡献，它所解决的“重要的问题”在于给各种大规模计算在分布式编程时提供了便利。</p>\n<blockquote>\n<p>Users specify a <em>map</em> function that processes a key/value pair to generate a set of intermediate key/value pairs, and a <em>reduce</em> function that merges all intermediate values associated with the same intermediate key.</p>\n<figure class=\"highlight plain\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">map    (k1,v1)        → list(k2,v2)</span><br><span class=\"line\">reduce (k2,list(v2))  → list(v2)</span><br></pre></td></tr></table></div></figure>\n\n<p>the input keys and values are drawn from a different domain than the output keys and values. Furthermore, the intermediate keys and values are from the same do- main as the output keys and values.</p>\n<p>Our C++ implementation passes strings to and from the user-defined functions and leaves it to the user code to convert between strings and appropriate types.</p>\n</blockquote>\n<p>上面选取的是论文中Section 2的内容，主要明确用户定义的Map和Reduce函数的外在表现和要求（如键值对的域）。而要真正应用MapReduce框架，还需要对MapReduce的语义有更直观的理解，可参考论文Section 2.3部分。简单来说，一个任务是否适合使用MapReduce模型来解决，需要看是否满足以下两点要求：</p>\n<ul>\n<li>计算的数据规模大，需要利用并行与分布式计算来加速</li>\n<li>计算任务之间没有依赖，没有先后顺序关系，任务完成的先后顺序对结果没有影响（操作元满足交换律）</li>\n</ul>\n<p>当然，在云计算繁荣发展的今天，关于MapReduce模型的优化在学术界备受关注，最近的一篇工作提出用符号执行的方法破除顺序依赖，使MapReduce框架也能加速存在计算先后顺序的计算过程。</p>\n\n        <h3 id=\"Section-3-Implementation\"   >\n          <a href=\"#Section-3-Implementation\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Section-3-Implementation\" class=\"headerlink\" title=\"Section 3: Implementation\"></a>Section 3: Implementation</h3>\n      <p>框架实现是这篇工作的实际困难与巧妙解法，系统软件要做的就是将简单留给用户，复杂性留给自己。</p>\n<blockquote>\n<p>As a reaction to this complexity, we designed a new abstraction that allows us to express the simple computa- tions we were trying to perform but hides the messy de- tails of parallelization, fault-tolerance, data distribution and load balancing in a library.</p>\n<p>The run-time system takes care of the details of partitioning the input data, scheduling the program’s execution across a set of machines, handling ma- chine failures, and managing the required inter-machine communication.</p>\n</blockquote>\n\n        <h4 id=\"3-1-Execution-Overview\"   >\n          <a href=\"#3-1-Execution-Overview\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#3-1-Execution-Overview\" class=\"headerlink\" title=\"3.1 Execution Overview\"></a>3.1 <strong>Execution Overview</strong></h4>\n      <p>分布式计算任务的完成是一个框架首先考虑的事，理解执行过程才能理解分布式编程的一般思路（对实验的完成也很有帮助），其次才是容错、性能等方面，因此这里将引用论文中关于执行过程的全部说明。执行过程如下图所示：</p>\n<img src=\"/2021/05/29/MapReduce%E8%AE%BA%E6%96%87%E5%8F%8AMIT%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/exec_overview.png\" class=\"\">\n\n<blockquote>\n<ol>\n<li>The MapReduce library in the user program first splits the input files into M pieces of typically 16 megabytes to 64 megabytes (MB) per piece (con- trollable by the user via an optional parameter). It then starts up many copies of the program on a clus- ter of machines.</li>\n<li>One of the copies of the program is special – the master. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task.</li>\n<li>A worker who is assigned a map task reads the contents of the corresponding input split. It parses key/value pairs out of the input data and passes each pair to the user-defined <em>Map</em> function. The interme- diate key/value pairs produced by the <em>Map</em> function are buffered in memory.</li>\n<li>Periodically, <strong>the buffered pairs are written to local disk, partitioned into R regions by the partitioning function.</strong> The locations of these buffered pairs on the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers.</li>\n<li>When a reduce worker is notified by the master about these locations, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all in- termediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. <strong>If the amount of intermediate data is too large to fit in memory, an external sort is used.</strong></li>\n<li>The reduce worker iterates over the sorted interme- diate data and for each unique intermediate key en- countered, <strong>it passes the key and the corresponding set of intermediate values to the user’s <em>Reduce</em> func- tion.</strong> The output of the <em>Reduce</em> function is appended to a final output file for this reduce partition.</li>\n<li>When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user pro- gram returns back to the user code.</li>\n</ol>\n</blockquote>\n<p>以上过程标号与图中标号对应，文字加粗部分是个人认为需要着重记忆的或“smart”的实现。</p>\n\n        <h4 id=\"3-x-Other-Problem-in-Distributed-Systems\"   >\n          <a href=\"#3-x-Other-Problem-in-Distributed-Systems\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#3-x-Other-Problem-in-Distributed-Systems\" class=\"headerlink\" title=\"3.x Other Problem in Distributed Systems\"></a>3.x Other Problem in Distributed Systems</h4>\n      <p>Section 3的其他内容将在以下做简要概括：</p>\n<ul>\n<li><strong>Master Data Structures：</strong>Master是整个MapReduce过程的管理者，是Worker间通讯的线人，它将保存任务的状态，以及文件内容在文件系统中的位置等。</li>\n<li><strong>Fault Tolerance：</strong><ul>\n<li>Worker是无状态的，任意宕机的Worker上完成的任务可被其他Worker重做。</li>\n<li>Master只有一个，宕机的可能性很小，因此若Master宕机则MapReduce任务失败，交给应用来处理。</li>\n<li>并行与分布式计算的正确性需要通过和可能的顺序执行结果进行比较来衡量。本来每个Worker操作的数据对象是不重叠的，因此不会有并发错误，但Worker宕机导致的任务重做可能会使系统各部分看到的状态不同，这时 <code>We rely on atomic commits of map and reduce task outputs to achieve this property.</code> 包括两点：1. Map任务的完成由唯一的Master来仲裁；2. 底层的分布式文件系统提供rename的原子性来保证reduce输出唯一。</li>\n</ul>\n</li>\n<li><strong>Locality：</strong>任务调度要考虑局部性，避免数据的网络传输。实际上这点在大型分布式系统中非常重要！</li>\n<li><strong>Task Granularity</strong>：理论上任务粒度越细越好， <code>Having each worker perform many different tasks improves dynamic load balancing, and also speeds up recovery when a worker fails: the many map tasks it has completed can be spread out across all the other worker machines.</code> 但现实能够支持的调度数量是有限的，请记住以下数字：<code>We often per- form MapReduce computations with M = 200, 000 and R = 5, 000, using 2,000 worker machines.</code></li>\n<li><strong>Backup Tasks：</strong>木桶效应，分布式问题就像是管理问题，是调度问题。不同的机器能力不同，快的得等慢的，当然管机器比管人要容易的多。这里举李沐（交大学长，亚马逊CTO，分布式深度学习框架）的<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://zhuanlan.zhihu.com/p/374777591?utm_source=qq&utm_medium=social&utm_oi=989596755247349760\" >五年工作感悟</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>。 <code>When a MapReduce operation is close to completion, the master schedules backup executions of the remaining *in-progress* tasks.</code></li>\n</ul>\n<p>以上就是MapReduce论文1到3节的全部内容理解，对于今后把握项目整体思想、分析分布式编程主要问题都有所帮助。</p>\n\n        <h2 id=\"二、MapReduce代码框架分析\"   >\n          <a href=\"#二、MapReduce代码框架分析\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#二、MapReduce代码框架分析\" class=\"headerlink\" title=\"二、MapReduce代码框架分析\"></a>二、MapReduce代码框架分析</h2>\n      <p>实验代码MapReduce是由MIT设计实现的用于教学的简化版本，通过此版本可以更好的理解上述编程模型和底层执行过程。我们的关注点在于<code>wc.go</code>中的由我们定义的map和reduce函数，以及<code>mapreduce</code>包中的所有内容。</p>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">main</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(os.Args) &lt; <span class=\"number\">4</span> &#123;</span><br><span class=\"line\">\t\tfmt.Printf(<span class=\"string\">&quot;%s: see usage comments in file\\n&quot;</span>, os.Args[<span class=\"number\">0</span>])</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> <span class=\"keyword\">if</span> os.Args[<span class=\"number\">1</span>] == <span class=\"string\">&quot;master&quot;</span> &#123;</span><br><span class=\"line\">\t\t<span class=\"keyword\">var</span> mr *mapreduce.Master</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> os.Args[<span class=\"number\">2</span>] == <span class=\"string\">&quot;sequential&quot;</span> &#123;</span><br><span class=\"line\">\t\t\tmr = mapreduce.Sequential(<span class=\"string\">&quot;wcseq&quot;</span>, os.Args[<span class=\"number\">3</span>:], <span class=\"number\">3</span>, mapF, reduceF)</span><br><span class=\"line\">\t\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\t\tmr = mapreduce.Distributed(<span class=\"string\">&quot;wcseq&quot;</span>, os.Args[<span class=\"number\">3</span>:], <span class=\"number\">3</span>, os.Args[<span class=\"number\">2</span>])</span><br><span class=\"line\">\t\t&#125;</span><br><span class=\"line\">\t\tmr.Wait()</span><br><span class=\"line\">\t&#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">\t\tmapreduce.RunWorker(os.Args[<span class=\"number\">2</span>], os.Args[<span class=\"number\">3</span>], mapF, reduceF, <span class=\"number\">100</span>, <span class=\"literal\">nil</span>)</span><br><span class=\"line\">\t&#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<p>上面展示了<code>wc.go</code>中的<code>main</code>函数的内容。与论文附录中展示的代码类似，用户通过指定自定义的map和reduce函数，构造特殊的数据结构（实验中是传多个参数）作为<code>MapReduce</code>函数的调用参数来开始一项MapReduce任务。在实验代码实现的MapReduce框架中，<code>mapreduce.Sequential</code> 和 <code>mapreduce.Distributed</code> 是 <em>MapReduce</em> 对外提供的两个接口。由于正确实现的MapReduce框架可以与顺序执行产生同样的结果，实验代码设计了顺序执行的<code>mapreduce.Sequential</code>来方便我们调试，以及在编写用户map和reduce函数时加深对程序行为的认识。</p>\n\n        <h3 id=\"1-首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\"   >\n          <a href=\"#1-首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#1-首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\" class=\"headerlink\" title=\"1. 首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：\"></a>1. 首先我们沿着函数调用路径来分析代码逻辑和部件间的协作：</h3>\n      <p>由于真实的分布式计算框架只需提供 <code>mapreduce.Distributed</code> 即可，我们首先分析用户主函数通过 <code>mapreduce.Distributed</code> 的调用能否完成分布式计算任务。</p>\n<p> <code>mapreduce.Distributed</code> 调用层次图如下：<code>run</code>中的<code>schedule</code>是由<code>distribute</code>传入的。</p>\n<figure class=\"highlight plain\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">main</span><br><span class=\"line\">｜—— Distributed</span><br><span class=\"line\">    ｜—— newMaster</span><br><span class=\"line\">    ｜—— mr.startRPCServer</span><br><span class=\"line\">    ｜—— go mr.run</span><br><span class=\"line\">        ｜—— schedule(mapPhase)</span><br><span class=\"line\">            ｜—— go mr.forwardRegistrations(ch)</span><br><span class=\"line\">            ｜—— schedule(mr.jobName, mr.files, mr.nReduce, mapPhase, ch)</span><br><span class=\"line\">        \t｜—— go call(reg, &quot;Worker.DoTask&quot;, ...)</span><br><span class=\"line\">        ｜—— schedule(reducePhase)</span><br><span class=\"line\">            ｜—— go mr.forwardRegistrations(ch)</span><br><span class=\"line\">            ｜—— schedule(mr.jobName, mr.files, mr.nReduce, reducePhase, ch)</span><br><span class=\"line\">        \t｜—— go call(reg, &quot;Worker.DoTask&quot;, ...)</span><br><span class=\"line\">        ｜—— mr.merge()</span><br><span class=\"line\">        ｜—— mr.doneChannel &lt;- true</span><br><span class=\"line\">        ｜—— mr.killWorkers</span><br><span class=\"line\">        ｜—— mr.stopRPCServer</span><br><span class=\"line\">｜—— mr.Wait()</span><br></pre></td></tr></table></div></figure>\n\n<p>分析调用路径后，奇怪的是，整个调用过程没有Worker的参与，即使Master声明了RPC，也没有Worker注册。<strong>也就是说，用户不能仅通过 <code>mapreduce.Distributed</code> 的调用完成分布式并行计算任务，而需要<code>mapreduce.RunWorker</code>的配合，这与论文附录中的接口区别较大</strong>。</p>\n<p>那我们自定义的map和reduce函数在测试时并没有并行计算吗？是的。</p>\n<figure class=\"highlight shell\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\">!/bin/bash</span></span><br><span class=\"line\">go run wc.go master sequential pg-*.txt</span><br><span class=\"line\">sort -n -k2 mrtmp.wcseq | tail -10 | diff - mr-testout.txt &gt; diff.out</span><br><span class=\"line\">if [ -s diff.out ]</span><br><span class=\"line\">then</span><br><span class=\"line\">echo &quot;Failed test. Output should be as in mr-testout.txt. Your output differs as follows (from diff.out):&quot; &gt; /dev/stderr</span><br><span class=\"line\">  cat diff.out</span><br><span class=\"line\">else</span><br><span class=\"line\">  echo &quot;Passed test&quot; &gt; /dev/stderr</span><br><span class=\"line\">fi</span><br></pre></td></tr></table></div></figure>\n\n<p>上面展示了<code>test_wc.sh</code>中的内容，另外查看<code> test_ii.sh</code>以及<code>test_mr.sh</code>两个测试文件后，可以看出我们自己编写的两套map和reduce函数只运行在<code>sequential</code>模式下，这是很令人失望的。考察<code>RunWorker</code>函数的被调用情况，只有<code>test_test.go</code>中调用过，当然了，测试的执行和main的执行也没有本质的区别啦。。</p>\n\n        <h3 id=\"2-更重要的，从面向对象的角度分析如何从零构建MapReduce框架\"   >\n          <a href=\"#2-更重要的，从面向对象的角度分析如何从零构建MapReduce框架\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#2-更重要的，从面向对象的角度分析如何从零构建MapReduce框架\" class=\"headerlink\" title=\"2. 更重要的，从面向对象的角度分析如何从零构建MapReduce框架\"></a>2. 更重要的，从面向对象的角度分析如何从零构建MapReduce框架</h3>\n      <p>思考论文中Section 3的执行过程概述以及Master数据结构部分，我们要怎样在单机多核上实现并行计算呢？那我们可以用多线程模拟Master和Worker。</p>\n<ul>\n<li><p>Master管理MapReduce任务，记录整个任务的元数据（任务名、Map个数、Reduce个数等），实现数据集划分和任务调度的策略，负责与Worker通信进行任务分发（需要Master和Worker间制定协议），对Reduce的结果进行合并。</p>\n</li>\n<li><p>Worker负责map和reduce的执行，将用户定义的map和reduce函数应用在数据集上得到结果（结果在文件系统上共享需要协议）。</p>\n</li>\n</ul>\n<p>上面是论文中的要求，作为简化，实验代码中Master并未实现数据集的划分，而是需要用户划分后通过文件指定Map的数量（其实在论文附录的代码中也是这样做的）。</p>\n<p>用go语言实现是相对简单的，任务分发用RPC库，状态监视用goroutine加通道、信号量。mapreduce包中的每个文件都分工明确，整体上实验代码非常清晰、整洁。</p>\n\n        <h2 id=\"三、实验问题的解决思路和代码实现\"   >\n          <a href=\"#三、实验问题的解决思路和代码实现\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#三、实验问题的解决思路和代码实现\" class=\"headerlink\" title=\"三、实验问题的解决思路和代码实现\"></a>三、实验问题的解决思路和代码实现</h2>\n      \n        <h4 id=\"实验整体解决思路\"   >\n          <a href=\"#实验整体解决思路\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#实验整体解决思路\" class=\"headerlink\" title=\"实验整体解决思路\"></a>实验整体解决思路</h4>\n      <p>实验问题整体上并不复杂，解决思路实际上只要阅读代码，找到该函数被调用的语境，结合论文和实验文档理解函数需要完成的任务，对整个包内容即自己可以使用的现有资源有充分的认识，以及阅读注释和文档掌握编程细节和go语言库函数即可。不同部分的具体要求不同，思考的领域维度也不相同，但只要根据实验步骤，循序渐进，就会发现实验就像一个个puzzle一样，以阅读、理解、填空为主，既不会让人灰心丧气，还享受到克服困难、学习新语言的成就感。</p>\n<p>实现过程中，我并没有碰到太多Bug，让人印象深刻的是Part I的 <code>doReduce</code> 函数，以及Part III的 <code>schedule</code> 函数的Bug。</p>\n\n        <h3 id=\"Part-I-Map-Reduce-input-and-output\"   >\n          <a href=\"#Part-I-Map-Reduce-input-and-output\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-I-Map-Reduce-input-and-output\" class=\"headerlink\" title=\"Part I: Map/Reduce input and output\"></a>Part I: Map/Reduce input and output</h3>\n      <p>这一部分要求实现的是 <code>commen_map.go</code> 中的 <code>doMap</code> 函数和<code>commen_reduce.go</code> 中的 <code>doReduce</code> 函数。</p>\n<p><code>doMap</code> 函数：该函数的功能是完成单个给定的mapTask。其主要执行过程如下：</p>\n<ul>\n<li>创建中间键值文件，创建相应的<code>json.Encoder</code></li>\n<li>读入map任务的输入文件内容，用<code>ioutil.ReadFile()</code>，然后调用map函数得到中间键值对</li>\n<li>对键算哈希，确定键值对要写入的文件，然后以json格式写入</li>\n</ul>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">doMap</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   jobName <span class=\"keyword\">string</span>, // the name of the MapReduce job</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   mapTask <span class=\"keyword\">int</span>, // which <span class=\"keyword\">map</span> task this is</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   inFile <span class=\"keyword\">string</span>,</span></span></span><br><span class=\"line\">   nReduce int, // the number of reduce task that will be run (&quot;R&quot; in the paper)</span><br><span class=\"line\">   mapF <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(filename <span class=\"keyword\">string</span>, contents <span class=\"keyword\">string</span>)</span> []<span class=\"title\">KeyValue</span>,</span></span><br><span class=\"line\">) &#123;</span><br><span class=\"line\">   </span><br><span class=\"line\">   interFiles := <span class=\"built_in\">make</span>([]*os.File, nReduce)</span><br><span class=\"line\">   encoders := <span class=\"built_in\">make</span>([]*json.Encoder, nReduce)</span><br><span class=\"line\">   <span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; nReduce; i++ &#123;</span><br><span class=\"line\">      interFile, err := os.Create(reduceName(jobName, mapTask, i))</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      interFiles[i] = interFile</span><br><span class=\"line\">      encoders[i] = json.NewEncoder(interFile)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   inputFile, err := ioutil.ReadFile(inFile)</span><br><span class=\"line\">   <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">      log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   inputKeyValue := mapF(inFile, <span class=\"keyword\">string</span>(inputFile[:]))</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">for</span> _, _KeyValue := <span class=\"keyword\">range</span> inputKeyValue &#123;</span><br><span class=\"line\">      index := ihash(_KeyValue.Key) % nReduce</span><br><span class=\"line\">      err = encoders[index].Encode(&amp;_KeyValue)</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; nReduce; i++ &#123;</span><br><span class=\"line\">      err = interFiles[i].Close()</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<p><code>doReduce</code> 函数：该函数用来完成单个给定的reduceTask。其执行过程如下：</p>\n<ul>\n<li>收集由它负责的键值对，读出文件中用json编码的键值对：如注释中所述对一个文件不断decode直到报错为止</li>\n<li>按键排序，即把相同键的键值对聚集到一起</li>\n<li>创建输出文件，创建对应的<code>json.Encoder</code></li>\n<li>通过键的变化把相同键的所有值形成字符串数组，调用reduce函数得到结果，写入文件中</li>\n</ul>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">doReduce</span><span class=\"params\">(</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   jobName <span class=\"keyword\">string</span>, // the name of the whole MapReduce job</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   reduceTask <span class=\"keyword\">int</span>, // which reduce task this is</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">   outFile <span class=\"keyword\">string</span>, // write the output here</span></span></span><br><span class=\"line\">   nMap int, // the number of map tasks that were run (&quot;M&quot; in the paper)</span><br><span class=\"line\">   reduceF <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(key <span class=\"keyword\">string</span>, values []<span class=\"keyword\">string</span>)</span> <span class=\"title\">string</span>,</span></span><br><span class=\"line\">) &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">var</span> KeyValues []KeyValue</span><br><span class=\"line\">   <span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; nMap; i++ &#123;</span><br><span class=\"line\">      interFile, err := os.Open(reduceName(jobName, i, reduceTask))</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      decoder := json.NewDecoder(interFile)</span><br><span class=\"line\">      <span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">var</span> kv KeyValue</span><br><span class=\"line\">         err = decoder.Decode(&amp;kv)</span><br><span class=\"line\">         <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">         KeyValues = <span class=\"built_in\">append</span>(KeyValues, kv)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">      err = interFile.Close()</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   sort.Slice(KeyValues, <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(i, j <span class=\"keyword\">int</span>)</span> <span class=\"title\">bool</span></span> &#123;<span class=\"keyword\">return</span> KeyValues[i].Key &lt; KeyValues[j].Key&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\">   outputFile, err := os.Create(outFile)</span><br><span class=\"line\">   <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">      log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   encoder := json.NewEncoder(outputFile)</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"keyword\">var</span> values []<span class=\"keyword\">string</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> key <span class=\"keyword\">string</span></span><br><span class=\"line\">   <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(KeyValues) &gt; <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">      key = KeyValues[<span class=\"number\">0</span>].Key</span><br><span class=\"line\">      <span class=\"keyword\">for</span> _, kv := <span class=\"keyword\">range</span> KeyValues &#123;</span><br><span class=\"line\">         <span class=\"keyword\">if</span> kv.Key == key &#123;</span><br><span class=\"line\">            values = <span class=\"built_in\">append</span>(values, kv.Value)</span><br><span class=\"line\">         &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">            err = encoder.Encode(KeyValue&#123;key, reduceF(key, values)&#125;)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">               log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            values = <span class=\"built_in\">make</span>([]<span class=\"keyword\">string</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">            values = <span class=\"built_in\">append</span>(values, kv.Value)</span><br><span class=\"line\">            key = kv.Key</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">      err = encoder.Encode(KeyValue&#123;key, reduceF(key, values)&#125;)</span><br><span class=\"line\">      <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">         log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   err = outputFile.Close()</span><br><span class=\"line\">   <span class=\"keyword\">if</span> err != <span class=\"literal\">nil</span> &#123;</span><br><span class=\"line\">      log.Fatal(<span class=\"string\">&quot;check: &quot;</span>, err)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n\n\n\n\n        <h3 id=\"Part-II-Single-worker-word-count\"   >\n          <a href=\"#Part-II-Single-worker-word-count\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-II-Single-worker-word-count\" class=\"headerlink\" title=\"Part II: Single-worker word count\"></a>Part II: Single-worker word count</h3>\n      <p>这部分要仿照论文中示例给出自定义函数，也就是map处理输入的字符串对其中的每个单词输出中间键值对，因为中间键值对的值都是1所以reduce直接算中间值数组长度即可。</p>\n<p>本以为字符串处理和判断单词是个难事，点开文档链接一看就会了，甚至字符串转换都贴心的写好了参考。</p>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">mapF</span><span class=\"params\">(filename <span class=\"keyword\">string</span>, contents <span class=\"keyword\">string</span>)</span> []<span class=\"title\">mapreduce</span>.<span class=\"title\">KeyValue</span></span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part II).</span></span><br><span class=\"line\">   f := <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(c <span class=\"keyword\">rune</span>)</span> <span class=\"title\">bool</span></span> &#123;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> !unicode.IsLetter(c)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   words := strings.FieldsFunc(contents, f)</span><br><span class=\"line\">   <span class=\"keyword\">var</span> KeyValues []mapreduce.KeyValue</span><br><span class=\"line\">   <span class=\"keyword\">for</span> _, word := <span class=\"keyword\">range</span> words &#123;</span><br><span class=\"line\">      KeyValues = <span class=\"built_in\">append</span>(KeyValues, mapreduce.KeyValue&#123;word, <span class=\"string\">&quot;1&quot;</span>&#125;)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   <span class=\"keyword\">return</span> KeyValues</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">reduceF</span><span class=\"params\">(key <span class=\"keyword\">string</span>, values []<span class=\"keyword\">string</span>)</span> <span class=\"title\">string</span></span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part II).</span></span><br><span class=\"line\">   <span class=\"keyword\">return</span> strconv.Itoa(<span class=\"built_in\">len</span>(values))</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n\n\n\n        <h3 id=\"Part-III-Distributing-MapReduce-tasks\"   >\n          <a href=\"#Part-III-Distributing-MapReduce-tasks\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-III-Distributing-MapReduce-tasks\" class=\"headerlink\" title=\"Part III: Distributing MapReduce tasks\"></a>Part III: Distributing MapReduce tasks</h3>\n      <p>这部分是要上手并行计算了。也是实验中最有趣的部分，涉及go语言通道和信号量的使用。</p>\n<ul>\n<li>已知我们就是要调RPC，RPC不能阻塞因此要用go routine开协程来监视调用情况。</li>\n<li>RPC中参数构建较简单，弄清楚通道里的Worker address是怎么来的就会用了。已知Worker <code>DoTask</code> 结束后不会再次注册，因此RPC返回后要将该Worker重新放入通道。</li>\n<li>使用<code>sync.WaitGroup</code> 来同步所有RPC的结束。</li>\n</ul>\n<p>这里遇到了一个很关键的bug: <code>wg.done()</code> 和 <code>registerChan &lt;- worker</code> 这两句写反了。这就出现了输出中显示map task都做完了但就是无法输出<code>Schedule: mapPhase done</code> 这句话。说明主线程被阻塞住了，为什么呢？因为这个<code>registerChan</code> 通道是没有缓冲区的，也就是通道中最多只有一个值，再往进放就会阻塞住。于是产生了如下循环依赖：</p>\n<ul>\n<li>主线程在等所有协程<code>wg.done()</code> </li>\n<li>完成任务的协程在等主线程开新的协程消费通道中的内容，才好把信号放进通道中</li>\n</ul>\n<p><em><strong>我个人认为在创建通道时给通道声明task数量的缓冲区会更好，因为这样协程才会顺利退出，否则飘着的协程虽不影响主线程接下来的执行，但浪费内存空间，而且调度时会浪费CPU时间。</strong></em></p>\n<p>修改顺序后，打破循环依赖，就顺利通过测试了～</p>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">schedule</span><span class=\"params\">(jobName <span class=\"keyword\">string</span>, mapFiles []<span class=\"keyword\">string</span>, nReduce <span class=\"keyword\">int</span>, phase jobPhase, registerChan <span class=\"keyword\">chan</span> <span class=\"keyword\">string</span>)</span></span> &#123;</span><br><span class=\"line\">   <span class=\"keyword\">var</span> ntasks <span class=\"keyword\">int</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> n_other <span class=\"keyword\">int</span> <span class=\"comment\">// number of inputs (for reduce) or outputs (for map)</span></span><br><span class=\"line\">   <span class=\"keyword\">switch</span> phase &#123;</span><br><span class=\"line\">   <span class=\"keyword\">case</span> mapPhase:</span><br><span class=\"line\">      ntasks = <span class=\"built_in\">len</span>(mapFiles)</span><br><span class=\"line\">      n_other = nReduce</span><br><span class=\"line\">   <span class=\"keyword\">case</span> reducePhase:</span><br><span class=\"line\">      ntasks = nReduce</span><br><span class=\"line\">      n_other = <span class=\"built_in\">len</span>(mapFiles)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   fmt.Printf(<span class=\"string\">&quot;Schedule: %v %v tasks (%d I/Os)\\n&quot;</span>, ntasks, phase, n_other)</span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"comment\">// All ntasks tasks have to be scheduled on workers. Once all tasks</span></span><br><span class=\"line\">   <span class=\"comment\">// have completed successfully, schedule() should return.</span></span><br><span class=\"line\">   <span class=\"comment\">//</span></span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part III, Part IV).</span></span><br><span class=\"line\">   <span class=\"comment\">//</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> wg sync.WaitGroup</span><br><span class=\"line\">   wg.Add(ntasks)</span><br><span class=\"line\">   <span class=\"keyword\">for</span> i := <span class=\"number\">0</span>; i &lt; ntasks; i++ &#123;</span><br><span class=\"line\">      taskNumber := i</span><br><span class=\"line\">      <span class=\"keyword\">go</span> <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">()</span></span> &#123;</span><br><span class=\"line\">         <span class=\"keyword\">var</span> worker <span class=\"keyword\">string</span></span><br><span class=\"line\">         <span class=\"keyword\">for</span> &#123;</span><br><span class=\"line\">            reg := &lt;-registerChan</span><br><span class=\"line\">            result := call(reg, <span class=\"string\">&quot;Worker.DoTask&quot;</span>, DoTaskArgs&#123;</span><br><span class=\"line\">               JobName:       jobName,</span><br><span class=\"line\">               File:          mapFiles[taskNumber],</span><br><span class=\"line\">               Phase:         phase,</span><br><span class=\"line\">               TaskNumber:    taskNumber,</span><br><span class=\"line\">               NumOtherPhase: n_other,</span><br><span class=\"line\">            &#125;, <span class=\"literal\">nil</span>)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> result == <span class=\"literal\">true</span> &#123;</span><br><span class=\"line\">               worker = reg</span><br><span class=\"line\">               <span class=\"keyword\">break</span></span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">         wg.Done()</span><br><span class=\"line\">         registerChan &lt;- worker</span><br><span class=\"line\">      &#125;()</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   wg.Wait()</span><br><span class=\"line\">   fmt.Printf(<span class=\"string\">&quot;Schedule: %v done\\n&quot;</span>, phase)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n\n\n\n        <h3 id=\"Part-IV-Handling-worker-failures\"   >\n          <a href=\"#Part-IV-Handling-worker-failures\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-IV-Handling-worker-failures\" class=\"headerlink\" title=\"Part IV: Handling worker failures\"></a>Part IV: Handling worker failures</h3>\n      <p>此部分只需在上一部分的基础上加上循环，即在RPC失败时选取下一空闲的Worker重做任务，在RPC返回成功时退出即可。</p>\n<img src=\"/2021/05/29/MapReduce%E8%AE%BA%E6%96%87%E5%8F%8AMIT%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/fault_tolerate.jpeg\" class=\"\">\n\n<p>没想到只加了几行就通过测试了，但它确实是这样。</p>\n\n        <h3 id=\"Part-V-Inverted-index-generation-OPTIONAL\"   >\n          <a href=\"#Part-V-Inverted-index-generation-OPTIONAL\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Part-V-Inverted-index-generation-OPTIONAL\" class=\"headerlink\" title=\"Part V: Inverted index generation (OPTIONAL)\"></a>Part V: Inverted index generation (OPTIONAL)</h3>\n      <p>这部分要完成倒排索引的建立，其实就是加深对map和reduce函数语义的认识，用它们做更多有意义的事。</p>\n<img src=\"/2021/05/29/MapReduce%E8%AE%BA%E6%96%87%E5%8F%8AMIT%E7%9B%B8%E5%85%B3%E5%AE%9E%E9%AA%8C%E6%80%BB%E7%BB%93/invert_index.jpeg\" class=\"\">\n\n<p>如上图所示，黑色是词数统计的过程，蓝色是倒排索引的区别。将生成倒排索引的任务与此前的词数统计做对比，很容易知道该如何改进。</p>\n<p>这里关键问题是去除重复，这里选择在reduce阶段做，这样编程更简洁明了，同时很容易证明是正确的。去除重复采用和Part I <code>doReduce</code> 中类似的方法，将所有中间value排序，然后统计不同的内容。</p>\n<figure class=\"highlight go\"><div class=\"table-container\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">mapF</span><span class=\"params\">(document <span class=\"keyword\">string</span>, value <span class=\"keyword\">string</span>)</span> <span class=\"params\">(res []mapreduce.KeyValue)</span></span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part V).</span></span><br><span class=\"line\">   f := <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(c <span class=\"keyword\">rune</span>)</span> <span class=\"title\">bool</span></span> &#123;</span><br><span class=\"line\">      <span class=\"keyword\">return</span> !unicode.IsLetter(c)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">   words := strings.FieldsFunc(value, f)</span><br><span class=\"line\">   <span class=\"keyword\">var</span> KeyValues []mapreduce.KeyValue</span><br><span class=\"line\">   <span class=\"keyword\">for</span> _, word := <span class=\"keyword\">range</span> words &#123;</span><br><span class=\"line\">      KeyValues = <span class=\"built_in\">append</span>(KeyValues, mapreduce.KeyValue&#123;word, document&#125;)</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   <span class=\"keyword\">return</span> KeyValues</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">func</span> <span class=\"title\">reduceF</span><span class=\"params\">(key <span class=\"keyword\">string</span>, values []<span class=\"keyword\">string</span>)</span> <span class=\"title\">string</span></span> &#123;</span><br><span class=\"line\">   <span class=\"comment\">// Your code here (Part V).</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> reduceValue []<span class=\"keyword\">string</span></span><br><span class=\"line\">   <span class=\"keyword\">var</span> lastValue <span class=\"keyword\">string</span></span><br><span class=\"line\">   sort.Slice(values, <span class=\"function\"><span class=\"keyword\">func</span><span class=\"params\">(i, j <span class=\"keyword\">int</span>)</span> <span class=\"title\">bool</span></span> &#123;<span class=\"keyword\">return</span> values[i] &lt; values[j]&#125;)</span><br><span class=\"line\">   <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(values) &gt; <span class=\"number\">0</span> &#123;</span><br><span class=\"line\">      reduceValue = <span class=\"built_in\">append</span>(reduceValue, values[<span class=\"number\">0</span>])</span><br><span class=\"line\">      lastValue = values[<span class=\"number\">0</span>]</span><br><span class=\"line\">      <span class=\"keyword\">for</span> _, value := <span class=\"keyword\">range</span> values &#123;</span><br><span class=\"line\">         <span class=\"keyword\">if</span> value != lastValue &#123;</span><br><span class=\"line\">            reduceValue = <span class=\"built_in\">append</span>(reduceValue, value)</span><br><span class=\"line\">            lastValue = value</span><br><span class=\"line\">         &#125;</span><br><span class=\"line\">      &#125;</span><br><span class=\"line\">   &#125;</span><br><span class=\"line\">   <span class=\"keyword\">return</span> strconv.Itoa(<span class=\"built_in\">len</span>(reduceValue)) + <span class=\"string\">&quot; &quot;</span> + strings.Join(reduceValue, <span class=\"string\">&quot;,&quot;</span>)</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n\n\n\n        <h2 id=\"四、实验过程总结与反思\"   >\n          <a href=\"#四、实验过程总结与反思\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#四、实验过程总结与反思\" class=\"headerlink\" title=\"四、实验过程总结与反思\"></a>四、实验过程总结与反思</h2>\n      <p>从科研项目的角度看，我越来越理解高校搞科研面对的问题：资源的限制。</p>\n<ul>\n<li><p>由MIT设计的这个实验，是运行在单机上的简化版本，作为我们这次云计算课程实验，它与我曾做过的其他众多实验体量类似，也没有实际应用的能力，如果不是作为名校开源的教材，可能没几个人会注意到这份框架实现。</p>\n</li>\n<li><p>这篇分布式场景下的经典工作，出自谷歌。假设MIT先想到搞这样的研究，不与企业合作的话，倒也可以写一个版本，但evaluation没法在真实场景下测只能模拟、调研工作也会比企业的人付出更多更多，最后发论文后也很难有实际项目落地。相比之下，企业做这样的研究就容易很多：Google发论文无数、微软研究院与英特尔是好兄弟，动不动就改硬件发论文、阿里达摩院宣讲时论文的产出等等。</p>\n</li>\n<li><p>所以，<strong>要与企业良性合作，互利互惠</strong>，做适应工业界当下需求的科研，积极与工业界交流。</p>\n</li>\n</ul>\n<p>从课程实验的角度看，该实验如果在以下方面作出改进会更好：</p>\n<ol>\n<li>简化注释，可将注释内容转移到文档中，以不经意的形式。这次实验注释过于详尽，使同学对很多数据结构的设计都缺乏思考。</li>\n<li>增加问题练习，在文档中增加需要在实验报告中回答的问题，加深同学对重点的理解。不仅能看懂，而且会表达。</li>\n<li>补充测试，这次实验测试过于简单，显然遗漏了某些边界情况，而且Part V自定义函数运行在Sequential模式下（过度简化）。随随便便就过了测试不能让同学们养成编程时缜密的思考方式。</li>\n<li>论文中有<code>If the amount of intermediate data is too large to fit in memory, an external sort is used.</code> 这样的描述，迭代器在数据量大时很常用，但如何构造和实现迭代器依然很陌生，如果简化框架能加入迭代器的实现就更好了。</li>\n</ol>\n"},{"title":"Manjaro安装配置踩坑","date":"2021-06-02T09:32:55.000Z","_content":"\n\n\n## MacOS制作启动盘\n\n[Mac 制作 Linux 启动盘](https://www.cnblogs.com/sitoi/p/13047622.html)\n\n[mac os x 下查看dd命令刻录U盘的进度](https://blog.csdn.net/weixin_33807284/article/details/92859241)\n\n\n\n## Manjaro 21.05 安装和配置\n\nArchLinux官网：https://archlinux.org/\n\n - [学习环境配置：Manjaro、MSYS2以及常见软件](https://www.cnblogs.com/wurui1994/p/6279501.html)\n - [最受欢迎的Linux发行版, Manjaro折腾全记录（超长超详细）](\"https://www.jianshu.com/p/21c39bc4dd31\")\n- [manjaro最新搜狗输入法安装教程](\"https://www.136.la/java/show-55970.html\")\n- [Linux(Manjaro) -Docker 安装及基本配置](https://www.cnblogs.com/imzhizi/p/10718310.html)\n\n\n\n\n## Ubuntu 18.04 安装和配置\n[Ubuntu 18.04 安装和配置](https://zhuanlan.zhihu.com/p/38364829)\n\n\n\n## 源码阅读利器：UnderStand安装与踩坑\n\n### 1）Understand用法及Linux安装指南\n\n - [Understand: 静态代码分析神器](https://zhuanlan.zhihu.com/p/44776823)\n - [Understand(源码阅读器)Installing on Linux and Solaris](https://support.scitools.com/t/installing-on-linux-and-solaris/34)\n\n### 2）Understand在Manjaro上运行报错的解决\n\n根据上述的Understand官网上的Linux安装指南，在Ubuntu 20.04上可以正常运行，但在Manjaro 21.05上出现如下错误：\n\n在`./understand` 时报错：\n\n​\t`./understand: symbol lookup error: /usr/lib/libfontconfig.so.1: undefined symbol: FT_Done_MM_Var`\n\n为此我作出以下调研和尝试：\n\n1. 其他软件的相似问题和解决方式：\n - [Tecplot运行报错:undefined symbol: FT_Done_MM_Var](https://blog.csdn.net/weixin_41174045/article/details/115741968)\n - [Err：undefined symbol：FT_Done_MM_Var 及 .so 文件替换方法](https://blog.csdn.net/qq_45569859/article/details/103341971)\n2. Linux使用动态库时的undefined symbol问题：\n - [Linux C编程问题：symbol lookup error: xxx undefined symbol xxx](https://blog.csdn.net/guangyacyb/article/details/85165231?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.control)\n - [\"symbol lookup error\"问题解决](https://blog.csdn.net/dfman1978/article/details/6104544)\n3. LinuxQuestions上的相似问题：\n - [libreoffice libfontconfig.so.1: undefined symbol: FT_Done_MM_Var](https://www.linuxquestions.org/questions/slackware-14/libreoffice-libfontconfig-so-1-undefined-symbol-ft_done_mm_var-4175665794/?__cf_chl_jschl_tk__=369654a585808df0dfb545a61055e86a3c75a6a9-1622624792-0-AdAhDup71USuBhSCHZOhTIyF2Qkc9S7lvAPBCx90jYXf1-1KrPFU2Bu4tF1dQcH1KLNQQMXeVkCkjetRZ2bYxDIngiM26sx6ocPE0HKlyhlp-8VoX_ar9vQqV7M-5sgP8zwHt_AdrPGaCay-ahSIgrYL25MNCS260O4WwvanLcVNOjVc3jlsGZphOymef5vs_SGJy70B5y6fZpGDVQLIM7qizqEhOIt2lP0L1FIIWzu3iRIt7_Ozi7I6LLZlxS2oNb5pBqJULDEJQ2iymBO5q7F6-85iMPfBVCSPGw_6Eq67BbgvH3C8PLaszRAaaYyKk8xTRZbbL2-h47yY8shc_2RcTpaU3JlOKbBX1OW6suFe96CSfvxr1PBUjP1EsE9KSlYtQo0P8fHBH8uGbdVsVAsjT1In4NOPuYeXWRO74RCbe7qS8N10mP7KOPuwt-Q39umxi9Xq_o8B6B0dwCZq9-e65zZEqDQMBAfAw7OKqau0x7SfJWIK6CK9-aGx4dPbuS_skJOmxJNWwN6DuaavTsddgQSqZcwroEFjwdzbtS6s4zBWI3OXS3ilQN3GNDOMtr4dhqaxJT9UYxAaJfZkOAo)\n\n从这些链接中我学到Linux使用动态库时需注意的问题和很多有用的Linux命令（如`ldd` 、`nm` 、`grep` 等），同时也发现自己**对make的过程，Makefile的编写等还不熟悉**，希望后面将这块知识补上。\n\n在调试的过程中我尝试了上述链接中的方法，但manjaro的`/usr/lib/`中 `libfreetype.so` 和`libfontconfig.so`都存在，`/usr/lib/libfontconfig.so`依赖于`/usr/liblib/freetype.so`，且`FT_Done_MM_Var\t` 也在`libfreetype.so` 中定义了。而Understand的源码和makefile文件无法找到，因此**不能通过修改编译过程解决**。已知Understand在Ubuntu 18.04上可以正常运行，而Manjaro 21.05与Ubuntu的唯一区别在于Manjaro的Linux系统版本是5.10，而Ubuntu的系统版本是5.8，两系统中`libfontconfig`的版本一致（都是`libfontconfig.so.1.12.0`，而`libfreetype`的版本不同（Manjaro是`libfreetype.so.6.17.4`，Ubuntu是`libfreetype.so.6.17.1`），因此可能的问题应该与第一个链接（[Tecplot运行报错](https://blog.csdn.net/weixin_41174045/article/details/115741968)）相似，**需要降低Linux系统版本**。\n\nManjaro换内核的帖子（[链接](https://tieba.baidu.com/p/6406292549)），尝试无果。\n\n最后，***将understand安装目录中`/bin/linux64` 下的 `libfreetype.so.6` 删除，运行成功！***\n\n反向思考错误原因，应该是`/bin/linux/libfreetype.so` 版本低，没有定义FT_Done_MM_Var，使用`/bin/linux/libfreetype.so` 时会加载系统的`/usr/lib/libfontconfig.so.1` 动态库。该动态库依赖的是版本较高的`/usr/lib/libfreetype.so`，而后者因为相同的库已存在所以没有加载，至此问题解决。\n\n\n\n## Linux命令学习与积累\n\n - [Linux df 命令](https://www.runoob.com/linux/linux-comm-df.html)\n - [Linux locate命令](https://www.runoob.com/linux/linux-comm-locate.html)\n    - [\\[SOLVED]Locate command not found](https://bbs.archlinux.org/viewtopic.php?id=99084)\n - [Linux grep 命令](https://www.runoob.com/linux/linux-comm-grep.html)\n - [Linux下nm和ldd命令](https://blog.csdn.net/netwalk/article/details/19335771)\n\n\n\n","source":"_posts/Manjaro安装配置踩坑.md","raw":"---\ntitle: Manjaro安装配置踩坑\ndate: 2021-06-02 17:32:55\ntags:\n---\n\n\n\n## MacOS制作启动盘\n\n[Mac 制作 Linux 启动盘](https://www.cnblogs.com/sitoi/p/13047622.html)\n\n[mac os x 下查看dd命令刻录U盘的进度](https://blog.csdn.net/weixin_33807284/article/details/92859241)\n\n\n\n## Manjaro 21.05 安装和配置\n\nArchLinux官网：https://archlinux.org/\n\n - [学习环境配置：Manjaro、MSYS2以及常见软件](https://www.cnblogs.com/wurui1994/p/6279501.html)\n - [最受欢迎的Linux发行版, Manjaro折腾全记录（超长超详细）](\"https://www.jianshu.com/p/21c39bc4dd31\")\n- [manjaro最新搜狗输入法安装教程](\"https://www.136.la/java/show-55970.html\")\n- [Linux(Manjaro) -Docker 安装及基本配置](https://www.cnblogs.com/imzhizi/p/10718310.html)\n\n\n\n\n## Ubuntu 18.04 安装和配置\n[Ubuntu 18.04 安装和配置](https://zhuanlan.zhihu.com/p/38364829)\n\n\n\n## 源码阅读利器：UnderStand安装与踩坑\n\n### 1）Understand用法及Linux安装指南\n\n - [Understand: 静态代码分析神器](https://zhuanlan.zhihu.com/p/44776823)\n - [Understand(源码阅读器)Installing on Linux and Solaris](https://support.scitools.com/t/installing-on-linux-and-solaris/34)\n\n### 2）Understand在Manjaro上运行报错的解决\n\n根据上述的Understand官网上的Linux安装指南，在Ubuntu 20.04上可以正常运行，但在Manjaro 21.05上出现如下错误：\n\n在`./understand` 时报错：\n\n​\t`./understand: symbol lookup error: /usr/lib/libfontconfig.so.1: undefined symbol: FT_Done_MM_Var`\n\n为此我作出以下调研和尝试：\n\n1. 其他软件的相似问题和解决方式：\n - [Tecplot运行报错:undefined symbol: FT_Done_MM_Var](https://blog.csdn.net/weixin_41174045/article/details/115741968)\n - [Err：undefined symbol：FT_Done_MM_Var 及 .so 文件替换方法](https://blog.csdn.net/qq_45569859/article/details/103341971)\n2. Linux使用动态库时的undefined symbol问题：\n - [Linux C编程问题：symbol lookup error: xxx undefined symbol xxx](https://blog.csdn.net/guangyacyb/article/details/85165231?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-5.control)\n - [\"symbol lookup error\"问题解决](https://blog.csdn.net/dfman1978/article/details/6104544)\n3. LinuxQuestions上的相似问题：\n - [libreoffice libfontconfig.so.1: undefined symbol: FT_Done_MM_Var](https://www.linuxquestions.org/questions/slackware-14/libreoffice-libfontconfig-so-1-undefined-symbol-ft_done_mm_var-4175665794/?__cf_chl_jschl_tk__=369654a585808df0dfb545a61055e86a3c75a6a9-1622624792-0-AdAhDup71USuBhSCHZOhTIyF2Qkc9S7lvAPBCx90jYXf1-1KrPFU2Bu4tF1dQcH1KLNQQMXeVkCkjetRZ2bYxDIngiM26sx6ocPE0HKlyhlp-8VoX_ar9vQqV7M-5sgP8zwHt_AdrPGaCay-ahSIgrYL25MNCS260O4WwvanLcVNOjVc3jlsGZphOymef5vs_SGJy70B5y6fZpGDVQLIM7qizqEhOIt2lP0L1FIIWzu3iRIt7_Ozi7I6LLZlxS2oNb5pBqJULDEJQ2iymBO5q7F6-85iMPfBVCSPGw_6Eq67BbgvH3C8PLaszRAaaYyKk8xTRZbbL2-h47yY8shc_2RcTpaU3JlOKbBX1OW6suFe96CSfvxr1PBUjP1EsE9KSlYtQo0P8fHBH8uGbdVsVAsjT1In4NOPuYeXWRO74RCbe7qS8N10mP7KOPuwt-Q39umxi9Xq_o8B6B0dwCZq9-e65zZEqDQMBAfAw7OKqau0x7SfJWIK6CK9-aGx4dPbuS_skJOmxJNWwN6DuaavTsddgQSqZcwroEFjwdzbtS6s4zBWI3OXS3ilQN3GNDOMtr4dhqaxJT9UYxAaJfZkOAo)\n\n从这些链接中我学到Linux使用动态库时需注意的问题和很多有用的Linux命令（如`ldd` 、`nm` 、`grep` 等），同时也发现自己**对make的过程，Makefile的编写等还不熟悉**，希望后面将这块知识补上。\n\n在调试的过程中我尝试了上述链接中的方法，但manjaro的`/usr/lib/`中 `libfreetype.so` 和`libfontconfig.so`都存在，`/usr/lib/libfontconfig.so`依赖于`/usr/liblib/freetype.so`，且`FT_Done_MM_Var\t` 也在`libfreetype.so` 中定义了。而Understand的源码和makefile文件无法找到，因此**不能通过修改编译过程解决**。已知Understand在Ubuntu 18.04上可以正常运行，而Manjaro 21.05与Ubuntu的唯一区别在于Manjaro的Linux系统版本是5.10，而Ubuntu的系统版本是5.8，两系统中`libfontconfig`的版本一致（都是`libfontconfig.so.1.12.0`，而`libfreetype`的版本不同（Manjaro是`libfreetype.so.6.17.4`，Ubuntu是`libfreetype.so.6.17.1`），因此可能的问题应该与第一个链接（[Tecplot运行报错](https://blog.csdn.net/weixin_41174045/article/details/115741968)）相似，**需要降低Linux系统版本**。\n\nManjaro换内核的帖子（[链接](https://tieba.baidu.com/p/6406292549)），尝试无果。\n\n最后，***将understand安装目录中`/bin/linux64` 下的 `libfreetype.so.6` 删除，运行成功！***\n\n反向思考错误原因，应该是`/bin/linux/libfreetype.so` 版本低，没有定义FT_Done_MM_Var，使用`/bin/linux/libfreetype.so` 时会加载系统的`/usr/lib/libfontconfig.so.1` 动态库。该动态库依赖的是版本较高的`/usr/lib/libfreetype.so`，而后者因为相同的库已存在所以没有加载，至此问题解决。\n\n\n\n## Linux命令学习与积累\n\n - [Linux df 命令](https://www.runoob.com/linux/linux-comm-df.html)\n - [Linux locate命令](https://www.runoob.com/linux/linux-comm-locate.html)\n    - [\\[SOLVED]Locate command not found](https://bbs.archlinux.org/viewtopic.php?id=99084)\n - [Linux grep 命令](https://www.runoob.com/linux/linux-comm-grep.html)\n - [Linux下nm和ldd命令](https://blog.csdn.net/netwalk/article/details/19335771)\n\n\n\n","slug":"Manjaro安装配置踩坑","published":1,"updated":"2021-06-03T12:25:22.712Z","_id":"ckpgvf0wu0000uaoz961y7yzv","comments":1,"layout":"post","photos":[],"link":"","content":"\n        <h2 id=\"MacOS制作启动盘\"   >\n          <a href=\"#MacOS制作启动盘\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#MacOS制作启动盘\" class=\"headerlink\" title=\"MacOS制作启动盘\"></a>MacOS制作启动盘</h2>\n      <p><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.cnblogs.com/sitoi/p/13047622.html\" >Mac 制作 Linux 启动盘</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n<p><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/weixin_33807284/article/details/92859241\" >mac os x 下查看dd命令刻录U盘的进度</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h2 id=\"Manjaro-21-05-安装和配置\"   >\n          <a href=\"#Manjaro-21-05-安装和配置\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Manjaro-21-05-安装和配置\" class=\"headerlink\" title=\"Manjaro 21.05 安装和配置\"></a>Manjaro 21.05 安装和配置</h2>\n      <p>ArchLinux官网：<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://archlinux.org/\" >https://archlinux.org/</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n<ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.cnblogs.com/wurui1994/p/6279501.html\" >学习环境配置：Manjaro、MSYS2以及常见软件</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><a href=\"%22https://www.jianshu.com/p/21c39bc4dd31%22\">最受欢迎的Linux发行版, Manjaro折腾全记录（超长超详细）</a></li>\n<li><a href=\"%22https://www.136.la/java/show-55970.html%22\">manjaro最新搜狗输入法安装教程</a></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.cnblogs.com/imzhizi/p/10718310.html\" >Linux(Manjaro) -Docker 安装及基本配置</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n\n        <h2 id=\"Ubuntu-18-04-安装和配置\"   >\n          <a href=\"#Ubuntu-18-04-安装和配置\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Ubuntu-18-04-安装和配置\" class=\"headerlink\" title=\"Ubuntu 18.04 安装和配置\"></a>Ubuntu 18.04 安装和配置</h2>\n      <p><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://zhuanlan.zhihu.com/p/38364829\" >Ubuntu 18.04 安装和配置</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h2 id=\"源码阅读利器：UnderStand安装与踩坑\"   >\n          <a href=\"#源码阅读利器：UnderStand安装与踩坑\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#源码阅读利器：UnderStand安装与踩坑\" class=\"headerlink\" title=\"源码阅读利器：UnderStand安装与踩坑\"></a>源码阅读利器：UnderStand安装与踩坑</h2>\n      \n        <h3 id=\"1）Understand用法及Linux安装指南\"   >\n          <a href=\"#1）Understand用法及Linux安装指南\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#1）Understand用法及Linux安装指南\" class=\"headerlink\" title=\"1）Understand用法及Linux安装指南\"></a>1）Understand用法及Linux安装指南</h3>\n      <ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://zhuanlan.zhihu.com/p/44776823\" >Understand: 静态代码分析神器</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://support.scitools.com/t/installing-on-linux-and-solaris/34\" >Understand(源码阅读器)Installing on Linux and Solaris</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n\n        <h3 id=\"2）Understand在Manjaro上运行报错的解决\"   >\n          <a href=\"#2）Understand在Manjaro上运行报错的解决\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#2）Understand在Manjaro上运行报错的解决\" class=\"headerlink\" title=\"2）Understand在Manjaro上运行报错的解决\"></a>2）Understand在Manjaro上运行报错的解决</h3>\n      <p>根据上述的Understand官网上的Linux安装指南，在Ubuntu 20.04上可以正常运行，但在Manjaro 21.05上出现如下错误：</p>\n<p>在<code>./understand</code> 时报错：</p>\n<p>​    <code>./understand: symbol lookup error: /usr/lib/libfontconfig.so.1: undefined symbol: FT_Done_MM_Var</code></p>\n<p>为此我作出以下调研和尝试：</p>\n<ol>\n<li>其他软件的相似问题和解决方式：</li>\n</ol>\n<ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/weixin_41174045/article/details/115741968\" >Tecplot运行报错:undefined symbol: FT_Done_MM_Var</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/qq_45569859/article/details/103341971\" >Err：undefined symbol：FT_Done_MM_Var 及 .so 文件替换方法</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n<ol start=\"2\">\n<li>Linux使用动态库时的undefined symbol问题：</li>\n</ol>\n<ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/guangyacyb/article/details/85165231?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-5.control\" >Linux C编程问题：symbol lookup error: xxx undefined symbol xxx</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/dfman1978/article/details/6104544\" >“symbol lookup error”问题解决</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n<ol start=\"3\">\n<li>LinuxQuestions上的相似问题：</li>\n</ol>\n<ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.linuxquestions.org/questions/slackware-14/libreoffice-libfontconfig-so-1-undefined-symbol-ft_done_mm_var-4175665794/?__cf_chl_jschl_tk__=369654a585808df0dfb545a61055e86a3c75a6a9-1622624792-0-AdAhDup71USuBhSCHZOhTIyF2Qkc9S7lvAPBCx90jYXf1-1KrPFU2Bu4tF1dQcH1KLNQQMXeVkCkjetRZ2bYxDIngiM26sx6ocPE0HKlyhlp-8VoX_ar9vQqV7M-5sgP8zwHt_AdrPGaCay-ahSIgrYL25MNCS260O4WwvanLcVNOjVc3jlsGZphOymef5vs_SGJy70B5y6fZpGDVQLIM7qizqEhOIt2lP0L1FIIWzu3iRIt7_Ozi7I6LLZlxS2oNb5pBqJULDEJQ2iymBO5q7F6-85iMPfBVCSPGw_6Eq67BbgvH3C8PLaszRAaaYyKk8xTRZbbL2-h47yY8shc_2RcTpaU3JlOKbBX1OW6suFe96CSfvxr1PBUjP1EsE9KSlYtQo0P8fHBH8uGbdVsVAsjT1In4NOPuYeXWRO74RCbe7qS8N10mP7KOPuwt-Q39umxi9Xq_o8B6B0dwCZq9-e65zZEqDQMBAfAw7OKqau0x7SfJWIK6CK9-aGx4dPbuS_skJOmxJNWwN6DuaavTsddgQSqZcwroEFjwdzbtS6s4zBWI3OXS3ilQN3GNDOMtr4dhqaxJT9UYxAaJfZkOAo\" >libreoffice libfontconfig.so.1: undefined symbol: FT_Done_MM_Var</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n<p>从这些链接中我学到Linux使用动态库时需注意的问题和很多有用的Linux命令（如<code>ldd</code> 、<code>nm</code> 、<code>grep</code> 等），同时也发现自己<strong>对make的过程，Makefile的编写等还不熟悉</strong>，希望后面将这块知识补上。</p>\n<p>在调试的过程中我尝试了上述链接中的方法，但manjaro的<code>/usr/lib/</code>中 <code>libfreetype.so</code> 和<code>libfontconfig.so</code>都存在，<code>/usr/lib/libfontconfig.so</code>依赖于<code>/usr/liblib/freetype.so</code>，且<code>FT_Done_MM_Var    </code> 也在<code>libfreetype.so</code> 中定义了。而Understand的源码和makefile文件无法找到，因此<strong>不能通过修改编译过程解决</strong>。已知Understand在Ubuntu 18.04上可以正常运行，而Manjaro 21.05与Ubuntu的唯一区别在于Manjaro的Linux系统版本是5.10，而Ubuntu的系统版本是5.8，两系统中<code>libfontconfig</code>的版本一致（都是<code>libfontconfig.so.1.12.0</code>，而<code>libfreetype</code>的版本不同（Manjaro是<code>libfreetype.so.6.17.4</code>，Ubuntu是<code>libfreetype.so.6.17.1</code>），因此可能的问题应该与第一个链接（<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/weixin_41174045/article/details/115741968\" >Tecplot运行报错</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>）相似，<strong>需要降低Linux系统版本</strong>。</p>\n<p>Manjaro换内核的帖子（<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://tieba.baidu.com/p/6406292549\" >链接</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>），尝试无果。</p>\n<p>最后，<em><strong>将understand安装目录中<code>/bin/linux64</code> 下的 <code>libfreetype.so.6</code> 删除，运行成功！</strong></em></p>\n<p>反向思考错误原因，应该是<code>/bin/linux/libfreetype.so</code> 版本低，没有定义FT_Done_MM_Var，使用<code>/bin/linux/libfreetype.so</code> 时会加载系统的<code>/usr/lib/libfontconfig.so.1</code> 动态库。该动态库依赖的是版本较高的<code>/usr/lib/libfreetype.so</code>，而后者因为相同的库已存在所以没有加载，至此问题解决。</p>\n\n        <h2 id=\"Linux命令学习与积累\"   >\n          <a href=\"#Linux命令学习与积累\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Linux命令学习与积累\" class=\"headerlink\" title=\"Linux命令学习与积累\"></a>Linux命令学习与积累</h2>\n      <ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.runoob.com/linux/linux-comm-df.html\" >Linux df 命令</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.runoob.com/linux/linux-comm-locate.html\" >Linux locate命令</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span><ul>\n<li>[[SOLVED]Locate command not found](<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://bbs.archlinux.org/viewtopic.php?id=99084\" >https://bbs.archlinux.org/viewtopic.php?id=99084</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>)</li>\n</ul>\n</li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.runoob.com/linux/linux-comm-grep.html\" >Linux grep 命令</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/netwalk/article/details/19335771\" >Linux下nm和ldd命令</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"\n        <h2 id=\"MacOS制作启动盘\"   >\n          <a href=\"#MacOS制作启动盘\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#MacOS制作启动盘\" class=\"headerlink\" title=\"MacOS制作启动盘\"></a>MacOS制作启动盘</h2>\n      <p><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.cnblogs.com/sitoi/p/13047622.html\" >Mac 制作 Linux 启动盘</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n<p><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/weixin_33807284/article/details/92859241\" >mac os x 下查看dd命令刻录U盘的进度</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h2 id=\"Manjaro-21-05-安装和配置\"   >\n          <a href=\"#Manjaro-21-05-安装和配置\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Manjaro-21-05-安装和配置\" class=\"headerlink\" title=\"Manjaro 21.05 安装和配置\"></a>Manjaro 21.05 安装和配置</h2>\n      <p>ArchLinux官网：<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://archlinux.org/\" >https://archlinux.org/</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n<ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.cnblogs.com/wurui1994/p/6279501.html\" >学习环境配置：Manjaro、MSYS2以及常见软件</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><a href=\"%22https://www.jianshu.com/p/21c39bc4dd31%22\">最受欢迎的Linux发行版, Manjaro折腾全记录（超长超详细）</a></li>\n<li><a href=\"%22https://www.136.la/java/show-55970.html%22\">manjaro最新搜狗输入法安装教程</a></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.cnblogs.com/imzhizi/p/10718310.html\" >Linux(Manjaro) -Docker 安装及基本配置</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n\n        <h2 id=\"Ubuntu-18-04-安装和配置\"   >\n          <a href=\"#Ubuntu-18-04-安装和配置\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Ubuntu-18-04-安装和配置\" class=\"headerlink\" title=\"Ubuntu 18.04 安装和配置\"></a>Ubuntu 18.04 安装和配置</h2>\n      <p><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://zhuanlan.zhihu.com/p/38364829\" >Ubuntu 18.04 安装和配置</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></p>\n\n        <h2 id=\"源码阅读利器：UnderStand安装与踩坑\"   >\n          <a href=\"#源码阅读利器：UnderStand安装与踩坑\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#源码阅读利器：UnderStand安装与踩坑\" class=\"headerlink\" title=\"源码阅读利器：UnderStand安装与踩坑\"></a>源码阅读利器：UnderStand安装与踩坑</h2>\n      \n        <h3 id=\"1）Understand用法及Linux安装指南\"   >\n          <a href=\"#1）Understand用法及Linux安装指南\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#1）Understand用法及Linux安装指南\" class=\"headerlink\" title=\"1）Understand用法及Linux安装指南\"></a>1）Understand用法及Linux安装指南</h3>\n      <ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://zhuanlan.zhihu.com/p/44776823\" >Understand: 静态代码分析神器</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://support.scitools.com/t/installing-on-linux-and-solaris/34\" >Understand(源码阅读器)Installing on Linux and Solaris</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n\n        <h3 id=\"2）Understand在Manjaro上运行报错的解决\"   >\n          <a href=\"#2）Understand在Manjaro上运行报错的解决\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#2）Understand在Manjaro上运行报错的解决\" class=\"headerlink\" title=\"2）Understand在Manjaro上运行报错的解决\"></a>2）Understand在Manjaro上运行报错的解决</h3>\n      <p>根据上述的Understand官网上的Linux安装指南，在Ubuntu 20.04上可以正常运行，但在Manjaro 21.05上出现如下错误：</p>\n<p>在<code>./understand</code> 时报错：</p>\n<p>​    <code>./understand: symbol lookup error: /usr/lib/libfontconfig.so.1: undefined symbol: FT_Done_MM_Var</code></p>\n<p>为此我作出以下调研和尝试：</p>\n<ol>\n<li>其他软件的相似问题和解决方式：</li>\n</ol>\n<ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/weixin_41174045/article/details/115741968\" >Tecplot运行报错:undefined symbol: FT_Done_MM_Var</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/qq_45569859/article/details/103341971\" >Err：undefined symbol：FT_Done_MM_Var 及 .so 文件替换方法</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n<ol start=\"2\">\n<li>Linux使用动态库时的undefined symbol问题：</li>\n</ol>\n<ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/guangyacyb/article/details/85165231?utm_medium=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~default-5.control\" >Linux C编程问题：symbol lookup error: xxx undefined symbol xxx</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/dfman1978/article/details/6104544\" >“symbol lookup error”问题解决</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n<ol start=\"3\">\n<li>LinuxQuestions上的相似问题：</li>\n</ol>\n<ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.linuxquestions.org/questions/slackware-14/libreoffice-libfontconfig-so-1-undefined-symbol-ft_done_mm_var-4175665794/?__cf_chl_jschl_tk__=369654a585808df0dfb545a61055e86a3c75a6a9-1622624792-0-AdAhDup71USuBhSCHZOhTIyF2Qkc9S7lvAPBCx90jYXf1-1KrPFU2Bu4tF1dQcH1KLNQQMXeVkCkjetRZ2bYxDIngiM26sx6ocPE0HKlyhlp-8VoX_ar9vQqV7M-5sgP8zwHt_AdrPGaCay-ahSIgrYL25MNCS260O4WwvanLcVNOjVc3jlsGZphOymef5vs_SGJy70B5y6fZpGDVQLIM7qizqEhOIt2lP0L1FIIWzu3iRIt7_Ozi7I6LLZlxS2oNb5pBqJULDEJQ2iymBO5q7F6-85iMPfBVCSPGw_6Eq67BbgvH3C8PLaszRAaaYyKk8xTRZbbL2-h47yY8shc_2RcTpaU3JlOKbBX1OW6suFe96CSfvxr1PBUjP1EsE9KSlYtQo0P8fHBH8uGbdVsVAsjT1In4NOPuYeXWRO74RCbe7qS8N10mP7KOPuwt-Q39umxi9Xq_o8B6B0dwCZq9-e65zZEqDQMBAfAw7OKqau0x7SfJWIK6CK9-aGx4dPbuS_skJOmxJNWwN6DuaavTsddgQSqZcwroEFjwdzbtS6s4zBWI3OXS3ilQN3GNDOMtr4dhqaxJT9UYxAaJfZkOAo\" >libreoffice libfontconfig.so.1: undefined symbol: FT_Done_MM_Var</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n<p>从这些链接中我学到Linux使用动态库时需注意的问题和很多有用的Linux命令（如<code>ldd</code> 、<code>nm</code> 、<code>grep</code> 等），同时也发现自己<strong>对make的过程，Makefile的编写等还不熟悉</strong>，希望后面将这块知识补上。</p>\n<p>在调试的过程中我尝试了上述链接中的方法，但manjaro的<code>/usr/lib/</code>中 <code>libfreetype.so</code> 和<code>libfontconfig.so</code>都存在，<code>/usr/lib/libfontconfig.so</code>依赖于<code>/usr/liblib/freetype.so</code>，且<code>FT_Done_MM_Var    </code> 也在<code>libfreetype.so</code> 中定义了。而Understand的源码和makefile文件无法找到，因此<strong>不能通过修改编译过程解决</strong>。已知Understand在Ubuntu 18.04上可以正常运行，而Manjaro 21.05与Ubuntu的唯一区别在于Manjaro的Linux系统版本是5.10，而Ubuntu的系统版本是5.8，两系统中<code>libfontconfig</code>的版本一致（都是<code>libfontconfig.so.1.12.0</code>，而<code>libfreetype</code>的版本不同（Manjaro是<code>libfreetype.so.6.17.4</code>，Ubuntu是<code>libfreetype.so.6.17.1</code>），因此可能的问题应该与第一个链接（<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/weixin_41174045/article/details/115741968\" >Tecplot运行报错</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>）相似，<strong>需要降低Linux系统版本</strong>。</p>\n<p>Manjaro换内核的帖子（<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://tieba.baidu.com/p/6406292549\" >链接</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>），尝试无果。</p>\n<p>最后，<em><strong>将understand安装目录中<code>/bin/linux64</code> 下的 <code>libfreetype.so.6</code> 删除，运行成功！</strong></em></p>\n<p>反向思考错误原因，应该是<code>/bin/linux/libfreetype.so</code> 版本低，没有定义FT_Done_MM_Var，使用<code>/bin/linux/libfreetype.so</code> 时会加载系统的<code>/usr/lib/libfontconfig.so.1</code> 动态库。该动态库依赖的是版本较高的<code>/usr/lib/libfreetype.so</code>，而后者因为相同的库已存在所以没有加载，至此问题解决。</p>\n\n        <h2 id=\"Linux命令学习与积累\"   >\n          <a href=\"#Linux命令学习与积累\" class=\"heading-link\"><i class=\"fas fa-link\"></i></a><a href=\"#Linux命令学习与积累\" class=\"headerlink\" title=\"Linux命令学习与积累\"></a>Linux命令学习与积累</h2>\n      <ul>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.runoob.com/linux/linux-comm-df.html\" >Linux df 命令</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.runoob.com/linux/linux-comm-locate.html\" >Linux locate命令</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span><ul>\n<li>[[SOLVED]Locate command not found](<span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://bbs.archlinux.org/viewtopic.php?id=99084\" >https://bbs.archlinux.org/viewtopic.php?id=99084</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span>)</li>\n</ul>\n</li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://www.runoob.com/linux/linux-comm-grep.html\" >Linux grep 命令</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n<li><span class=\"exturl\"><a class=\"exturl__link\"   href=\"https://blog.csdn.net/netwalk/article/details/19335771\" >Linux下nm和ldd命令</a><span class=\"exturl__icon\"><i class=\"fas fa-external-link-alt\"></i></span></span></li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/MapReduce论文及MIT相关实验总结/exec_overview.png","slug":"exec_overview.png","post":"ckp9m0c200000vowu1i8r4wkr","modified":0,"renderable":0},{"_id":"source/_posts/MapReduce论文及MIT相关实验总结/fault_tolerate.jpeg","slug":"fault_tolerate.jpeg","post":"ckp9m0c200000vowu1i8r4wkr","modified":0,"renderable":0},{"_id":"source/_posts/MapReduce论文及MIT相关实验总结/invert_index.jpeg","slug":"invert_index.jpeg","post":"ckp9m0c200000vowu1i8r4wkr","modified":0,"renderable":0}],"PostCategory":[],"PostTag":[],"Tag":[]}}